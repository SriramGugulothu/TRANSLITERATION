{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8813062,"sourceType":"datasetVersion","datasetId":5301302}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom transformers import MobileBertTokenizer, MobileBertModel\nimport string\nfrom datasets import Dataset as Hug_Face_Dataset,load_from_disk\nfrom torch.utils.data import DataLoader,Dataset\nimport torch.nn.functional as F\nimport torch.nn as nn      ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-01T08:15:33.386254Z","iopub.execute_input":"2024-07-01T08:15:33.386516Z","iopub.status.idle":"2024-07-01T08:15:40.301099Z","shell.execute_reply.started":"2024-07-01T08:15:33.386493Z","shell.execute_reply":"2024-07-01T08:15:40.300192Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df = pd.read_parquet(r\"/kaggle/input/parquet\")","metadata":{"execution":{"iopub.status.busy":"2024-07-01T08:15:40.302970Z","iopub.execute_input":"2024-07-01T08:15:40.303534Z","iopub.status.idle":"2024-07-01T08:15:40.813742Z","shell.execute_reply.started":"2024-07-01T08:15:40.303499Z","shell.execute_reply":"2024-07-01T08:15:40.812961Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-01T08:15:45.572618Z","iopub.execute_input":"2024-07-01T08:15:45.572967Z","iopub.status.idle":"2024-07-01T08:15:45.589868Z","shell.execute_reply.started":"2024-07-01T08:15:45.572940Z","shell.execute_reply":"2024-07-01T08:15:45.588875Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                              tokens  \\\n0  [This, division, also, contains, the, Ventana,...   \n1  [\", So, here, is, the, balance, NBC, has, to, ...   \n2  [It, is, a, protest, song, that, \", creates, a...   \n3  [This, differs, from, approaches, such, as, IP...   \n4  [Since, then, ,, only, Terry, Bradshaw, in, 14...   \n\n                                            ner_tags lang  \n0         [0, 0, 0, 0, 0, 5, 6, 0, 0, 0, 0, 5, 0, 0]   en  \n1  [0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 7, 8, 0, 0, ...   en  \n2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   en  \n3  [0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, ...   en  \n4  [0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 1, 2, 0, 0, 0, ...   en  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tokens</th>\n      <th>ner_tags</th>\n      <th>lang</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[This, division, also, contains, the, Ventana,...</td>\n      <td>[0, 0, 0, 0, 0, 5, 6, 0, 0, 0, 0, 5, 0, 0]</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[\", So, here, is, the, balance, NBC, has, to, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 7, 8, 0, 0, ...</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[It, is, a, protest, song, that, \", creates, a...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[This, differs, from, approaches, such, as, IP...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[Since, then, ,, only, Terry, Bradshaw, in, 14...</td>\n      <td>[0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 1, 2, 0, 0, 0, ...</td>\n      <td>en</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-06-30T15:27:09.235225Z","iopub.execute_input":"2024-06-30T15:27:09.235886Z","iopub.status.idle":"2024-06-30T15:27:09.240551Z","shell.execute_reply.started":"2024-06-30T15:27:09.235855Z","shell.execute_reply":"2024-06-30T15:27:09.239314Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"mp2 = {'B-PER':1,'I-PER':2,'B-ORG':3,'I-ORG':4,'B-LOC':5,'I-LOC':6,'B-MISC':7,'I-MISC':8,'B-NRM':9,'B-REG':10,'B-RS':11,'I-LIT':12,'I-NRM':13,'I-REG':14,'I-RS':15,'B-ANIM':16,'I-ANIM':17,'B-BIO':18,'I-BIO':19,'B-CEL':20,'I-CEL':21,'B-DIS':22,'I-DIS':23,'B-EVE':24,\n      'I-EVE':25,'B-FOOD':26,'I-FOOD':27,'B-INST':28,'I-INST':29,'B-MEDIA':30,'I-MEDIA':31,'B-MYTH':32,'I-MYTH':33,'B-PLANT':34,'I-PLANT':35,'B-TIME':36,'I-TIME':37,'B-VEHI':38,'I-VEHI':39,'B-LIT':40} ","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:18:14.522634Z","iopub.execute_input":"2024-07-01T07:18:14.523059Z","iopub.status.idle":"2024-07-01T07:18:14.532815Z","shell.execute_reply.started":"2024-07-01T07:18:14.523018Z","shell.execute_reply":"2024-07-01T07:18:14.531427Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def fun(tokens,tags):\n    count = 0\n    words = []\n    entities = []\n    index = 0\n    for token in tokens:\n        if(token[0] not in string.punctuation):\n            temp = token.split()\n            for t in temp:\n                words.append(t)\n            if(tags[index]!=0):\n                entities.append((str(count+1),str(count+len(temp)),mp[tags[index]]))\n            count+=len(temp)\n        index+=1\n    return words,entities","metadata":{"execution":{"iopub.status.busy":"2024-07-01T08:15:49.369402Z","iopub.execute_input":"2024-07-01T08:15:49.370183Z","iopub.status.idle":"2024-07-01T08:15:49.376443Z","shell.execute_reply.started":"2024-07-01T08:15:49.370148Z","shell.execute_reply":"2024-07-01T08:15:49.375493Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df2 = pd.DataFrame(columns=['input','output'])","metadata":{"execution":{"iopub.status.busy":"2024-07-01T08:15:51.719126Z","iopub.execute_input":"2024-07-01T08:15:51.719927Z","iopub.status.idle":"2024-07-01T08:15:51.726212Z","shell.execute_reply.started":"2024-07-01T08:15:51.719885Z","shell.execute_reply":"2024-07-01T08:15:51.725252Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df2","metadata":{"execution":{"iopub.status.busy":"2024-07-01T08:15:53.436284Z","iopub.execute_input":"2024-07-01T08:15:53.436742Z","iopub.status.idle":"2024-07-01T08:15:53.444931Z","shell.execute_reply.started":"2024-07-01T08:15:53.436713Z","shell.execute_reply":"2024-07-01T08:15:53.443952Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Empty DataFrame\nColumns: [input, output]\nIndex: []","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input</th>\n      <th>output</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"mp = {1:'B-PER',2:'I-PER',3:'B-ORG',4:'I-ORG',5:'B-LOC',6:'I-LOC',7:'B-MISC',8:'I-MISC'}","metadata":{"execution":{"iopub.status.busy":"2024-07-01T08:15:57.124038Z","iopub.execute_input":"2024-07-01T08:15:57.124378Z","iopub.status.idle":"2024-07-01T08:15:57.128698Z","shell.execute_reply.started":"2024-07-01T08:15:57.124351Z","shell.execute_reply":"2024-07-01T08:15:57.127709Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"for i in range(0,len(df)):\n    k,l = fun(df['tokens'][i],df['ner_tags'][i])\n    df2.loc[i]=[k,l]","metadata":{"execution":{"iopub.status.busy":"2024-07-01T08:15:58.763351Z","iopub.execute_input":"2024-07-01T08:15:58.763761Z","iopub.status.idle":"2024-07-01T08:19:59.102947Z","shell.execute_reply.started":"2024-07-01T08:15:58.763735Z","shell.execute_reply":"2024-07-01T08:19:59.102168Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"df2","metadata":{"execution":{"iopub.status.busy":"2024-07-01T08:21:30.336658Z","iopub.execute_input":"2024-07-01T08:21:30.337009Z","iopub.status.idle":"2024-07-01T08:21:30.367009Z","shell.execute_reply.started":"2024-07-01T08:21:30.336981Z","shell.execute_reply":"2024-07-01T08:21:30.366092Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                                   input  \\\n0      [This, division, also, contains, the, Ventana,...   \n1      [So, here, is, the, balance, NBC, has, to, con...   \n2      [It, is, a, protest, song, that, creates, a, c...   \n3      [This, differs, from, approaches, such, as, IP...   \n4      [Since, then, only, Terry, Bradshaw, in, 147, ...   \n...                                                  ...   \n92715  [The, couple, had, a, son, David, and, a, daug...   \n92716  [The, Home, Secretary, J., R., Clynes, was, pr...   \n92717  [At, the, time, of, her, birth, she, was, four...   \n92718  [The, film, was, based, on, the, Broadway, pla...   \n92719  [The, couple, had, two, children, both, born, ...   \n\n                                                  output  \n0        [(6, 6, B-LOC), (7, 7, I-LOC), (11, 11, B-LOC)]  \n1      [(6, 6, B-ORG), (10, 10, B-MISC), (11, 11, I-M...  \n2                                      [(22, 22, B-LOC)]  \n3                                       [(9, 9, B-MISC)]  \n4      [(4, 4, B-PER), (5, 5, I-PER), (9, 9, B-PER), ...  \n...                                                  ...  \n92715                   [(6, 6, B-PER), (10, 10, B-PER)]  \n92716      [(4, 4, B-PER), (5, 5, I-PER), (6, 6, I-PER)]  \n92717                 [(17, 17, B-PER), (18, 18, I-PER)]  \n92718                                   [(7, 7, B-MISC)]  \n92719  [(9, 9, B-MISC), (12, 12, B-PER), (14, 14, B-P...  \n\n[92720 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input</th>\n      <th>output</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[This, division, also, contains, the, Ventana,...</td>\n      <td>[(6, 6, B-LOC), (7, 7, I-LOC), (11, 11, B-LOC)]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[So, here, is, the, balance, NBC, has, to, con...</td>\n      <td>[(6, 6, B-ORG), (10, 10, B-MISC), (11, 11, I-M...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[It, is, a, protest, song, that, creates, a, c...</td>\n      <td>[(22, 22, B-LOC)]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[This, differs, from, approaches, such, as, IP...</td>\n      <td>[(9, 9, B-MISC)]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[Since, then, only, Terry, Bradshaw, in, 147, ...</td>\n      <td>[(4, 4, B-PER), (5, 5, I-PER), (9, 9, B-PER), ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>92715</th>\n      <td>[The, couple, had, a, son, David, and, a, daug...</td>\n      <td>[(6, 6, B-PER), (10, 10, B-PER)]</td>\n    </tr>\n    <tr>\n      <th>92716</th>\n      <td>[The, Home, Secretary, J., R., Clynes, was, pr...</td>\n      <td>[(4, 4, B-PER), (5, 5, I-PER), (6, 6, I-PER)]</td>\n    </tr>\n    <tr>\n      <th>92717</th>\n      <td>[At, the, time, of, her, birth, she, was, four...</td>\n      <td>[(17, 17, B-PER), (18, 18, I-PER)]</td>\n    </tr>\n    <tr>\n      <th>92718</th>\n      <td>[The, film, was, based, on, the, Broadway, pla...</td>\n      <td>[(7, 7, B-MISC)]</td>\n    </tr>\n    <tr>\n      <th>92719</th>\n      <td>[The, couple, had, two, children, both, born, ...</td>\n      <td>[(9, 9, B-MISC), (12, 12, B-PER), (14, 14, B-P...</td>\n    </tr>\n  </tbody>\n</table>\n<p>92720 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-06-30T16:10:46.629497Z","iopub.execute_input":"2024-06-30T16:10:46.629896Z","iopub.status.idle":"2024-06-30T16:10:48.064809Z","shell.execute_reply.started":"2024-06-30T16:10:46.629867Z","shell.execute_reply":"2024-06-30T16:10:48.063623Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-06-30T19:15:06.807939Z","iopub.execute_input":"2024-06-30T19:15:06.808304Z","iopub.status.idle":"2024-06-30T19:15:06.812807Z","shell.execute_reply.started":"2024-06-30T19:15:06.808272Z","shell.execute_reply":"2024-06-30T19:15:06.811796Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"dataset3 = Hug_Face_Dataset.from_pandas(df2)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T08:21:35.096878Z","iopub.execute_input":"2024-07-01T08:21:35.097211Z","iopub.status.idle":"2024-07-01T08:21:35.609428Z","shell.execute_reply.started":"2024-07-01T08:21:35.097186Z","shell.execute_reply":"2024-07-01T08:21:35.608670Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"dataset3.save_to_disk(r\"C:\\Users\\srira\\OneDrive\\Desktop\\kaggle\")","metadata":{"execution":{"iopub.status.busy":"2024-07-01T08:21:57.762286Z","iopub.execute_input":"2024-07-01T08:21:57.763164Z","iopub.status.idle":"2024-07-01T08:21:57.877309Z","shell.execute_reply.started":"2024-07-01T08:21:57.763130Z","shell.execute_reply":"2024-07-01T08:21:57.876437Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Saving the dataset (0/1 shards):   0%|          | 0/92720 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0f8bce0184a440ea2a3f1afa19acedd"}},"metadata":{}}]},{"cell_type":"code","source":"dataset = load_from_disk(r\"C:\\Users\\srira\\OneDrive\\Desktop\\kaggle\")","metadata":{"execution":{"iopub.status.busy":"2024-07-01T08:21:59.696305Z","iopub.execute_input":"2024-07-01T08:21:59.696976Z","iopub.status.idle":"2024-07-01T08:21:59.709237Z","shell.execute_reply.started":"2024-07-01T08:21:59.696942Z","shell.execute_reply":"2024-07-01T08:21:59.708251Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"df_temp = pd.DataFrame(dataset)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T08:22:02.371681Z","iopub.execute_input":"2024-07-01T08:22:02.372493Z","iopub.status.idle":"2024-07-01T08:22:12.534411Z","shell.execute_reply.started":"2024-07-01T08:22:02.372430Z","shell.execute_reply":"2024-07-01T08:22:12.533318Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"df_temp","metadata":{"execution":{"iopub.status.busy":"2024-07-01T08:22:12.536324Z","iopub.execute_input":"2024-07-01T08:22:12.536744Z","iopub.status.idle":"2024-07-01T08:22:12.568235Z","shell.execute_reply.started":"2024-07-01T08:22:12.536707Z","shell.execute_reply":"2024-07-01T08:22:12.567303Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"                                                   input  \\\n0      [This, division, also, contains, the, Ventana,...   \n1      [So, here, is, the, balance, NBC, has, to, con...   \n2      [It, is, a, protest, song, that, creates, a, c...   \n3      [This, differs, from, approaches, such, as, IP...   \n4      [Since, then, only, Terry, Bradshaw, in, 147, ...   \n...                                                  ...   \n92715  [The, couple, had, a, son, David, and, a, daug...   \n92716  [The, Home, Secretary, J., R., Clynes, was, pr...   \n92717  [At, the, time, of, her, birth, she, was, four...   \n92718  [The, film, was, based, on, the, Broadway, pla...   \n92719  [The, couple, had, two, children, both, born, ...   \n\n                                                  output  __index_level_0__  \n0        [[6, 6, B-LOC], [7, 7, I-LOC], [11, 11, B-LOC]]                  0  \n1      [[6, 6, B-ORG], [10, 10, B-MISC], [11, 11, I-M...                  1  \n2                                      [[22, 22, B-LOC]]                  2  \n3                                       [[9, 9, B-MISC]]                  3  \n4      [[4, 4, B-PER], [5, 5, I-PER], [9, 9, B-PER], ...                  4  \n...                                                  ...                ...  \n92715                   [[6, 6, B-PER], [10, 10, B-PER]]              92715  \n92716      [[4, 4, B-PER], [5, 5, I-PER], [6, 6, I-PER]]              92716  \n92717                 [[17, 17, B-PER], [18, 18, I-PER]]              92717  \n92718                                   [[7, 7, B-MISC]]              92718  \n92719  [[9, 9, B-MISC], [12, 12, B-PER], [14, 14, B-P...              92719  \n\n[92720 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input</th>\n      <th>output</th>\n      <th>__index_level_0__</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[This, division, also, contains, the, Ventana,...</td>\n      <td>[[6, 6, B-LOC], [7, 7, I-LOC], [11, 11, B-LOC]]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[So, here, is, the, balance, NBC, has, to, con...</td>\n      <td>[[6, 6, B-ORG], [10, 10, B-MISC], [11, 11, I-M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[It, is, a, protest, song, that, creates, a, c...</td>\n      <td>[[22, 22, B-LOC]]</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[This, differs, from, approaches, such, as, IP...</td>\n      <td>[[9, 9, B-MISC]]</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[Since, then, only, Terry, Bradshaw, in, 147, ...</td>\n      <td>[[4, 4, B-PER], [5, 5, I-PER], [9, 9, B-PER], ...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>92715</th>\n      <td>[The, couple, had, a, son, David, and, a, daug...</td>\n      <td>[[6, 6, B-PER], [10, 10, B-PER]]</td>\n      <td>92715</td>\n    </tr>\n    <tr>\n      <th>92716</th>\n      <td>[The, Home, Secretary, J., R., Clynes, was, pr...</td>\n      <td>[[4, 4, B-PER], [5, 5, I-PER], [6, 6, I-PER]]</td>\n      <td>92716</td>\n    </tr>\n    <tr>\n      <th>92717</th>\n      <td>[At, the, time, of, her, birth, she, was, four...</td>\n      <td>[[17, 17, B-PER], [18, 18, I-PER]]</td>\n      <td>92717</td>\n    </tr>\n    <tr>\n      <th>92718</th>\n      <td>[The, film, was, based, on, the, Broadway, pla...</td>\n      <td>[[7, 7, B-MISC]]</td>\n      <td>92718</td>\n    </tr>\n    <tr>\n      <th>92719</th>\n      <td>[The, couple, had, two, children, both, born, ...</td>\n      <td>[[9, 9, B-MISC], [12, 12, B-PER], [14, 14, B-P...</td>\n      <td>92719</td>\n    </tr>\n  </tbody>\n</table>\n<p>92720 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, inputTokens,outputEntity,tokenizer,max_tokens=128,mapping={'B-PER':1}):\n        self.source = inputTokens\n        self.target = outputEntity\n        self.tokenizer = tokenizer\n        self.max_tokens = max_tokens\n        self.mapping = mapping\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        \n    def __len__(self):\n        return len(self.source)\n    \n    def __getitem__(self, idx):\n        if isinstance(idx, list):\n            return [self._get_single_item(i) for i in idx]\n        else :\n            return self._get_single_item(idx)\n    \n    def _get_single_item(self,idx):\n        \n        source_data = self.source[idx]\n        target_data = self.target[idx]\n        tokenized_input = self.tokenizer(source_data, return_tensors='pt', padding='max_length', truncation=True, max_length=self.max_tokens,is_split_into_words=True)\n        label_ids = torch.zeros(tokenized_input['input_ids'].size(1), dtype=torch.long)\n        \n        for start, end, label in target_data:\n            start = int(start)\n            end = int(end)\n            label_id = self.mapping[label]\n            label_ids[start:end+1] = label_id\n        \n        return tokenized_input['input_ids'].squeeze(0).to(self.device), tokenized_input['attention_mask'].squeeze(0).to(self.device), label_ids.to(self.device)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T08:22:39.465910Z","iopub.execute_input":"2024-07-01T08:22:39.466251Z","iopub.status.idle":"2024-07-01T08:22:39.477150Z","shell.execute_reply.started":"2024-07-01T08:22:39.466223Z","shell.execute_reply":"2024-07-01T08:22:39.476120Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"class NERModel(nn.Module):\n    \n    def __init__(self, max_tokens=128, hidden_size=64, num_entities=8,mobilebert_model=None,device='cpu'):\n        \n        super(NERModel, self).__init__()\n        \n        self.max_tokens = max_tokens\n        self.num_entities = num_entities\n        # MobileBERT model (base model)\n        self.mobilebert = mobilebert_model.to(device=device)\n        \n        self.hidden_size = hidden_size\n        \n        self.device = device\n        \n        # First GRU Layer\n        self.gru1 = nn.ModuleList([\n            nn.GRU(input_size=self.mobilebert.config.hidden_size, hidden_size=hidden_size, batch_first=True)\n            for _ in range(self.max_tokens)\n        ])\n        \n        # Second GRU Layer\n        self.gru2 = nn.ModuleList([\n            nn.GRU(input_size=hidden_size, hidden_size=hidden_size, batch_first=True)\n            for _ in range(self.max_tokens)\n        ])\n        \n        # Fully connected layers\n        self.fc_layers = nn.ModuleList([\n            nn.Linear(hidden_size, num_entities) for _ in range(max_tokens)\n        ])\n    \n            \n    def forward(self, input_ids, attention_mask):\n        \n        batch_size = input_ids.size(0)\n        \n        \n        outputs = self.mobilebert(input_ids=input_ids, attention_mask=attention_mask)\n        \n        sequence_output = outputs.last_hidden_state  \n        \n        temp = torch.zeros(1,batch_size,self.hidden_size,device = input_ids.device)\n        \n        \n        gru1_outputs = torch.zeros(batch_size, self.max_tokens, self.gru1[0].hidden_size, device=input_ids.device)\n        gru2_outputs = torch.zeros(batch_size, self.max_tokens, self.gru2[0].hidden_size, device=input_ids.device)\n        \n        for i in range(self.max_tokens):\n\n            gru1_output, temp = self.gru1[i](sequence_output[:, i].unsqueeze(1),temp)\n            gru1_outputs[:,i,:] = gru1_output.squeeze(1)\n            \n        temp = torch.zeros(1,batch_size,self.hidden_size,device = input_ids.device)\n        \n        for i in range(self.max_tokens-1,-1,-1):\n            temp2, temp =  self.gru1[i](sequence_output[:,i].unsqueeze(1),temp)\n            temp2 = temp2.squeeze(1)\n            gru1_outputs[:,i,:] = (gru1_outputs[:,i,:] + temp2) / 2\n            \n        temp = torch.zeros(1,batch_size,self.gru2[0].input_size,device = input_ids.device)\n        \n        for i in range(self.max_tokens):\n            gru2_output, temp = self.gru2[i](gru1_outputs[:, i].unsqueeze(1),temp)\n            gru2_outputs[:,i,:] = gru2_output.squeeze(1)\n            \n        temp = torch.zeros(1,batch_size,self.gru2[0].input_size,device = input_ids.device)\n        \n        for i in range(self.max_tokens-1,-1,-1):\n            temp2, temp =  self.gru2[i](gru1_outputs[:,i].unsqueeze(1),temp)\n            temp2 = temp2.squeeze(1)\n            gru2_outputs[:,i,:] = (gru2_outputs[:,i,:] + temp2) / 2                  \n            \n        overallOutput = torch.zeros(batch_size, self.max_tokens,self.num_entities, device=input_ids.device)\n        \n        for i, fc_layer in enumerate(self.fc_layers):\n            overallOutput[:, i, :] = fc_layer(gru2_outputs[:, i, :])\n        \n        return overallOutput","metadata":{"execution":{"iopub.status.busy":"2024-07-01T08:56:50.228256Z","iopub.execute_input":"2024-07-01T08:56:50.229053Z","iopub.status.idle":"2024-07-01T08:56:50.246697Z","shell.execute_reply.started":"2024-07-01T08:56:50.229021Z","shell.execute_reply":"2024-07-01T08:56:50.245806Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"def dataProcessing(dataset,tokenizer,max_tokens,batch_size,mapping):\n    inputData = dataset['input'] \n    outputData = dataset['output']\n    myDataset = MyDataset(inputData,outputData,tokenizer,max_tokens,mapping)\n    dataLoader = DataLoader(myDataset,batch_size,shuffle = False)\n    return dataLoader    ","metadata":{"execution":{"iopub.status.busy":"2024-07-01T08:22:51.769866Z","iopub.execute_input":"2024-07-01T08:22:51.770219Z","iopub.status.idle":"2024-07-01T08:22:51.775803Z","shell.execute_reply.started":"2024-07-01T08:22:51.770190Z","shell.execute_reply":"2024-07-01T08:22:51.774775Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def train(max_tokens,hidden_size,num_entities,learning_rate,batch_size,mapping,epochs):\n    \n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    tokenizer = MobileBertTokenizer.from_pretrained('google/mobilebert-uncased')\n    mobilebert_model = MobileBertModel.from_pretrained('google/mobilebert-uncased')\n    \n    dataset = load_from_disk(r\"C:\\Users\\srira\\OneDrive\\Desktop\\kaggle\")\n    \n    dataloader = dataProcessing(dataset,tokenizer,max_tokens,batch_size,mapping)\n    \n    model = NERModel(max_tokens,hidden_size,num_entities,mobilebert_model,device)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n    \n    criterion = nn.CrossEntropyLoss()\n    \n    model.to(device)\n    \n    model.train()\n    \n    numberOfInputs = len(dataset['input'])\n    \n    for epoch in range(epochs): \n\n        total_loss = 0.0\n        total_steps = 0.0\n        \n        correct_predictions = 0.0\n        print(f'epoch{epoch}')\n        \n        for idx,(input_ids, attention_mask, labels) in enumerate(dataloader):\n            \n            optimizer.zero_grad()\n        \n            output = model(input_ids, attention_mask)\n\n            # Flatten the logits and labels for loss calculation\n            \n            output_flat = output.view(-1, output.size(-1))\n            labels_flat = labels.view(-1)\n\n            probabilities = F.softmax(output_flat, dim=1)\n\n            predicted_labels = torch.argmax(probabilities, dim=1)\n            \n            correct_predictions += (predicted_labels == labels_flat & (labels_flat != 0) ).sum().item()\n\n            # Calculate loss\n            loss = criterion(output_flat, labels_flat)\n\n            # Backward pass\n            loss.backward()\n            optimizer.step()\n\n            # Accumulate loss\n            total_loss += loss.item() \n            \n            if(idx%10==0):\n                print(f'loss {loss.item()}')\n            \n            total_steps += 1\n\n        # Print average loss\n        avg_loss = total_loss / total_steps\n        accuracy_percentage = correct_predictions / numberOfInputs\n        print(f'epoch {epoch}, average_loss {avg_loss}, accuracyPercentage, {accuracy_percentage}')   ","metadata":{"execution":{"iopub.status.busy":"2024-07-01T09:23:32.971291Z","iopub.execute_input":"2024-07-01T09:23:32.971670Z","iopub.status.idle":"2024-07-01T09:23:32.985169Z","shell.execute_reply.started":"2024-07-01T09:23:32.971642Z","shell.execute_reply":"2024-07-01T09:23:32.983909Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"print(64*3)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T09:03:29.348439Z","iopub.execute_input":"2024-07-01T09:03:29.348817Z","iopub.status.idle":"2024-07-01T09:03:29.353583Z","shell.execute_reply.started":"2024-07-01T09:03:29.348789Z","shell.execute_reply":"2024-07-01T09:03:29.352493Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"192\n","output_type":"stream"}]},{"cell_type":"code","source":"mapping = {'B-PER':1,'I-PER':2,'B-ORG':3,'I-ORG':4,'B-LOC':5,'I-LOC':6,'B-MISC':7,'I-MISC':8,'B-NRM':9,'B-REG':10,'B-RS':11,'I-LIT':12,'I-NRM':13,'I-REG':14,'I-RS':15,'B-ANIM':16,'I-ANIM':17,'B-BIO':18,'I-BIO':19,'B-CEL':20,'I-CEL':21,'B-DIS':22,'I-DIS':23,'B-EVE':24,\n      'I-EVE':25,'B-FOOD':26,'I-FOOD':27,'B-INST':28,'I-INST':29,'B-MEDIA':30,'I-MEDIA':31,'B-MYTH':32,'I-MYTH':33,'B-PLANT':34,'I-PLANT':35,'B-TIME':36,'I-TIME':37,'B-VEHI':38,'I-VEHI':39,'B-LIT':40}","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:45:21.057502Z","iopub.execute_input":"2024-07-01T07:45:21.057911Z","iopub.status.idle":"2024-07-01T07:45:21.067062Z","shell.execute_reply.started":"2024-07-01T07:45:21.057882Z","shell.execute_reply":"2024-07-01T07:45:21.065572Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"print(64*)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mapping = {'B-PER':1,'I-PER':2,'B-ORG':3,'I-ORG':4,'B-LOC':5,'I-LOC':6,'B-MISC':7,'I-MISC':8,'B-NRM':9,'B-REG':10,'B-RS':11,'I-LIT':12,'I-NRM':13,'I-REG':14,'I-RS':15,'B-ANIM':16,'I-ANIM':17,'B-BIO':18,'I-BIO':19,'B-CEL':20,'I-CEL':21,'B-DIS':22,'I-DIS':23,'B-EVE':24,\n      'I-EVE':25,'B-FOOD':26,'I-FOOD':27,'B-INST':28,'I-INST':29,'B-MEDIA':30,'I-MEDIA':31,'B-MYTH':32,'I-MYTH':33,'B-PLANT':34,'I-PLANT':35,'B-TIME':36,'I-TIME':37,'B-VEHI':38,'I-VEHI':39,'B-LIT':40} \ntrain(max_tokens=128,hidden_size=64,num_entities=41,learning_rate=1e-4,batch_size=64,mapping=mapping,epochs=10)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T09:23:52.012296Z","iopub.execute_input":"2024-07-01T09:23:52.012939Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"epoch0\nloss 3.7215969562530518\nloss 3.501929759979248\nloss 3.2008464336395264\nloss 2.911377429962158\nloss 2.670694351196289\nloss 2.4513728618621826\nloss 2.2195491790771484\nloss 1.9941368103027344\nloss 1.7590441703796387\nloss 1.5392378568649292\n","output_type":"stream"}]},{"cell_type":"code","source":"inputData2 = dataset['input']\noutputData2 = dataset['output']","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:45:37.013061Z","iopub.execute_input":"2024-07-01T07:45:37.013502Z","iopub.status.idle":"2024-07-01T07:45:44.065253Z","shell.execute_reply.started":"2024-07-01T07:45:37.013470Z","shell.execute_reply":"2024-07-01T07:45:44.063844Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# Example of training loop (similar to previous examples)\nmodel = NERModel(20,64,41)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\ncriterion = nn.CrossEntropyLoss()\n\nmodel.train()\ncount = 1\nfor epoch in range(2): \n        \n    total_loss = 0.0\n    total_steps = 0 \n    \n    for input_ids, attention_mask, labels in dataloader:\n        optimizer.zero_grad()\n        logits = model(input_ids, attention_mask)\n        \n        # Flatten the logits and labels for loss calculation\n        logits_flat = logits.view(-1, logits.size(-1))\n        labels_flat = labels.view(-1)\n        \n        probabilities = F.softmax(logits_flat, dim=1)\n        \n        predicted_labels = torch.argmax(probabilities, dim=1)\n        \n        correct_predictions = (predicted_labels == labels_flat & (labels_flat != 0) ).sum().item()\n        print(correct_predictions)\n        \n        # Calculate loss\n        loss = criterion(logits_flat, labels_flat)\n        \n        # Backward pass\n        loss.backward()\n        optimizer.step()\n        \n        # Accumulate loss\n        total_loss += loss.item() \n        total_steps += 1\n        \n        count+=1\n    \n    # Print average loss\n    avg_loss = total_loss / total_steps\n    print(f'Epoch [{epoch+1}/{10}], Loss: {avg_loss:.4f}')\n ","metadata":{"execution":{"iopub.status.busy":"2024-06-30T16:27:05.328474Z","iopub.execute_input":"2024-06-30T16:27:05.329504Z","iopub.status.idle":"2024-06-30T16:27:05.334025Z","shell.execute_reply.started":"2024-06-30T16:27:05.329468Z","shell.execute_reply":"2024-06-30T16:27:05.332910Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-06-30T16:25:34.726999Z","iopub.execute_input":"2024-06-30T16:25:34.727852Z","iopub.status.idle":"2024-06-30T16:25:34.732527Z","shell.execute_reply.started":"2024-06-30T16:25:34.727816Z","shell.execute_reply":"2024-06-30T16:25:34.731187Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-06-30T16:52:48.865316Z","iopub.execute_input":"2024-06-30T16:52:48.866584Z","iopub.status.idle":"2024-06-30T16:52:48.894521Z","shell.execute_reply.started":"2024-06-30T16:52:48.866543Z","shell.execute_reply":"2024-06-30T16:52:48.892934Z"},"trusted":true},"execution_count":63,"outputs":[]}]}