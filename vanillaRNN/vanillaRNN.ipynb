{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8273608,"sourceType":"datasetVersion","datasetId":4912633},{"sourceId":8400322,"sourceType":"datasetVersion","datasetId":4998024}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sriramgugulothu/dl-assignment3?scriptVersionId=177655187\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport pandas as pd\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport copy\nfrom torch.utils.data import Dataset, DataLoader\nimport random","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-14T15:05:57.617414Z","iopub.execute_input":"2024-05-14T15:05:57.617817Z","iopub.status.idle":"2024-05-14T15:05:59.845841Z","shell.execute_reply.started":"2024-05-14T15:05:57.617768Z","shell.execute_reply":"2024-05-14T15:05:59.844855Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# !pip install wandb\n# import wandb\n# from wandb.keras import WandbCallback\n# import socket\n# socket.setdefaulttimeout(30)\n# wandb.login()\n# wandb.init(project ='vanillaRNN')","metadata":{"execution":{"iopub.status.busy":"2024-05-14T15:05:59.850598Z","iopub.execute_input":"2024-05-14T15:05:59.850862Z","iopub.status.idle":"2024-05-14T15:05:59.85527Z","shell.execute_reply.started":"2024-05-14T15:05:59.850839Z","shell.execute_reply":"2024-05-14T15:05:59.854296Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T15:05:59.856601Z","iopub.execute_input":"2024-05-14T15:05:59.856838Z","iopub.status.idle":"2024-05-14T15:05:59.919436Z","shell.execute_reply.started":"2024-05-14T15:05:59.856817Z","shell.execute_reply":"2024-05-14T15:05:59.918411Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"train_csv = \"/kaggle/input/telugu/tel/tel_train.csv\"\ntest_csv = \"/kaggle/input/telugu/tel/tel_test.csv\"\nval_csv = \"/kaggle/input/telugu/tel/tel_valid.csv\"","metadata":{"execution":{"iopub.status.busy":"2024-05-14T15:05:59.922656Z","iopub.execute_input":"2024-05-14T15:05:59.922994Z","iopub.status.idle":"2024-05-14T15:05:59.932898Z","shell.execute_reply.started":"2024-05-14T15:05:59.922967Z","shell.execute_reply":"2024-05-14T15:05:59.931947Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv(train_csv, header=None)\ntrain_input = train_data[0].to_numpy()\ntrain_output = train_data[1].to_numpy()\nval_data = pd.read_csv(val_csv,header = None)\nval_input = val_data[0].to_numpy()\nval_output = val_data[1].to_numpy()\ntest_data = pd.read_csv(test_csv,header= None)\nprint(len(train_input))\nprint(len(train_output))\nprint(len(val_input))\nprint(len(test_data))\nprint(val_input)\nprint(val_output)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T15:05:59.934111Z","iopub.execute_input":"2024-05-14T15:05:59.93449Z","iopub.status.idle":"2024-05-14T15:06:00.064557Z","shell.execute_reply.started":"2024-05-14T15:05:59.934453Z","shell.execute_reply":"2024-05-14T15:06:00.063482Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"51200\n51200\n4096\n4096\n['bheeshmudini' 'vinyasaanni' 'kaavachhunu' ... 'asramam' 'divine' 'dis']\n['భీష్ముడిని' 'విన్యాసాన్ని' 'కావచ్చును' ... 'ఆశ్రమం' 'డివైన్' 'డిస్']\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train_output[0][5]) #the size of input and output is 4096\nmaxi = 0\nt =''\nfor x in val_input:\n    maxi = max(maxi,len(x))\n    if(maxi == len(x)):\n        t=x\n        \nprint(maxi,t)\nt =''\nmaxi =0 \nfor x in val_output:\n    maxi = max(maxi,len(x))\n    if(maxi == len(x)):\n        t=x\n        \nprint(maxi,t)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-14T15:06:00.065784Z","iopub.execute_input":"2024-05-14T15:06:00.066122Z","iopub.status.idle":"2024-05-14T15:06:00.079155Z","shell.execute_reply.started":"2024-05-14T15:06:00.066095Z","shell.execute_reply":"2024-05-14T15:06:00.078153Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"ల\n28 paramaanandabharithudayyaadu\n19 పరమానందభరితుడయ్యాడు\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndef pre_processing(train_input,train_output):\n    data = {\n    \"all_characters\" : [],\n    \"char_num_map\" : {},\n    \"num_char_map\" : {},\n    \"source_charToNum\": torch.zeros(len(train_input),30, dtype=torch.int, device=device),\n    \"source_data\" : train_input,\n        \n    \"all_characters_2\" : [],\n    \"char_num_map_2\" : {},\n    \"num_char_map_2\" : {},\n    \"val_charToNum\": torch.zeros(len(train_output),23, dtype=torch.int, device=device),\n    \"target_data\" : train_output,\n    \"source_len\" : 0,\n    \"target_len\" : 0\n }\n    k = 0 \n    l = 0\n    for i in range(0,len(train_input)):\n        train_input[i] = \"{\" + train_input[i] + \"}\"*(29-len(train_input[i]))\n        charToNum = []\n        for char in (train_input[i]):\n            index = 0\n            if(char not in data[\"all_characters\"]):\n                data[\"all_characters\"].append(char)\n                index = data[\"all_characters\"].index(char)\n                data[\"char_num_map\"][char] = index\n                data[\"num_char_map\"][index] = char\n            else:\n                index = data[\"all_characters\"].index(char)\n            \n            charToNum.append(index)\n            \n        my_tensor = torch.tensor(charToNum,device = device)\n        data[\"source_charToNum\"][k] = my_tensor\n        \n        charToNum1 = []\n        \n        train_output[i] = \"{\" + train_output[i] + \"}\"*(22-len(train_output[i]))\n        for char in (train_output[i]):\n            index = 0\n            if(char not in data[\"all_characters_2\"]):\n                data[\"all_characters_2\"].append(char)\n                index = data[\"all_characters_2\"].index(char)\n                data[\"char_num_map_2\"][char] = index\n                data[\"num_char_map_2\"][index] = char\n            else:\n                index = data[\"all_characters_2\"].index(char)\n                \n            charToNum1.append(index)\n            \n        my_tensor1 = torch.tensor(charToNum1,device = device)\n        data[\"val_charToNum\"][k] = my_tensor1\n        \n        k+=1\n    \n    data[\"source_len\"] = len(data[\"all_characters\"])\n    data[\"target_len\"] = len(data[\"all_characters_2\"])\n        \n    return data\n    \n    \ndata = pre_processing(copy.copy(train_input),copy.copy(train_output))\n# print(data[\"all_characters\"])\n# print(data[\"char_num_map\"])\n# print(data[\"num_char_map\"])\n# print(data[\"all_characters_2\"])\n# print(data[\"char_num_map_2\"])\n# print(data[\"num_char_map_2\"])\nprint(data[\"source_charToNum\"])\nprint(data['val_charToNum'])\nprint(data[\"num_char_map_2\"])\nprint(data[\"num_char_map\"])\nprint(train_input[0])\nprint(data['source_len'])\nprint(data['target_len'])\n","metadata":{"execution":{"iopub.status.busy":"2024-05-14T15:06:00.080385Z","iopub.execute_input":"2024-05-14T15:06:00.080699Z","iopub.status.idle":"2024-05-14T15:06:07.971438Z","shell.execute_reply.started":"2024-05-14T15:06:00.080673Z","shell.execute_reply":"2024-05-14T15:06:07.970467Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"tensor([[ 0,  1,  2,  ...,  9,  9,  9],\n        [ 0,  1,  2,  ...,  9,  9,  9],\n        [ 0, 13,  2,  ...,  9,  9,  9],\n        ...,\n        [ 0,  1,  8,  ...,  9,  9,  9],\n        [ 0,  3, 16,  ...,  9,  9,  9],\n        [ 0, 14, 20,  ...,  9,  9,  9]], device='cuda:0', dtype=torch.int32)\ntensor([[ 0,  1,  2,  ..., 10, 10, 10],\n        [ 0,  1, 11,  ..., 10, 10, 10],\n        [ 0, 14,  3,  ..., 10, 10, 10],\n        ...,\n        [ 0,  1, 25,  ..., 10, 10, 10],\n        [ 0,  2, 20,  ..., 10, 10, 10],\n        [ 0, 27, 25,  ..., 10, 10, 10]], device='cuda:0', dtype=torch.int32)\n{0: '{', 1: 'వ', 2: 'ర', 3: '్', 4: 'గ', 5: 'ా', 6: 'ల', 7: 'ి', 8: 'న', 9: 'ే', 10: '}', 11: 'స', 12: 'త', 13: 'ద', 14: 'ఫ', 15: 'య', 16: 'క', 17: 'ట', 18: 'మ', 19: 'ో', 20: 'ూ', 21: 'ళ', 22: 'ప', 23: 'ధ', 24: 'ు', 25: 'ె', 26: 'ం', 27: 'చ', 28: 'ై', 29: 'డ', 30: 'ఖ', 31: 'ఉ', 32: 'ష', 33: 'ఆ', 34: 'ొ', 35: 'శ', 36: 'అ', 37: 'భ', 38: 'ృ', 39: 'ణ', 40: 'హ', 41: 'జ', 42: 'ీ', 43: 'ఇ', 44: 'బ', 45: 'ఐ', 46: 'ఒ', 47: 'ఎ', 48: 'ౌ', 49: 'థ', 50: 'ఈ', 51: 'ఊ', 52: 'ఏ', 53: 'ఢ', 54: 'ఓ', 55: 'ఔ', 56: 'ఞ', 57: 'ఠ', 58: 'ఘ', 59: 'ఛ', 60: 'ః', 61: 'ఝ', 62: 'ఋ', 63: 'ఱ'}\n{0: '{', 1: 'v', 2: 'a', 3: 'r', 4: 'g', 5: 'l', 6: 'i', 7: 'n', 8: 'e', 9: '}', 10: 's', 11: 't', 12: 'd', 13: 'f', 14: 'c', 15: 'm', 16: 'o', 17: 'u', 18: 'w', 19: 'p', 20: 'h', 21: 'k', 22: 'y', 23: 'b', 24: 'j', 25: 'z', 26: 'x', 27: 'q'}\nvargaalavaarine\n28\n64\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train_input[1])\nprint(train_output[1])","metadata":{"execution":{"iopub.status.busy":"2024-05-14T15:06:07.972621Z","iopub.execute_input":"2024-05-14T15:06:07.9729Z","iopub.status.idle":"2024-05-14T15:06:07.978182Z","shell.execute_reply.started":"2024-05-14T15:06:07.972877Z","shell.execute_reply":"2024-05-14T15:06:07.977263Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"vastadira\nవస్తాదిరా\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndef pre_processing_validation(val_input,val_output):\n    data2 = {\n    \"all_characters\" : [],\n    \"char_num_map\" : {},\n    \"num_char_map\" : {},\n    \"source_charToNum\": torch.zeros(len(val_input),30, dtype=torch.int, device=device),\n    \"source_data\" : val_input,\n    \"all_characters_2\" : [],\n    \"char_num_map_2\" : {},\n    \"num_char_map_2\" : {},\n    \"val_charToNum\": torch.zeros(len(val_output),23, dtype=torch.int, device=device),\n    \"target_data\" : val_output,\n    \"source_len\" : 0,\n    \"target_len\" : 0\n }\n    k = 0 \n    l = 0\n    \n    m1 = data[\"char_num_map\"]\n    m2 = data[\"char_num_map_2\"]\n    \n    for i in range(0,len(val_input)):\n        val_input[i] = \"{\" + val_input[i] + \"}\"*(29-len(val_input[i]))\n        charToNum = []\n        for char in (val_input[i]):\n            index = 0\n            if(char not in data2[\"all_characters\"]):\n                data2[\"all_characters\"].append(char)\n                index = m1[char]\n                data2[\"char_num_map\"][char] = index\n                data2[\"num_char_map\"][index] = char\n            else:\n                index = m1[char]\n            \n            charToNum.append(index)\n            \n        my_tensor = torch.tensor(charToNum,device = device)\n        data2[\"source_charToNum\"][k] = my_tensor\n        \n        charToNum1 = []\n        val_output[i] = \"{\" + val_output[i] + \"}\"*(22-len(val_output[i]))\n        for char in (val_output[i]):\n            index = 0\n            if(char not in data2[\"all_characters_2\"]):\n                data2[\"all_characters_2\"].append(char)\n                index = m2[char]\n                data2[\"char_num_map_2\"][char] = index\n                data2[\"num_char_map_2\"][index] = char\n            else:\n                index = m2[char]\n                \n            charToNum1.append(index)\n            \n        my_tensor1 = torch.tensor(charToNum1,device = device)\n        data2[\"val_charToNum\"][k] = my_tensor1\n        \n        k+=1\n    \n    data2[\"source_len\"] = len(data2[\"all_characters\"])\n    data2[\"target_len\"] = len(data2[\"all_characters_2\"])\n        \n    return data2\n    \n    \ndata2 = pre_processing_validation(copy.copy(val_input),copy.copy(val_output))\n# print(data[\"all_characters\"])\n# print(data[\"char_num_map\"])\n# print(data[\"num_char_map\"])\n# print(data[\"all_characters_2\"])\n# print(data[\"char_num_map_2\"])\n# print(data[\"num_char_map_2\"])\nprint(data2[\"num_char_map\"])\nprint(data2[\"source_charToNum\"].shape)\n\nprint(data2[\"num_char_map_2\"])\nprint(data2['val_charToNum'][0])\n\n\nprint(val_input[0])\nprint(data2['source_len'])\nprint(data2['target_len'])\n","metadata":{"execution":{"iopub.status.busy":"2024-05-14T15:06:07.979591Z","iopub.execute_input":"2024-05-14T15:06:07.979892Z","iopub.status.idle":"2024-05-14T15:06:08.522992Z","shell.execute_reply.started":"2024-05-14T15:06:07.979868Z","shell.execute_reply":"2024-05-14T15:06:08.522007Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"{0: '{', 23: 'b', 20: 'h', 8: 'e', 10: 's', 15: 'm', 17: 'u', 12: 'd', 6: 'i', 7: 'n', 9: '}', 1: 'v', 22: 'y', 2: 'a', 21: 'k', 14: 'c', 11: 't', 3: 'r', 19: 'p', 5: 'l', 16: 'o', 4: 'g', 24: 'j', 18: 'w', 26: 'x', 13: 'f', 25: 'z', 27: 'q'}\ntorch.Size([4096, 30])\n{0: '{', 37: 'భ', 42: 'ీ', 32: 'ష', 3: '్', 18: 'మ', 24: 'ు', 29: 'డ', 7: 'ి', 8: 'న', 10: '}', 1: 'వ', 15: 'య', 5: 'ా', 11: 'స', 16: 'క', 27: 'చ', 12: 'త', 2: 'ర', 26: 'ం', 22: 'ప', 6: 'ల', 20: 'ూ', 49: 'థ', 33: 'ఆ', 35: 'శ', 40: 'హ', 19: 'ో', 4: 'గ', 41: 'జ', 13: 'ద', 34: 'ొ', 28: 'ై', 9: 'ే', 46: 'ఒ', 25: 'ె', 17: 'ట', 39: 'ణ', 43: 'ఇ', 38: 'ృ', 54: 'ఓ', 23: 'ధ', 45: 'ఐ', 47: 'ఎ', 36: 'అ', 44: 'బ', 52: 'ఏ', 14: 'ఫ', 31: 'ఉ', 30: 'ఖ', 21: 'ళ', 51: 'ఊ', 48: 'ౌ', 55: 'ఔ', 57: 'ఠ', 58: 'ఘ', 56: 'ఞ', 50: 'ఈ', 59: 'ఛ', 62: 'ఋ', 60: 'ః', 53: 'ఢ'}\ntensor([ 0, 37, 42, 32,  3, 18, 24, 29,  7,  8,  7, 10, 10, 10, 10, 10, 10, 10,\n        10, 10, 10, 10, 10], device='cuda:0', dtype=torch.int32)\nbheeshmudini\n28\n62\n","output_type":"stream"}]},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, x,y):\n        self.source = x\n        self.target = y\n    \n    def __len__(self):\n        return len(self.source)\n    \n    def __getitem__(self, idx):\n        source_data = self.source[idx]\n        target_data = self.target[idx]\n        return source_data, target_data","metadata":{"execution":{"iopub.status.busy":"2024-05-14T15:06:08.524218Z","iopub.execute_input":"2024-05-14T15:06:08.524571Z","iopub.status.idle":"2024-05-14T15:06:08.530273Z","shell.execute_reply.started":"2024-05-14T15:06:08.52454Z","shell.execute_reply":"2024-05-14T15:06:08.529326Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class MyDataset2(Dataset):\n    def __init__(self, x,y):\n        self.source = x\n        self.target = y\n    \n    def __len__(self):\n        return len(self.source)\n    \n    def __getitem__(self, idx):\n        source_data = self.source[idx]\n        target_data = self.target[idx]\n        return source_data, target_data","metadata":{"execution":{"iopub.status.busy":"2024-05-14T15:06:08.531625Z","iopub.execute_input":"2024-05-14T15:06:08.532058Z","iopub.status.idle":"2024-05-14T15:06:08.541397Z","shell.execute_reply.started":"2024-05-14T15:06:08.532004Z","shell.execute_reply":"2024-05-14T15:06:08.540714Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def validationAccuracy(encoder,decoder,batchsize,tf_ratio):\n    \n    dataLoader = dataLoaderFun(\"validation\",batchsize) # dataLoader depending on train or validation\n    \n    encoder.eval()\n    decoder.eval()\n    \n    validation_accuracy = 0\n    validation_loss = 0\n    \n    lossFunction = nn.NLLLoss()\n    \n    for batch_num, (source_batch, target_batch) in enumerate(dataLoader):\n        \n        encoder_initial_state = encoder.getInitialState() #hiddenlayers * BatchSize * Neurons\n        \n        encoder_output, encoder_current_state = encoder(source_batch,encoder_initial_state)\n        #print(encoder_output)\n        #success till here\n\n        loss = 0 # decoder starts form here\n        correct = 0\n\n        output_seq_len = target_batch.shape[1] # here you will get as name justified. 40\n\n        decoder_actual_output = []\n        #print(target_batch)\n\n        randNumber = random.random()\n\n        decoder_curr_state = encoder_current_state\n\n        for i in range(0,output_seq_len):\n\n            if(i == 0):\n                decoder_input_tensor = target_batch[:, i].reshape(batchsize,1) #32*1\n                #print(dec_input_tensor.shape)\n            else:\n                if randNumber < tf_ratio:\n                    decoder_input_tensor = target_batch[:, i].reshape(batchsize, 1) # current batch is passed\n                else:\n                    decoder_input_tensor = decoder_input_tensor.reshape(batchsize, 1) # prev result is passed\n\n            #print(curr_target_chars.shape) #32\n            decoder_output, decoder_curr_state = decoder(decoder_input_tensor,decoder_curr_state)\n            #print(decoder_output.shape) #(32*1*67) but your output is (32*1*65) becz ur output size is 65\n            topv, topi = decoder_output.topk(1)  # you will get top vales and their indices.\n            #print(\"topv\", topv)\n            decoder_input_tensor = topi.squeeze().detach()  # here whatever top softmax indeces are present but converted to 1 dimension\n            #print(decoder_input_tensor.shape)\n            decoder_actual_output.append(decoder_input_tensor) # softmax values are attached                    \n\n            decoder_output = decoder_output[:, -1, :] #it is just reduce the size from (32*1*67) to (32*67)\n            #print(decoder_output.shape,curr_target_chars.shape)\n            #print(decoder_output.shape,curr_target_chars.shape)\n\n            curr_target_chars = target_batch[:, i] #(32)\n            curr_target_chars = curr_target_chars.type(dtype=torch.long)\n            #print(curr_target_chars)\n\n            loss+=(lossFunction(decoder_output, curr_target_chars)) # you are passing 32*67 softmax values to curr_target_chars which has the 32*1\n\n        tensor_2d = torch.stack(decoder_actual_output)\n        decoder_actual_output = tensor_2d.t() #it is outside the for loop\n\n        validation_accuracy += (decoder_actual_output == target_batch).all(dim=1).sum().item() # it is simple just summing up the equal values\n        validation_loss += (loss.item()/output_seq_len)\n\n        if(batch_num%20 == 0):\n            print(\"bt:\", batch_num, \" loss:\", loss.item()/output_seq_len)\n        #'k'/24\n        # here you get the actual word letters seqeunces softamx indeces\n        #[[0,1,2],[0,1,2]] = [shr,ram] 32*40\n        #correct = (decoder_actual_output == target_batch).all(dim=1).sum().item()\n        #accuracy = accuracy + correct\n    \n    encoder.train()\n    decoder.train()\n    print(\"validation_accuracy\",validation_accuracy/40.96)\n    print(\"validation_loss\",validation_loss)\n#     wandb.log({'validation_accuracy':validation_accuracy/40.96})\n#     wandb.log({'validation_loss':validation_loss})","metadata":{"execution":{"iopub.status.busy":"2024-05-14T15:06:08.542511Z","iopub.execute_input":"2024-05-14T15:06:08.542845Z","iopub.status.idle":"2024-05-14T15:06:08.557527Z","shell.execute_reply.started":"2024-05-14T15:06:08.542811Z","shell.execute_reply":"2024-05-14T15:06:08.556593Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    \n    def __init__(self,inputDim,embSize,encoderLayers,hiddenLayerNuerons,cellType,batch_size):\n        super(Encoder, self).__init__()\n        self.embedding = nn.Embedding(inputDim, embSize)\n        self.encoderLayers = encoderLayers\n        self.hiddenLayerNuerons = hiddenLayerNuerons\n        self.batch_size = batch_size\n        \n        if(cellType=='GRU'):\n            self.rnn = nn.GRU(embSize,hiddenLayerNuerons,num_layers=encoderLayers, batch_first=True)\n        elif(cellType=='LSTM'):\n            self.rnn = nn.LSTM(embSize,hiddenLayerNuerons,num_layers=encoderLayers, batch_first=True)\n        else:\n            self.rnn = nn.RNN(embSize,hiddenLayerNuerons,num_layers=encoderLayers, batch_first=True)\n            \n    def forward(self, currentInput, prevState):\n        embdInput = self.embedding(currentInput)\n        output, prev_state = self.rnn(embdInput, prevState)\n        return output, prev_state\n    \n    def getInitialState(self):\n        return torch.zeros(self.encoderLayers,self.batch_size,self.hiddenLayerNuerons, device=device)\n    \nclass Decoder(nn.Module):\n    def __init__(self,outputDim,embSize,hiddenLayerNuerons,decoderLayers,cellType,dropout_p):\n        super(Decoder, self).__init__()\n        self.embedding = nn.Embedding(outputDim, embSize)\n        \n        if(cellType==\"GRU\"):\n            self.rnn = nn.GRU(embSize,hiddenLayerNuerons,num_layers=decoderLayers, batch_first=True)\n        elif(cellType==\"LSTM\"):\n            self.rnn = nn.LSTM(embSize,hiddenLayerNuerons,num_layers=decoderLayers, batch_first=True)\n        else:\n            self.rnn = nn.RNN(embSize,hiddenLayerNuerons,num_layers=decoderLayers, batch_first=True)\n            \n        self.fc = nn.Linear(hiddenLayerNuerons, outputDim) # it is useful for mapping the calculation to vocabularu\n        self.softmax = nn.LogSoftmax(dim=2) #output is in 3rd column \n        self.dropout = nn.Dropout(dropout_p)\n\n    def forward(self, current_input, prev_state):\n        embd_input = self.embedding(current_input)\n        curr_embd = F.relu(embd_input)\n        output, prev_state = self.rnn(curr_embd, prev_state)\n        output = self.dropout(output)\n        output = self.softmax(self.fc(output)) \n        return output, prev_state ","metadata":{"execution":{"iopub.status.busy":"2024-05-14T15:06:08.562314Z","iopub.execute_input":"2024-05-14T15:06:08.562699Z","iopub.status.idle":"2024-05-14T15:06:08.578107Z","shell.execute_reply.started":"2024-05-14T15:06:08.562673Z","shell.execute_reply":"2024-05-14T15:06:08.577263Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"print(6//2)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T15:06:08.579167Z","iopub.execute_input":"2024-05-14T15:06:08.579529Z","iopub.status.idle":"2024-05-14T15:06:08.594858Z","shell.execute_reply.started":"2024-05-14T15:06:08.579496Z","shell.execute_reply":"2024-05-14T15:06:08.59388Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"3\n","output_type":"stream"}]},{"cell_type":"code","source":"input_dim = data[\"source_len\"]\noutput_dim = data[\"target_len\"]\nchar_embd_dim=64\nhidden_layer_neurons = 512\nlearning_rate  =0.0001\nbatch_size = 64\nnumber_of_layers = 10\ntf_ratio = 0.2\nepochs = 50\ntrain(64,1,1,512,'GRU','Yes',0.4,20,32,1e-4,\"Adam\",0.2)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T15:14:59.515375Z","iopub.execute_input":"2024-05-14T15:14:59.516004Z","iopub.status.idle":"2024-05-14T15:15:32.689967Z","shell.execute_reply.started":"2024-05-14T15:14:59.515973Z","shell.execute_reply":"2024-05-14T15:15:32.688792Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"bt: 0  loss: 4.162725365680197\nbt: 200  loss: 1.7977855516516643\nbt: 400  loss: 1.6172750721807065\nbt: 600  loss: 1.6146344723908796\nbt: 800  loss: 1.5446684464164402\nbt: 1000  loss: 1.430673184602157\n1\ntensor([[ 0,  1,  5,  5,  3,  5,  5,  8,  7, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 36,  2,  3,  3, 24, 12, 24,  8, 19, 10, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 18,  7, 16, 24, 18, 19, 17,  7,  6,  7, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0,  8,  7,  2,  3,  3, 15,  8,  7,  8,  7, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 22, 22,  3, 26,  5, 12,  3, 12,  5,  8, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 36, 25,  3,  8,  3, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 22,  3,  2,  3, 24,  7, 16, 24,  3,  3, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0,  2,  5,  3,  5, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 22,  2,  3,  3,  2,  7, 26, 27, 16, 26,  8,  7, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 16,  5,  2,  3, 15, 16,  3,  5,  6, 10, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 27,  7,  2,  7, 26, 27, 24, 16, 19,  8,  8,  3,  8,  8, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 16, 24,  2,  7,  3,  7, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 18,  5,  3,  3,  6, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 44,  5,  3,  3, 24,  3, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 22,  2,  3,  3,  3,  3,  7, 24, 24,  8, 24, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 44,  3,  6,  3,  3,  3, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 18, 24, 26, 24,  6,  8,  5,  7,  7, 24,  8, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 11,  5,  3,  8, 26, 24, 24,  8, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0,  1,  7,  6, 24,  8, 24,  6,  3,  6, 10, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 16, 25,  3,  3,  3, 19, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 12,  7,  2, 16,  3, 24, 24,  6, 19,  8,  7, 24,  7, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 22,  3,  2,  5, 22, 16, 24,  8,  8,  3,  8,  7, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 36, 25,  3,  3,  3,  5,  8,  3, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 11,  7, 26,  3,  3,  3,  2, 24, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0,  4,  3,  2, 19,  2,  7,  5,  5, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 16,  5,  3,  8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 16,  6,  3,  7,  3,  5, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 36,  8,  3, 16,  3,  5,  8,  5,  8, 24, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 36,  7,  7,  3, 26, 27, 27,  5, 22,  7,  2,  3,  8, 16, 26, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 18, 25,  2, 24,  6,  8,  3,  8,  5, 10, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 16,  5, 15, 16,  3, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 36,  7,  6,  7, 27,  7,  7,  7, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10]], device='cuda:0')\ntensor([[ 0, 33, 16,  5, 29, 18, 42,  8,  7, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 36, 13,  3, 37, 24, 12, 18,  8, 19, 10, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0,  6, 34, 16, 19, 18, 19, 17,  7,  1,  3, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0,  8,  7,  2,  3, 37, 15,  8,  7, 23,  7, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 22, 35,  3, 27,  5, 12,  3, 12,  5, 22, 18,  9, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 47, 44, 19,  8, 42, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 22,  3,  2,  9, 18,  7, 16, 24, 39,  3, 39,  7, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0,  2,  5, 22,  5, 16,  9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 22,  2,  7,  4, 39,  7, 26, 27, 16, 26, 29,  7, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 16,  5,  2,  3, 15, 16,  3, 12,  6, 16, 24, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 27,  9, 15,  7, 26, 27, 24, 16, 19,  1, 27,  3, 27,  8,  9, 13,  7,\n         10, 10, 10, 10, 10],\n        [ 0,  4, 24,  2,  7, 16,  7, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 18,  5,  4,  3,  6,  7, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 44, 44,  3, 44, 24,  2, 24, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 22,  2,  7, 11,  3, 12,  7, 12, 24, 29, 24, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 44,  3,  6, 25,  2,  3, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 18, 24, 26, 29,  6,  8, 22,  3, 22, 24, 29, 24, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 11,  5,  4,  8, 26, 13, 24,  8,  9, 10, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0,  1, 25,  6, 24,  4, 24,  6,  3,  6, 10, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 16, 34, 11,  3, 12, 19, 15,  5, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 29, 15,  5, 16,  3, 15, 24,  6, 19, 41,  7, 11,  3, 17, 24,  6, 24,\n         10, 10, 10, 10, 10],\n        [ 0, 41,  3, 56,  5, 22, 16, 18, 34, 27,  3, 27,  7, 26, 13,  7, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 31, 13, 15,  3, 15,  5,  8,  3,  8,  9, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 11,  7, 26, 40, 35,  3,  2, 42, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0,  4,  3,  8, 19,  2,  7, 15,  5, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 15, 48,  1,  8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 16,  6,  3,  1,  2,  5,  6,  3, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0,  1, 25, 12, 16, 11,  5,  4,  5, 29, 24, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 36, 37,  7,  8, 26, 13,  8,  5, 22, 20,  2,  3,  1, 16, 26,  4,  5,\n          8,  9, 10, 10, 10],\n        [ 0, 54, 32, 23, 24,  6,  8,  3,  8, 42, 10, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0, 16,  5, 15, 16,  3, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10],\n        [ 0,  1, 34,  6,  7, 27,  9, 11,  7, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n         10, 10, 10, 10, 10]], device='cuda:0', dtype=torch.int32)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[28], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m tf_ratio \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m\n\u001b[1;32m      9\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGRU\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mYes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAdam\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[27], line 92\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(embSize, encoderLayers, decoderLayers, hiddenLayerNuerons, cellType, bidirection, dropout, epochs, batchsize, learningRate, optimizer, tf_ratio)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28mprint\u001b[39m(decoder_actual_output)\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28mprint\u001b[39m(target_batch)\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mk\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m24\u001b[39;49m\n\u001b[1;32m     93\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (loss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;241m/\u001b[39moutput_seq_len)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(batch_num\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n","\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'int'"],"ename":"TypeError","evalue":"unsupported operand type(s) for /: 'str' and 'int'","output_type":"error"}]},{"cell_type":"code","source":"data = pre_processing(copy.copy(train_input),copy.copy(train_output))","metadata":{"execution":{"iopub.status.busy":"2024-05-14T15:06:08.606636Z","iopub.execute_input":"2024-05-14T15:06:08.606916Z","iopub.status.idle":"2024-05-14T15:06:16.327459Z","shell.execute_reply.started":"2024-05-14T15:06:08.606894Z","shell.execute_reply":"2024-05-14T15:06:16.326385Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def dataLoaderFun(dataName,batch_size):\n    if(dataName == 'train'):\n        dataset = MyDataset(data[\"source_charToNum\"],data['val_charToNum'])\n        return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n    else:\n        dataset = MyDataset(data2[\"source_charToNum\"],data2['val_charToNum'])\n        return  DataLoader(dataset, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T15:06:16.32862Z","iopub.execute_input":"2024-05-14T15:06:16.328904Z","iopub.status.idle":"2024-05-14T15:06:16.334611Z","shell.execute_reply.started":"2024-05-14T15:06:16.328881Z","shell.execute_reply":"2024-05-14T15:06:16.333667Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def train(embSize,encoderLayers,decoderLayers,hiddenLayerNuerons,cellType,bidirection,dropout,epochs,batchsize,learningRate,optimizer,tf_ratio):\n    #add optimizer,tf_ratio to wandb parameters\n    \n    dataLoader = dataLoaderFun(\"train\",batchsize) # dataLoader depending on train or validation\n    \n    \n    encoder = Encoder(data[\"source_len\"],embSize,encoderLayers,hiddenLayerNuerons,cellType,batchsize).to(device)\n    decoder = Decoder(data[\"target_len\"],embSize,hiddenLayerNuerons,encoderLayers,cellType,dropout).to(device)\n    \n    # done till here\n    if(optimizer == 'Adam'):\n        encoderOptimizer = optim.Adam(encoder.parameters(), lr=learningRate)\n        decoderOptimizer = optim.Adam(decoder.parameters(), lr=learningRate)\n    else:\n        encoderOptimizer = optim.NAdam(encoder.parameters(), lr=learningRate)\n        decoderOptimizer = optim.NAdam(decoder.parameters(), lr=learningRate)\n    \n    lossFunction = nn.NLLLoss()\n\n    for epoch in range (0,epochs):\n    \n        train_accuracy = 0 \n        train_loss = 0 \n\n        for batch_num, (source_batch, target_batch) in enumerate(dataLoader):\n                        \n            encoder_initial_state = encoder.getInitialState() #hiddenlayers * BatchSize * Neurons\n            \n            if(bidirection == \"Yes\"):\n                reversed_batch = torch.flip(source_batch, dims=[1]) # reverse the batch across rows.\n                source_batch = (source_batch + reversed_batch)//2 # adding reversed data to source data by averaging\n                \n            encoder_output, encoder_current_state = encoder(source_batch,encoder_initial_state)\n            \n            #print(encoder_output)\n            #success till here3\n            \n            \n            loss = 0 # decoder starts form here\n            correct = 0\n            \n            output_seq_len = target_batch.shape[1] # here you will get as name justified. 40\n\n            decoder_actual_output = []\n            #print(target_batch)\n            \n            randNumber = random.random()\n\n            decoder_curr_state = encoder_current_state\n\n            for i in range(0,output_seq_len):\n                \n                if(i == 0):\n                    decoder_input_tensor = target_batch[:, i].reshape(batchsize,1) #32*1\n                    #print(dec_input_tensor.shape)\n                else:\n                    if randNumber < tf_ratio:\n                        decoder_input_tensor = target_batch[:, i].reshape(batchsize, 1) # current batch is passed\n                    else:\n                        decoder_input_tensor = decoder_input_tensor.reshape(batchsize, 1) # prev result is passed\n\n                #print(curr_target_chars.shape) #32\n                decoder_output, decoder_curr_state = decoder(decoder_input_tensor,decoder_curr_state)\n                #print(decoder_output.shape) #(32*1*67) but your output is (32*1*65) becz ur output size is 65\n                topv, topi = decoder_output.topk(1)  # you will get top vales and their indices.\n                #print(\"topv\", topv)\n                decoder_input_tensor = topi.squeeze().detach()  # here whatever top softmax indeces are present but converted to 1 dimension\n                #print(decoder_input_tensor.shape)\n                decoder_actual_output.append(decoder_input_tensor) # softmax values are attached                    \n                        \n                decoder_output = decoder_output[:, -1, :] #it is just reduce the size from (32*1*67) to (32*67)\n                #print(decoder_output.shape,curr_target_chars.shape)\n                #print(decoder_output.shape,curr_target_chars.shape)\n\n                curr_target_chars = target_batch[:, i] #(32)\n                curr_target_chars = curr_target_chars.type(dtype=torch.long)\n                #print(curr_target_chars)\n                \n                loss+=(lossFunction(decoder_output, curr_target_chars)) # you are passing 32*67 softmax values to curr_target_chars which has the 32*1\n                \n            tensor_2d = torch.stack(decoder_actual_output)\n            decoder_actual_output = tensor_2d.t() #it is outside the for loop\n            #print(decoder_actual_output) #32*40\n            if(batch_num == 0 and epoch == epochs-1):\n                numToCharConverter(target_batch,decoder_actual_output,data) \n                \n            train_accuracy += (decoder_actual_output == target_batch).all(dim=1).sum().item() # it is simple just summing up the equal values\n            if(train_accuracy>0):\n                print(train_accuracy)\n                print(decoder_actual_output)\n                print(target_batch)\n                'k'/24\n            train_loss += (loss.item()/output_seq_len)\n            \n            if(batch_num%200 == 0):\n                print(\"bt:\", batch_num, \" loss:\", loss.item()/output_seq_len)\n            #'k'/24\n            # here you get the actual word letters seqeunces softamx indeces\n            #[[0,1,2],[0,1,2]] = [shr,ram] 32*40\n            #correct = (decoder_actual_output == target_batch).all(dim=1).sum().item()\n            #accuracy = accuracy + correct\n            encoderOptimizer.zero_grad()\n            decoderOptimizer.zero_grad()\n            loss.backward()\n            encoderOptimizer.step()\n            decoderOptimizer.step()\n            \n        print(\"train_accuracy\",train_accuracy/512)\n        print(\"train_loss\",train_loss)\n#         wandb.log({'train_accuracy':train_accuracy/512})\n#         wandb.log({'train_loss':train_loss})\n        validationAccuracy(encoder,decoder,batchsize,tf_ratio)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T15:14:53.707182Z","iopub.execute_input":"2024-05-14T15:14:53.707619Z","iopub.status.idle":"2024-05-14T15:14:53.729046Z","shell.execute_reply.started":"2024-05-14T15:14:53.707589Z","shell.execute_reply":"2024-05-14T15:14:53.728081Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"\n\n\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n    \n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def numToCharConverter(inputArray,outputArray,data):\n    mp = data['num_char_map_2']\n    t1 = ''\n    t2 = ''\n    for row1, row2 in zip(inputArray,outputArray):\n        t1=''\n        t2=''\n        for e1, e2 in zip(row1,row2):\n            t1+=mp[e1.item()]\n            t2+=mp[e2.item()]\n        print(t1,\" \",t2)\n            \n        \n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-14T15:06:16.35833Z","iopub.execute_input":"2024-05-14T15:06:16.358606Z","iopub.status.idle":"2024-05-14T15:06:16.373197Z","shell.execute_reply.started":"2024-05-14T15:06:16.358583Z","shell.execute_reply":"2024-05-14T15:06:16.372359Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def main_fun():\n#     wandb.init(project ='vanillaRNN')\n#     params = wandb.config\n#     with wandb.init(project = 'vanillaRNN', name='embedding'+str(params.embSize)+'cellType'+params.cellType+'batchSize'+str(params.batchsize)) as run:\n#         train(params.embSize,params.encoderLayers,params.decoderLayers,params.hiddenLayerNuerons,params.cellType,params.bidirection,params.dropout,params.epochs,params.batchsize,params.learningRate,params.optimizer,params.tf_ratio)\n    \n# sweep_params = {\n#     'method' : 'bayes',\n#     'name'   : 'DeepLearningAssignment3',\n#     'metric' : {\n#         'goal' : 'maximize',\n#         'name' : 'validation_accuracy',\n#     },\n#     'parameters' : {\n#         'embSize':{'values':[16,32,64]},\n#         'encoderLayers':{'values':[1,5,10]},\n#         'decoderLayers' : {'values' : [1,5,10]},\n#         'hiddenLayerNuerons'   : {'values' : [64,256,512]},\n#         'cellType' : {'values' : ['GRU'] } ,\n#         'bidirection' : {'values' : ['No','Yes']},\n#         'dropout' : {'values' : [0,0.2,0.3]},\n#         'epochs'  : {'values': [10,20,30]},\n#         'batchsize' : {'values' : [32,64]},\n#         'learningRate' : {'values' : [1e-2,1e-3,1e-4]},\n#         'optimizer':{'values' : ['Adam','Nadam']},\n#         'tf_ratio' :{'values' : [0.2,0.4,0.5]}\n#     }\n# }\n# sweepId = wandb.sweep(sweep_params,project = 'vanillaRNN')\n# wandb.agent(sweepId,function =main_fun,count = 2)\n# wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-05-14T15:06:16.374568Z","iopub.execute_input":"2024-05-14T15:06:16.375176Z","iopub.status.idle":"2024-05-14T15:06:16.385285Z","shell.execute_reply.started":"2024-05-14T15:06:16.375141Z","shell.execute_reply":"2024-05-14T15:06:16.384479Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"\ntrain(data)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T15:06:16.386505Z","iopub.execute_input":"2024-05-14T15:06:16.386867Z","iopub.status.idle":"2024-05-14T15:06:16.666234Z","shell.execute_reply.started":"2024-05-14T15:06:16.386835Z","shell.execute_reply":"2024-05-14T15:06:16.664957Z"},"trusted":true},"execution_count":21,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mTypeError\u001b[0m: train() missing 11 required positional arguments: 'encoderLayers', 'decoderLayers', 'hiddenLayerNuerons', 'cellType', 'bidirection', 'dropout', 'epochs', 'batchsize', 'learningRate', 'optimizer', and 'tf_ratio'"],"ename":"TypeError","evalue":"train() missing 11 required positional arguments: 'encoderLayers', 'decoderLayers', 'hiddenLayerNuerons', 'cellType', 'bidirection', 'dropout', 'epochs', 'batchsize', 'learningRate', 'optimizer', and 'tf_ratio'","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}