{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8273608,"sourceType":"datasetVersion","datasetId":4912633},{"sourceId":8400322,"sourceType":"datasetVersion","datasetId":4998024}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport pandas as pd\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport copy\nfrom torch.utils.data import Dataset, DataLoader\nimport random","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-16T02:58:26.413888Z","iopub.execute_input":"2024-05-16T02:58:26.414276Z","iopub.status.idle":"2024-05-16T02:58:26.420510Z","shell.execute_reply.started":"2024-05-16T02:58:26.414248Z","shell.execute_reply":"2024-05-16T02:58:26.419227Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!pip install wandb\nimport wandb\nfrom wandb.keras import WandbCallback\nimport socket\nsocket.setdefaulttimeout(30)\nwandb.login()\nwandb.init(project ='AttentionRNN')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:58:29.728773Z","iopub.execute_input":"2024-05-16T02:58:29.729595Z","iopub.status.idle":"2024-05-16T02:58:29.735638Z","shell.execute_reply.started":"2024-05-16T02:58:29.729549Z","shell.execute_reply":"2024-05-16T02:58:29.734565Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"cpu\n","output_type":"stream"}]},{"cell_type":"code","source":"train_csv = \"/kaggle/input/telugu/tel/tel_train.csv\"\ntest_csv = \"/kaggle/input/telugu/tel/tel_test.csv\"\nval_csv = \"/kaggle/input/telugu/tel/tel_valid.csv\"","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:58:31.612835Z","iopub.execute_input":"2024-05-16T02:58:31.613404Z","iopub.status.idle":"2024-05-16T02:58:31.623497Z","shell.execute_reply.started":"2024-05-16T02:58:31.613365Z","shell.execute_reply":"2024-05-16T02:58:31.621021Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv(train_csv, header=None)\ntrain_input = train_data[0].to_numpy()\ntrain_output = train_data[1].to_numpy()\nval_data = pd.read_csv(val_csv,header = None)\nval_input = val_data[0].to_numpy()\nval_output = val_data[1].to_numpy()\ntest_data = pd.read_csv(test_csv,header= None)\nprint(len(train_input))\nprint(len(train_output))\nprint(len(val_input))\nprint(len(test_data))\nprint(val_input)\nprint(val_output)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:58:34.197841Z","iopub.execute_input":"2024-05-16T02:58:34.198296Z","iopub.status.idle":"2024-05-16T02:58:34.490217Z","shell.execute_reply.started":"2024-05-16T02:58:34.198256Z","shell.execute_reply":"2024-05-16T02:58:34.489108Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"51200\n51200\n4096\n4096\n['bheeshmudini' 'vinyasaanni' 'kaavachhunu' ... 'asramam' 'divine' 'dis']\n['భీష్ముడిని' 'విన్యాసాన్ని' 'కావచ్చును' ... 'ఆశ్రమం' 'డివైన్' 'డిస్']\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train_output[0][5]) #the size of input and output is 4096\nmaxi = 0\nt =''\nfor x in val_input:\n    maxi = max(maxi,len(x))\n    if(maxi == len(x)):\n        t=x\n        \nprint(maxi,t)\nt =''\nmaxi =0 \nfor x in val_output:\n    maxi = max(maxi,len(x))\n    if(maxi == len(x)):\n        t=x\n        \nprint(maxi,t)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:58:37.046804Z","iopub.execute_input":"2024-05-16T02:58:37.047437Z","iopub.status.idle":"2024-05-16T02:58:37.061684Z","shell.execute_reply.started":"2024-05-16T02:58:37.047404Z","shell.execute_reply":"2024-05-16T02:58:37.060351Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"ల\n28 paramaanandabharithudayyaadu\n19 పరమానందభరితుడయ్యాడు\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndef pre_processing(train_input,train_output):\n    data = {\n    \"all_characters\" : [],\n    \"char_num_map\" : {},\n    \"num_char_map\" : {},\n    \"source_charToNum\": torch.zeros(len(train_input),30, dtype=torch.int, device=device),\n    \"source_data\" : train_input,\n        \n    \"all_characters_2\" : [],\n    \"char_num_map_2\" : {},\n    \"num_char_map_2\" : {},\n    \"val_charToNum\": torch.zeros(len(train_output),23, dtype=torch.int, device=device),\n    \"target_data\" : train_output,\n    \"source_len\" : 0,\n    \"target_len\" : 0\n }\n    k = 0 \n    l = 0\n    for i in range(0,len(train_input)):\n        train_input[i] = \"{\" + train_input[i] + \"}\"*(29-len(train_input[i]))\n        charToNum = []\n        for char in (train_input[i]):\n            index = 0\n            if(char not in data[\"all_characters\"]):\n                data[\"all_characters\"].append(char)\n                index = data[\"all_characters\"].index(char)\n                data[\"char_num_map\"][char] = index\n                data[\"num_char_map\"][index] = char\n            else:\n                index = data[\"all_characters\"].index(char)\n            \n            charToNum.append(index)\n            \n        my_tensor = torch.tensor(charToNum,device = device)\n        data[\"source_charToNum\"][k] = my_tensor\n        \n        charToNum1 = []\n        \n        train_output[i] = \"{\" + train_output[i] + \"}\"*(22-len(train_output[i]))\n        for char in (train_output[i]):\n            index = 0\n            if(char not in data[\"all_characters_2\"]):\n                data[\"all_characters_2\"].append(char)\n                index = data[\"all_characters_2\"].index(char)\n                data[\"char_num_map_2\"][char] = index\n                data[\"num_char_map_2\"][index] = char\n            else:\n                index = data[\"all_characters_2\"].index(char)\n                \n            charToNum1.append(index)\n            \n        my_tensor1 = torch.tensor(charToNum1,device = device)\n        data[\"val_charToNum\"][k] = my_tensor1\n        \n        k+=1\n    \n    data[\"source_len\"] = len(data[\"all_characters\"])\n    data[\"target_len\"] = len(data[\"all_characters_2\"])\n        \n    return data\n    \n    \ndata = pre_processing(copy.copy(train_input),copy.copy(train_output))\n# print(data[\"all_characters\"])\n# print(data[\"char_num_map\"])\n# print(data[\"num_char_map\"])\n# print(data[\"all_characters_2\"])\n# print(data[\"char_num_map_2\"])\n# print(data[\"num_char_map_2\"])\nprint(data[\"source_charToNum\"])\nprint(data['val_charToNum'])\nprint(data[\"num_char_map_2\"])\nprint(data[\"num_char_map\"])\nprint(train_input[0])\nprint(data['source_len'])\nprint(data['target_len'])\n","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:58:40.015253Z","iopub.execute_input":"2024-05-16T02:58:40.016385Z","iopub.status.idle":"2024-05-16T02:58:45.449196Z","shell.execute_reply.started":"2024-05-16T02:58:40.016347Z","shell.execute_reply":"2024-05-16T02:58:45.447769Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"tensor([[ 0,  1,  2,  ...,  9,  9,  9],\n        [ 0,  1,  2,  ...,  9,  9,  9],\n        [ 0, 13,  2,  ...,  9,  9,  9],\n        ...,\n        [ 0,  1,  8,  ...,  9,  9,  9],\n        [ 0,  3, 16,  ...,  9,  9,  9],\n        [ 0, 14, 20,  ...,  9,  9,  9]], dtype=torch.int32)\ntensor([[ 0,  1,  2,  ..., 10, 10, 10],\n        [ 0,  1, 11,  ..., 10, 10, 10],\n        [ 0, 14,  3,  ..., 10, 10, 10],\n        ...,\n        [ 0,  1, 25,  ..., 10, 10, 10],\n        [ 0,  2, 20,  ..., 10, 10, 10],\n        [ 0, 27, 25,  ..., 10, 10, 10]], dtype=torch.int32)\n{0: '{', 1: 'వ', 2: 'ర', 3: '్', 4: 'గ', 5: 'ా', 6: 'ల', 7: 'ి', 8: 'న', 9: 'ే', 10: '}', 11: 'స', 12: 'త', 13: 'ద', 14: 'ఫ', 15: 'య', 16: 'క', 17: 'ట', 18: 'మ', 19: 'ో', 20: 'ూ', 21: 'ళ', 22: 'ప', 23: 'ధ', 24: 'ు', 25: 'ె', 26: 'ం', 27: 'చ', 28: 'ై', 29: 'డ', 30: 'ఖ', 31: 'ఉ', 32: 'ష', 33: 'ఆ', 34: 'ొ', 35: 'శ', 36: 'అ', 37: 'భ', 38: 'ృ', 39: 'ణ', 40: 'హ', 41: 'జ', 42: 'ీ', 43: 'ఇ', 44: 'బ', 45: 'ఐ', 46: 'ఒ', 47: 'ఎ', 48: 'ౌ', 49: 'థ', 50: 'ఈ', 51: 'ఊ', 52: 'ఏ', 53: 'ఢ', 54: 'ఓ', 55: 'ఔ', 56: 'ఞ', 57: 'ఠ', 58: 'ఘ', 59: 'ఛ', 60: 'ః', 61: 'ఝ', 62: 'ఋ', 63: 'ఱ'}\n{0: '{', 1: 'v', 2: 'a', 3: 'r', 4: 'g', 5: 'l', 6: 'i', 7: 'n', 8: 'e', 9: '}', 10: 's', 11: 't', 12: 'd', 13: 'f', 14: 'c', 15: 'm', 16: 'o', 17: 'u', 18: 'w', 19: 'p', 20: 'h', 21: 'k', 22: 'y', 23: 'b', 24: 'j', 25: 'z', 26: 'x', 27: 'q'}\nvargaalavaarine\n28\n64\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndef pre_processing_validation(val_input,val_output):\n    data2 = {\n    \"all_characters\" : [],\n    \"char_num_map\" : {},\n    \"num_char_map\" : {},\n    \"source_charToNum\": torch.zeros(len(val_input),30, dtype=torch.int, device=device),\n    \"source_data\" : val_input,\n    \"all_characters_2\" : [],\n    \"char_num_map_2\" : {},\n    \"num_char_map_2\" : {},\n    \"val_charToNum\": torch.zeros(len(val_output),23, dtype=torch.int, device=device),\n    \"target_data\" : val_output,\n    \"source_len\" : 0,\n    \"target_len\" : 0\n }\n    k = 0 \n    l = 0\n    \n    m1 = data[\"char_num_map\"]\n    m2 = data[\"char_num_map_2\"]\n    \n    for i in range(0,len(val_input)):\n        val_input[i] = \"{\" + val_input[i] + \"}\"*(29-len(val_input[i]))\n        charToNum = []\n        for char in (val_input[i]):\n            index = 0\n            if(char not in data2[\"all_characters\"]):\n                data2[\"all_characters\"].append(char)\n                index = m1[char]\n                data2[\"char_num_map\"][char] = index\n                data2[\"num_char_map\"][index] = char\n            else:\n                index = m1[char]\n            \n            charToNum.append(index)\n            \n        my_tensor = torch.tensor(charToNum,device = device)\n        data2[\"source_charToNum\"][k] = my_tensor\n        \n        charToNum1 = []\n        val_output[i] = \"{\" + val_output[i] + \"}\"*(22-len(val_output[i]))\n        for char in (val_output[i]):\n            index = 0\n            if(char not in data2[\"all_characters_2\"]):\n                data2[\"all_characters_2\"].append(char)\n                index = m2[char]\n                data2[\"char_num_map_2\"][char] = index\n                data2[\"num_char_map_2\"][index] = char\n            else:\n                index = m2[char]\n                \n            charToNum1.append(index)\n            \n        my_tensor1 = torch.tensor(charToNum1,device = device)\n        data2[\"val_charToNum\"][k] = my_tensor1\n        \n        k+=1\n    \n    data2[\"source_len\"] = len(data2[\"all_characters\"])\n    data2[\"target_len\"] = len(data2[\"all_characters_2\"])\n        \n    return data2\n    \n    \ndata2 = pre_processing_validation(copy.copy(val_input),copy.copy(val_output))\n# print(data[\"all_characters\"])\n# print(data[\"char_num_map\"])\n# print(data[\"num_char_map\"])\n# print(data[\"all_characters_2\"])\n# print(data[\"char_num_map_2\"])\n# print(data[\"num_char_map_2\"])\nprint(data2[\"num_char_map\"])\nprint(data2[\"source_charToNum\"].shape)\n\nprint(data2[\"num_char_map_2\"])\nprint(data2['val_charToNum'][0])\n\n\nprint(val_input[0])\nprint(data2['source_len'])\nprint(data2['target_len'])\n","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:58:45.451628Z","iopub.execute_input":"2024-05-16T02:58:45.452107Z","iopub.status.idle":"2024-05-16T02:58:45.811964Z","shell.execute_reply.started":"2024-05-16T02:58:45.452067Z","shell.execute_reply":"2024-05-16T02:58:45.810672Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"{0: '{', 23: 'b', 20: 'h', 8: 'e', 10: 's', 15: 'm', 17: 'u', 12: 'd', 6: 'i', 7: 'n', 9: '}', 1: 'v', 22: 'y', 2: 'a', 21: 'k', 14: 'c', 11: 't', 3: 'r', 19: 'p', 5: 'l', 16: 'o', 4: 'g', 24: 'j', 18: 'w', 26: 'x', 13: 'f', 25: 'z', 27: 'q'}\ntorch.Size([4096, 30])\n{0: '{', 37: 'భ', 42: 'ీ', 32: 'ష', 3: '్', 18: 'మ', 24: 'ు', 29: 'డ', 7: 'ి', 8: 'న', 10: '}', 1: 'వ', 15: 'య', 5: 'ా', 11: 'స', 16: 'క', 27: 'చ', 12: 'త', 2: 'ర', 26: 'ం', 22: 'ప', 6: 'ల', 20: 'ూ', 49: 'థ', 33: 'ఆ', 35: 'శ', 40: 'హ', 19: 'ో', 4: 'గ', 41: 'జ', 13: 'ద', 34: 'ొ', 28: 'ై', 9: 'ే', 46: 'ఒ', 25: 'ె', 17: 'ట', 39: 'ణ', 43: 'ఇ', 38: 'ృ', 54: 'ఓ', 23: 'ధ', 45: 'ఐ', 47: 'ఎ', 36: 'అ', 44: 'బ', 52: 'ఏ', 14: 'ఫ', 31: 'ఉ', 30: 'ఖ', 21: 'ళ', 51: 'ఊ', 48: 'ౌ', 55: 'ఔ', 57: 'ఠ', 58: 'ఘ', 56: 'ఞ', 50: 'ఈ', 59: 'ఛ', 62: 'ఋ', 60: 'ః', 53: 'ఢ'}\ntensor([ 0, 37, 42, 32,  3, 18, 24, 29,  7,  8,  7, 10, 10, 10, 10, 10, 10, 10,\n        10, 10, 10, 10, 10], dtype=torch.int32)\nbheeshmudini\n28\n62\n","output_type":"stream"}]},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, x,y):\n        self.source = x\n        self.target = y\n    \n    def __len__(self):\n        return len(self.source)\n    \n    def __getitem__(self, idx):\n        source_data = self.source[idx]\n        target_data = self.target[idx]\n        return source_data, target_data","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:58:51.452218Z","iopub.execute_input":"2024-05-16T02:58:51.452635Z","iopub.status.idle":"2024-05-16T02:58:51.459401Z","shell.execute_reply.started":"2024-05-16T02:58:51.452604Z","shell.execute_reply":"2024-05-16T02:58:51.458128Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class MyDataset2(Dataset):\n    def __init__(self, x,y):\n        self.source = x\n        self.target = y\n    \n    def __len__(self):\n        return len(self.source)\n    \n    def __getitem__(self, idx):\n        source_data = self.source[idx]\n        target_data = self.target[idx]\n        return source_data, target_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def validationAccuracy(encoder,decoder,batchsize,tf_ratio,cellType,bidirection):\n    \n    dataLoader = dataLoaderFun(\"validation\",batchsize) # dataLoader depending on train or validation\n    \n    encoder.eval()\n    decoder.eval()\n    \n    validation_accuracy = 0\n    validation_loss = 0\n    \n    lossFunction = nn.NLLLoss()\n    \n    for batch_num, (source_batch, target_batch) in enumerate(dataLoader):\n        \n        encoder_initial_state = encoder.getInitialState() #hiddenlayers * BatchSize * Neurons\n            \n        if(bidirection == \"Yes\"):\n            reversed_batch = torch.flip(source_batch, dims=[1]) # reverse the batch across rows.\n            source_batch = (source_batch + reversed_batch)//2 # adding reversed data to source data by averaging\n\n        if(cellType == 'LSTM'):\n            encoder_initial_state = (encoder_initial_state, encoder.getInitialState())\n\n        encoder_states = encoder(source_batch,encoder_initial_state)\n\n        decoder_current_state = encoder_states[-1, :, :, :] # this selects the last state from encoder states\n\n        encoder_final_layer_states = encoder_states[:, -1, :, :]\n\n        loss = 0 # decoder starts\n            \n        output_seq_len = target_batch.shape[1] # here you will get as name justified. 40\n        attentions = []\n        decoder_actual_output = []\n        #print(target_batch)\n\n        randNumber = random.random()\n\n\n        for i in range(0,output_seq_len):\n            \n            if(i == 0):\n                decoder_current_input = torch.full((batchsize,1),0, device=device)\n                #decoder_input_tensor = target_batch[:, i].reshape(batchsize,1) #32*1\n                #print(dec_input_tensor.shape)\n            else:\n                if randNumber < tf_ratio:\n                    decoder_current_input = target_batch[:, i].reshape(batchsize, 1)\n                    #decoder_input_tensor = target_batch[:, i].reshape(batchsize, 1) # current batch is passed\n                else:\n                    decoder_current_input = decoder_current_input.reshape(batchsize, 1)\n                    #decoder_input_tensor = decoder_input_tensor.reshape(batchsize, 1) # prev result is passed\n\n            decoder_output, decoder_current_state, attn_weights = decoder(decoder_current_input, decoder_current_state, encoder_final_layer_states)\n\n            attentions.append(attn_weights)\n            topv, topi = decoder_output.topk(1)\n            decoder_current_input = topi.squeeze().detach()\n            decoder_actual_output.append(decoder_current_input)\n            decoder_output = decoder_output[:, -1, :]\n            curr_target_chars = target_batch[:, i] #(32)\n            curr_target_chars = curr_target_chars.type(dtype=torch.long)\n            loss+=(lossFunction(decoder_output, curr_target_chars))\n\n            # tensor_2d = torch.stack(decoder_actual_output)\n            # decoder_actual_output = tensor_2d.t() #it is outside the for loop\n            # #print(decoder_actual_output) #32*40\n            # if(batch_num == 0 and epoch == epochs-1):\n            #     numToCharConverter(target_batch,decoder_actual_output,data) \n                \n            # train_accuracy += (decoder_actual_output == target_batch).all(dim=1).sum().item() # it is simple just summing up the equal values\n\n        validation_loss += (loss.item()/output_seq_len)\n        \n        decoder_actual_output = torch.cat(decoder_actual_output,dim=0).reshape(output_seq_len,batchsize).transpose(0,1)\n        \n        validation_accuracy += (decoder_actual_output == target_batch).all(dim=1).sum().item()\n        \n        if(batch_num%40 == 0):\n            print(\"bt:\", batch_num, \" loss:\", loss.item()/output_seq_len)\n            #'k'/24\n            # here you get the actual word letters seqeunces softamx indeces\n            #[[0,1,2],[0,1,2]] = [shr,ram] 32*40\n            #correct = (decoder_actual_output == target_batch).all(dim=1).sum().item()\n            #accuracy = accuracy + correct           \n    encoder.train()\n    decoder.train()\n    print(\"validation_accuracy\",validation_accuracy/40.96)\n    print(\"validation_loss\",validation_loss)\n    wandb.log({'validation_accuracy':validation_accuracy/40.96})\n    wandb.log({'validation_loss':validation_loss})","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:58:58.551038Z","iopub.execute_input":"2024-05-16T02:58:58.553691Z","iopub.status.idle":"2024-05-16T02:58:58.573275Z","shell.execute_reply.started":"2024-05-16T02:58:58.553637Z","shell.execute_reply":"2024-05-16T02:58:58.572180Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class Attention(nn.Module):\n    def __init__(self, hidden_size):\n        super(Attention, self).__init__()\n        self.Wa = nn.Linear(hidden_size, hidden_size)\n        self.Ua = nn.Linear(hidden_size, hidden_size)\n        self.Va = nn.Linear(hidden_size, 1)\n\n    def forward(self, query, keys):\n        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n        scores = scores.squeeze().unsqueeze(1)\n        weights = F.softmax(scores, dim=0)\n        weights = weights.permute(2,1,0)\n        keys = keys.permute(1,0,2)\n        context = torch.bmm(weights, keys)\n        return context, weights","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:59:02.350464Z","iopub.execute_input":"2024-05-16T02:59:02.350906Z","iopub.status.idle":"2024-05-16T02:59:02.360481Z","shell.execute_reply.started":"2024-05-16T02:59:02.350867Z","shell.execute_reply":"2024-05-16T02:59:02.359237Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    \n    def __init__(self,inputDim,embSize,encoderLayers,hiddenLayerNuerons,cellType,batch_size):\n        super(Encoder, self).__init__()\n        self.embedding = nn.Embedding(inputDim, embSize)\n        self.encoderLayers = encoderLayers\n        self.hiddenLayerNuerons = hiddenLayerNuerons\n        self.batch_size = batch_size\n        self.cellType = cellType\n        if(cellType=='GRU'):\n            self.rnn = nn.GRU(embSize,hiddenLayerNuerons,num_layers=encoderLayers, batch_first=True)\n        elif(cellType=='RNN'):\n            self.rnn = nn.RNN(embSize,hiddenLayerNuerons,num_layers=encoderLayers, batch_first=True)\n        else:\n            self.rnn = nn.LSTM(embSize,hiddenLayerNuerons,num_layers=encoderLayers, batch_first=True)\n\n    def forward(self,sourceBatch,encoderCurrState):\n        sequenceLength = len(sourceBatch[0])\n        encoderStates = torch.zeros(sequenceLength,self.encoderLayers,self.batch_size,self.hiddenLayerNuerons,device=device)\n        for i in range(0,sequenceLength):\n            currInput = sourceBatch[:,i].reshape(self.batch_size,1)\n            dummy , encoderCurrState = self.statesCalculation(currInput,encoderCurrState)\n            if(self.cellType == 'LSTM'):\n                encoderStates[i] = encoderCurrState[1]\n            else:\n                encoderStates[i] = encoderCurrState\n            \n        return encoderStates,encoderCurrState\n\n\n    def statesCalculation(self, currentInput, prevState):\n        embdInput = self.embedding(currentInput)\n        output, prev_state = self.rnn(embdInput, prevState)\n        return output, prev_state\n    \n    def getInitialState(self):\n        return torch.zeros(self.encoderLayers,self.batch_size,self.hiddenLayerNuerons, device=device)\n    \nclass Decoder(nn.Module):\n    def __init__(self,outputDim,embSize,hiddenLayerNuerons,decoderLayers,cellType,dropout_p):\n        super(Decoder, self).__init__()\n        self.embedding = nn.Embedding(outputDim, embSize)\n        self.cellType = cellType\n                \n        if(cellType == 'GRU'): # changed here\n            self.rnn = nn.GRU(embSize+hiddenLayerNuerons,hiddenLayerNuerons,num_layers=decoderLayers, batch_first=True)\n        elif(cellType == 'RNN'):\n            self.rnn = nn.RNN(embSize+hiddenLayerNuerons,hiddenLayerNuerons,num_layers=decoderLayers, batch_first=True)\n        else:\n            self.rnn = nn.LSTM(embSize+hiddenLayerNuerons,hiddenLayerNuerons,num_layers=decoderLayers, batch_first=True)\n            \n        self.fc = nn.Linear(hiddenLayerNuerons, outputDim) # it is useful for mapping the calculation to vocabularu\n        self.softmax = nn.LogSoftmax(dim=2) #output is in 3rd column \n        self.dropout = nn.Dropout(dropout_p)\n        self.attention = Attention(hiddenLayerNuerons).to(device)\n\n    def forward(self, current_input, prev_state,encoder_final_layers):\n        if(self.cellType == 'LSTM'):\n            context , attn_weights = self.attention(prev_state[1][-1,:,:], encoder_final_layers)\n        else:\n            context , attn_weights = self.attention(prev_state[-1,:,:], encoder_final_layers)\n        \n        embd_input = self.embedding(current_input)\n        curr_embd = F.relu(embd_input)\n        input_gru = torch.cat((curr_embd, context), dim=2)\n        output, prev_state = self.rnn(input_gru, prev_state)\n        output = self.dropout(output)\n        output = self.softmax(self.fc(output)) \n        return output, prev_state, attn_weights","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:59:05.904267Z","iopub.execute_input":"2024-05-16T02:59:05.904665Z","iopub.status.idle":"2024-05-16T02:59:05.927017Z","shell.execute_reply.started":"2024-05-16T02:59:05.904634Z","shell.execute_reply":"2024-05-16T02:59:05.925674Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# input_dim = data[\"source_len\"]\n# output_dim = data[\"target_len\"]\n# char_embd_dim=64\n# hidden_layer_neurons = 512\n# learning_rate  =0.0001\n# batch_size = 64\n# number_of_layers = 10\n# tf_ratio = 0.2\n# epochs = 50\ntrain(64,5,5,216,'GRU','No',0.4,10,64,1e-4,\"Adam\",0.2)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T03:28:38.464257Z","iopub.execute_input":"2024-05-16T03:28:38.464680Z","iopub.status.idle":"2024-05-16T03:28:38.925226Z","shell.execute_reply.started":"2024-05-16T03:28:38.464645Z","shell.execute_reply":"2024-05-16T03:28:38.923812Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"[tensor([[[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0331]],\n\n        ...,\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]]],\n       grad_fn=<PermuteBackward0>), tensor([[[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        ...,\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]]],\n       grad_fn=<PermuteBackward0>), tensor([[[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        ...,\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]]],\n       grad_fn=<PermuteBackward0>), tensor([[[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        ...,\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]]],\n       grad_fn=<PermuteBackward0>), tensor([[[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        ...,\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]]],\n       grad_fn=<PermuteBackward0>), tensor([[[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        ...,\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]]],\n       grad_fn=<PermuteBackward0>), tensor([[[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        ...,\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]]],\n       grad_fn=<PermuteBackward0>), tensor([[[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        ...,\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]]],\n       grad_fn=<PermuteBackward0>), tensor([[[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        ...,\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]]],\n       grad_fn=<PermuteBackward0>), tensor([[[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        ...,\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]]],\n       grad_fn=<PermuteBackward0>), tensor([[[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        ...,\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]]],\n       grad_fn=<PermuteBackward0>), tensor([[[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        ...,\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]]],\n       grad_fn=<PermuteBackward0>), tensor([[[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        ...,\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]]],\n       grad_fn=<PermuteBackward0>), tensor([[[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        ...,\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]]],\n       grad_fn=<PermuteBackward0>), tensor([[[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        ...,\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]]],\n       grad_fn=<PermuteBackward0>), tensor([[[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        ...,\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]]],\n       grad_fn=<PermuteBackward0>), tensor([[[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        ...,\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]]],\n       grad_fn=<PermuteBackward0>), tensor([[[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        ...,\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]]],\n       grad_fn=<PermuteBackward0>), tensor([[[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        ...,\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]]],\n       grad_fn=<PermuteBackward0>), tensor([[[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        ...,\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]]],\n       grad_fn=<PermuteBackward0>), tensor([[[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        ...,\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]]],\n       grad_fn=<PermuteBackward0>), tensor([[[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        ...,\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]]],\n       grad_fn=<PermuteBackward0>), tensor([[[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0337, 0.0337, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        ...,\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]],\n\n        [[0.0337, 0.0336, 0.0336,  ..., 0.0332, 0.0332, 0.0332]],\n\n        [[0.0336, 0.0336, 0.0336,  ..., 0.0331, 0.0331, 0.0331]]],\n       grad_fn=<PermuteBackward0>)]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[29], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# input_dim = data[\"source_len\"]\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# output_dim = data[\"target_len\"]\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# char_embd_dim=64\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# tf_ratio = 0.2\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# epochs = 50\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m216\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGRU\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAdam\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[28], line 125\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(embSize, encoderLayers, decoderLayers, hiddenLayerNuerons, cellType, bidirection, dropout, epochs, batchsize, learningRate, optimizer, tf_ratio)\u001b[0m\n\u001b[1;32m    122\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (loss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;241m/\u001b[39moutput_seq_len)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28mprint\u001b[39m(attentions)\n\u001b[0;32m--> 125\u001b[0m \u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mk\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m24\u001b[39;49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(batch_num\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbt:\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch_num, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m loss:\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;241m/\u001b[39moutput_seq_len)\n","\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'int'"],"ename":"TypeError","evalue":"unsupported operand type(s) for /: 'str' and 'int'","output_type":"error"}]},{"cell_type":"code","source":"data = pre_processing(copy.copy(train_input),copy.copy(train_output))","metadata":{"execution":{"iopub.status.busy":"2024-05-15T17:32:18.212266Z","iopub.execute_input":"2024-05-15T17:32:18.212804Z","iopub.status.idle":"2024-05-15T17:32:24.078735Z","shell.execute_reply.started":"2024-05-15T17:32:18.212755Z","shell.execute_reply":"2024-05-15T17:32:24.076951Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def dataLoaderFun(dataName,batch_size):\n    if(dataName == 'train'):\n        dataset = MyDataset(data[\"source_charToNum\"],data['val_charToNum'])\n        return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n    else:\n        dataset = MyDataset(data2[\"source_charToNum\"],data2['val_charToNum'])\n        return  DataLoader(dataset, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T02:59:10.942116Z","iopub.execute_input":"2024-05-16T02:59:10.943207Z","iopub.status.idle":"2024-05-16T02:59:10.949352Z","shell.execute_reply.started":"2024-05-16T02:59:10.943165Z","shell.execute_reply":"2024-05-16T02:59:10.948247Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def train(embSize,encoderLayers,decoderLayers,hiddenLayerNuerons,cellType,bidirection,dropout,epochs,batchsize,learningRate,optimizer,tf_ratio):\n    #add optimizer,tf_ratio to wandb parameters\n    \n    dataLoader = dataLoaderFun(\"train\",batchsize) # dataLoader depending on train or validation\n    \n    \n    encoder = Encoder(data[\"source_len\"],embSize,encoderLayers,hiddenLayerNuerons,cellType,batchsize).to(device)\n    decoder = Decoder(data[\"target_len\"],embSize,hiddenLayerNuerons,encoderLayers,cellType,dropout).to(device)\n    \n    # done till here\n    if(optimizer == 'Adam'):\n        encoderOptimizer = optim.Adam(encoder.parameters(), lr=learningRate)\n        decoderOptimizer = optim.Adam(decoder.parameters(), lr=learningRate)\n    else:\n        encoderOptimizer = optim.NAdam(encoder.parameters(), lr=learningRate)\n        decoderOptimizer = optim.NAdam(decoder.parameters(), lr=learningRate)\n    \n    lossFunction = nn.NLLLoss()\n\n    for epoch in range (0,epochs):\n    \n        train_accuracy = 0 \n        train_loss = 0 \n\n        for batch_num, (source_batch, target_batch) in enumerate(dataLoader):\n                        \n            encoder_initial_state = encoder.getInitialState() #hiddenlayers * BatchSize * Neurons\n            \n            if(bidirection == \"Yes\"):\n                reversed_batch = torch.flip(source_batch, dims=[1]) # reverse the batch across rows.\n                source_batch = (source_batch + reversed_batch)//2 # adding reversed data to source data by averaging\n            \n            if(cellType == 'LSTM'):\n                encoder_initial_state = (encoder_initial_state, encoder.getInitialState())\n                \n            encoder_states, dummy = encoder(source_batch,encoder_initial_state)\n\n            decoder_current_state = dummy # this selects the last state from encoder states\n\n            encoder_final_layer_states = encoder_states[:, -1, :, :] # this selects the hidden top layers from each sequence\n\n            # decoder_current_input = torch.full((batchsize,1),0, device=device)#it fills torch with 0s becaus '{' is mappped to zeroes\n\n            #embd_input = decoder.embedding(decoder_current_input)\n\n            #curr_embd = F.relu(embd_input)            \n\n            #Here I need to get the encoder states\n\n            #here you should change\n            \n            #print(encoder_output)\n            #success till here3\n            \n            \n            loss = 0 # decoder starts form \n            \n            output_seq_len = target_batch.shape[1] # here you will get as name justified. 40\n            attentions = []\n            decoder_actual_output = []\n            #print(target_batch)\n            \n            randNumber = random.random()\n\n            \n\n            for i in range(0,output_seq_len):\n\n                if(i == 0):\n                    decoder_current_input = torch.full((batchsize,1),0, device=device)\n                    #decoder_input_tensor = target_batch[:, i].reshape(batchsize,1) #32*1\n                    #print(dec_input_tensor.shape)\n                else:\n                    if randNumber < tf_ratio:\n                        decoder_current_input = target_batch[:, i].reshape(batchsize, 1)\n                        #decoder_input_tensor = target_batch[:, i].reshape(batchsize, 1) # current batch is passed\n                    else:\n                        decoder_current_input = decoder_current_input.reshape(batchsize, 1)\n                        #decoder_input_tensor = decoder_input_tensor.reshape(batchsize, 1) # prev result is passed\n                \n                decoder_output, decoder_current_state, attn_weights = decoder(decoder_current_input, decoder_current_state, encoder_final_layer_states)\n                \n                attentions.append(attn_weights)\n\n                topv, topi = decoder_output.topk(1)\n                decoder_current_input = topi.squeeze().detach()\n                decoder_actual_output.append(decoder_current_input)\n                decoder_output = decoder_output[:, -1, :]\n                curr_target_chars = target_batch[:, i] #(32)\n                curr_target_chars = curr_target_chars.type(dtype=torch.long)\n                loss+=(lossFunction(decoder_output, curr_target_chars))\n\n                # #print(curr_target_chars.shape) #32\n                # decoder_output, decoder_curr_state = decoder(decoder_input_tensor,decoder_curr_state)\n                # #print(decoder_output.shape) #(32*1*67) but your output is (32*1*65) becz ur output size is 65\n                # topv, topi = decoder_output.topk(1)  # you will get top vales and their indices.\n                # #print(\"topv\", topv)\n                # decoder_input_tensor = topi.squeeze().detach()  # here whatever top softmax indeces are present but converted to 1 dimension\n                # #print(decoder_input_tensor.shape)\n                # decoder_actual_output.append(decoder_input_tensor) # softmax values are attached                    \n                        \n                # decoder_output = decoder_output[:, -1, :] #it is just reduce the size from (32*1*67) to (32*67)\n                # #print(decoder_output.shape,curr_target_chars.shape)\n                # #print(decoder_output.shape,curr_target_chars.shape)\n\n                # curr_target_chars = target_batch[:, i] #(32)\n                # curr_target_chars = curr_target_chars.type(dtype=torch.long)\n                # #print(curr_target_chars)\n                \n                # loss+=(lossFunction(decoder_output, curr_target_chars)) # you are passing 32*67 softmax values to curr_target_chars which has the 32*1\n            \n            decoder_actual_output = torch.cat(decoder_actual_output,dim=0).reshape(output_seq_len,batchsize).transpose(0,1)\n            train_accuracy += (decoder_actual_output == target_batch).all(dim=1).sum().item()\n            # tensor_2d = torch.stack(decoder_actual_output)\n            # decoder_actual_output = tensor_2d.t() #it is outside the for loop\n            # #print(decoder_actual_output) #32*40\n            # if(batch_num == 0 and epoch == epochs-1):\n            #     numToCharConverter(target_batch,decoder_actual_output,data) \n                \n            # train_accuracy += (decoder_actual_output == target_batch).all(dim=1).sum().item() # it is simple just summing up the equal values\n\n            train_loss += (loss.item()/output_seq_len)\n            \n            print(attentions)\n            'k'/24\n            \n            if(batch_num%200 == 0):\n                print(\"bt:\", batch_num, \" loss:\", loss.item()/output_seq_len)\n            #'k'/24\n            # here you get the actual word letters seqeunces softamx indeces\n            #[[0,1,2],[0,1,2]] = [shr,ram] 32*40\n            #correct = (decoder_actual_output == target_batch).all(dim=1).sum().item()\n            #accuracy = accuracy + correct\n            encoderOptimizer.zero_grad()\n            decoderOptimizer.zero_grad()\n            loss.backward()\n            encoderOptimizer.step()\n            decoderOptimizer.step()\n            \n        print(\"train_accuracy\",train_accuracy/512)\n        print(\"train_loss\",train_loss)\n        #wandb.log({'train_accuracy':train_accuracy/512})\n        #wandb.log({'train_loss':train_loss})\n        validationAccuracy(encoder,decoder,batchsize,tf_ratio,cellType,bidirection)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T03:28:22.273023Z","iopub.execute_input":"2024-05-16T03:28:22.273401Z","iopub.status.idle":"2024-05-16T03:28:22.301030Z","shell.execute_reply.started":"2024-05-16T03:28:22.273374Z","shell.execute_reply":"2024-05-16T03:28:22.299883Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"\n\n\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n    \n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def numToCharConverter(inputArray,outputArray,data):\n    mp = data['num_char_map_2']\n    t1 = ''\n    t2 = ''\n    for row1, row2 in zip(inputArray,outputArray):\n        t1=''\n        t2=''\n        for e1, e2 in zip(row1,row2):\n            t1+=mp[e1.item()]\n            t2+=mp[e2.item()]\n        print(t1,\" \",t2)\n            \n        \n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-15T17:32:39.484203Z","iopub.execute_input":"2024-05-15T17:32:39.484755Z","iopub.status.idle":"2024-05-15T17:32:39.493662Z","shell.execute_reply.started":"2024-05-15T17:32:39.484713Z","shell.execute_reply":"2024-05-15T17:32:39.492619Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def main_fun():\n    wandb.init(project ='AttentionRNN')\n    params = wandb.config\n    with wandb.init(project = 'AttentionRNN', name='embedding'+str(params.embSize)+'cellType'+params.cellType+'batchSize'+str(params.batchsize)) as run:\n        train(params.embSize,params.encoderLayers,params.decoderLayers,params.hiddenLayerNuerons,params.cellType,params.bidirection,params.dropout,params.epochs,params.batchsize,params.learningRate,params.optimizer,params.tf_ratio)\n    \nsweep_params = {\n    'method' : 'bayes',\n    'name'   : 'DeepLearningAssignmentAttention3',\n    'metric' : {\n        'goal' : 'maximize',\n        'name' : 'validation_accuracy',\n    },\n    'parameters' : {\n        'embSize':{'values':[16,32,64]},\n        'encoderLayers':{'values':[1,5,10]},\n        'decoderLayers' : {'values' : [1,5,10]},\n        'hiddenLayerNuerons'   : {'values' : [64,256,512]},\n        'cellType' : {'values' : ['GRU','RNN'] } ,\n        'bidirection' : {'values' : ['no','Yes']},\n        'dropout' : {'values' : [0,0.2,0.3]},\n        'epochs'  : {'values': [10,15]},\n        'batchsize' : {'values' : [32,64]},\n        'learningRate' : {'values' : [1e-2,1e-3,1e-4]},\n        'optimizer':{'values' : ['Adam','Nadam']},\n        'tf_ratio' :{'values' : [0.2,0.4,0.5]}\n    }\n}\nsweepId = wandb.sweep(sweep_params,project = 'AttentionRNN')\nwandb.agent(sweepId,function =main_fun,count = 3)\nwandb.finish()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain(data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}