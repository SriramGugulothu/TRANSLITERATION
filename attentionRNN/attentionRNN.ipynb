{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8273608,"sourceType":"datasetVersion","datasetId":4912633},{"sourceId":8400322,"sourceType":"datasetVersion","datasetId":4998024}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport pandas as pd\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport copy\nfrom torch.utils.data import Dataset, DataLoader\nimport random","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-15T07:18:05.484456Z","iopub.execute_input":"2024-05-15T07:18:05.484751Z","iopub.status.idle":"2024-05-15T07:18:10.277111Z","shell.execute_reply.started":"2024-05-15T07:18:05.484725Z","shell.execute_reply":"2024-05-15T07:18:10.276220Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install wandb\nimport wandb\nfrom wandb.keras import WandbCallback\nimport socket\nsocket.setdefaulttimeout(30)\nwandb.login()\nwandb.init(project ='vanillaRNN')","metadata":{"execution":{"iopub.status.busy":"2024-05-15T07:18:10.278938Z","iopub.execute_input":"2024-05-15T07:18:10.279380Z","iopub.status.idle":"2024-05-15T07:28:25.075638Z","shell.execute_reply.started":"2024-05-15T07:18:10.279351Z","shell.execute_reply":"2024-05-15T07:28:25.074628Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.6)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.45.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (69.0.3)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","output_type":"stream"},{"name":"stderr","text":"2024-05-15 07:18:26.564799: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-15 07:18:26.564910: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-15 07:18:26.748597: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs23m066\u001b[0m (\u001b[33mdlassignment\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240515_072808-2lvjc2ca</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/dlassignment/vanillaRNN/runs/2lvjc2ca' target=\"_blank\">silver-wind-57</a></strong> to <a href='https://wandb.ai/dlassignment/vanillaRNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/dlassignment/vanillaRNN' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/dlassignment/vanillaRNN/runs/2lvjc2ca' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN/runs/2lvjc2ca</a>"},"metadata":{}},{"execution_count":2,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/dlassignment/vanillaRNN/runs/2lvjc2ca?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7d1bf0476a10>"},"metadata":{}}]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T07:28:25.077309Z","iopub.execute_input":"2024-05-15T07:28:25.077882Z","iopub.status.idle":"2024-05-15T07:28:25.144884Z","shell.execute_reply.started":"2024-05-15T07:28:25.077848Z","shell.execute_reply":"2024-05-15T07:28:25.143725Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"train_csv = \"/kaggle/input/telugu/tel/tel_train.csv\"\ntest_csv = \"/kaggle/input/telugu/tel/tel_test.csv\"\nval_csv = \"/kaggle/input/telugu/tel/tel_valid.csv\"","metadata":{"execution":{"iopub.status.busy":"2024-05-15T07:28:25.147540Z","iopub.execute_input":"2024-05-15T07:28:25.148254Z","iopub.status.idle":"2024-05-15T07:28:25.157328Z","shell.execute_reply.started":"2024-05-15T07:28:25.148219Z","shell.execute_reply":"2024-05-15T07:28:25.156675Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv(train_csv, header=None)\ntrain_input = train_data[0].to_numpy()\ntrain_output = train_data[1].to_numpy()\nval_data = pd.read_csv(val_csv,header = None)\nval_input = val_data[0].to_numpy()\nval_output = val_data[1].to_numpy()\ntest_data = pd.read_csv(test_csv,header= None)\nprint(len(train_input))\nprint(len(train_output))\nprint(len(val_input))\nprint(len(test_data))\nprint(val_input)\nprint(val_output)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T07:28:25.158187Z","iopub.execute_input":"2024-05-15T07:28:25.158511Z","iopub.status.idle":"2024-05-15T07:28:25.377858Z","shell.execute_reply.started":"2024-05-15T07:28:25.158478Z","shell.execute_reply":"2024-05-15T07:28:25.376748Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"51200\n51200\n4096\n4096\n['bheeshmudini' 'vinyasaanni' 'kaavachhunu' ... 'asramam' 'divine' 'dis']\n['భీష్ముడిని' 'విన్యాసాన్ని' 'కావచ్చును' ... 'ఆశ్రమం' 'డివైన్' 'డిస్']\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train_output[0][5]) #the size of input and output is 4096\nmaxi = 0\nt =''\nfor x in val_input:\n    maxi = max(maxi,len(x))\n    if(maxi == len(x)):\n        t=x\n        \nprint(maxi,t)\nt =''\nmaxi =0 \nfor x in val_output:\n    maxi = max(maxi,len(x))\n    if(maxi == len(x)):\n        t=x\n        \nprint(maxi,t)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-15T07:28:25.379265Z","iopub.execute_input":"2024-05-15T07:28:25.380111Z","iopub.status.idle":"2024-05-15T07:28:25.397653Z","shell.execute_reply.started":"2024-05-15T07:28:25.380074Z","shell.execute_reply":"2024-05-15T07:28:25.396675Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"ల\n28 paramaanandabharithudayyaadu\n19 పరమానందభరితుడయ్యాడు\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndef pre_processing(train_input,train_output):\n    data = {\n    \"all_characters\" : [],\n    \"char_num_map\" : {},\n    \"num_char_map\" : {},\n    \"source_charToNum\": torch.zeros(len(train_input),30, dtype=torch.int, device=device),\n    \"source_data\" : train_input,\n        \n    \"all_characters_2\" : [],\n    \"char_num_map_2\" : {},\n    \"num_char_map_2\" : {},\n    \"val_charToNum\": torch.zeros(len(train_output),23, dtype=torch.int, device=device),\n    \"target_data\" : train_output,\n    \"source_len\" : 0,\n    \"target_len\" : 0\n }\n    k = 0 \n    l = 0\n    for i in range(0,len(train_input)):\n        train_input[i] = \"{\" + train_input[i] + \"}\"*(29-len(train_input[i]))\n        charToNum = []\n        for char in (train_input[i]):\n            index = 0\n            if(char not in data[\"all_characters\"]):\n                data[\"all_characters\"].append(char)\n                index = data[\"all_characters\"].index(char)\n                data[\"char_num_map\"][char] = index\n                data[\"num_char_map\"][index] = char\n            else:\n                index = data[\"all_characters\"].index(char)\n            \n            charToNum.append(index)\n            \n        my_tensor = torch.tensor(charToNum,device = device)\n        data[\"source_charToNum\"][k] = my_tensor\n        \n        charToNum1 = []\n        \n        train_output[i] = \"{\" + train_output[i] + \"}\"*(22-len(train_output[i]))\n        for char in (train_output[i]):\n            index = 0\n            if(char not in data[\"all_characters_2\"]):\n                data[\"all_characters_2\"].append(char)\n                index = data[\"all_characters_2\"].index(char)\n                data[\"char_num_map_2\"][char] = index\n                data[\"num_char_map_2\"][index] = char\n            else:\n                index = data[\"all_characters_2\"].index(char)\n                \n            charToNum1.append(index)\n            \n        my_tensor1 = torch.tensor(charToNum1,device = device)\n        data[\"val_charToNum\"][k] = my_tensor1\n        \n        k+=1\n    \n    data[\"source_len\"] = len(data[\"all_characters\"])\n    data[\"target_len\"] = len(data[\"all_characters_2\"])\n        \n    return data\n    \n    \ndata = pre_processing(copy.copy(train_input),copy.copy(train_output))\n# print(data[\"all_characters\"])\n# print(data[\"char_num_map\"])\n# print(data[\"num_char_map\"])\n# print(data[\"all_characters_2\"])\n# print(data[\"char_num_map_2\"])\n# print(data[\"num_char_map_2\"])\nprint(data[\"source_charToNum\"])\nprint(data['val_charToNum'])\nprint(data[\"num_char_map_2\"])\nprint(data[\"num_char_map\"])\nprint(train_input[0])\nprint(data['source_len'])\nprint(data['target_len'])\n","metadata":{"execution":{"iopub.status.busy":"2024-05-15T07:28:25.399644Z","iopub.execute_input":"2024-05-15T07:28:25.400172Z","iopub.status.idle":"2024-05-15T07:28:33.077025Z","shell.execute_reply.started":"2024-05-15T07:28:25.400129Z","shell.execute_reply":"2024-05-15T07:28:33.075638Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"tensor([[ 0,  1,  2,  ...,  9,  9,  9],\n        [ 0,  1,  2,  ...,  9,  9,  9],\n        [ 0, 13,  2,  ...,  9,  9,  9],\n        ...,\n        [ 0,  1,  8,  ...,  9,  9,  9],\n        [ 0,  3, 16,  ...,  9,  9,  9],\n        [ 0, 14, 20,  ...,  9,  9,  9]], device='cuda:0', dtype=torch.int32)\ntensor([[ 0,  1,  2,  ..., 10, 10, 10],\n        [ 0,  1, 11,  ..., 10, 10, 10],\n        [ 0, 14,  3,  ..., 10, 10, 10],\n        ...,\n        [ 0,  1, 25,  ..., 10, 10, 10],\n        [ 0,  2, 20,  ..., 10, 10, 10],\n        [ 0, 27, 25,  ..., 10, 10, 10]], device='cuda:0', dtype=torch.int32)\n{0: '{', 1: 'వ', 2: 'ర', 3: '్', 4: 'గ', 5: 'ా', 6: 'ల', 7: 'ి', 8: 'న', 9: 'ే', 10: '}', 11: 'స', 12: 'త', 13: 'ద', 14: 'ఫ', 15: 'య', 16: 'క', 17: 'ట', 18: 'మ', 19: 'ో', 20: 'ూ', 21: 'ళ', 22: 'ప', 23: 'ధ', 24: 'ు', 25: 'ె', 26: 'ం', 27: 'చ', 28: 'ై', 29: 'డ', 30: 'ఖ', 31: 'ఉ', 32: 'ష', 33: 'ఆ', 34: 'ొ', 35: 'శ', 36: 'అ', 37: 'భ', 38: 'ృ', 39: 'ణ', 40: 'హ', 41: 'జ', 42: 'ీ', 43: 'ఇ', 44: 'బ', 45: 'ఐ', 46: 'ఒ', 47: 'ఎ', 48: 'ౌ', 49: 'థ', 50: 'ఈ', 51: 'ఊ', 52: 'ఏ', 53: 'ఢ', 54: 'ఓ', 55: 'ఔ', 56: 'ఞ', 57: 'ఠ', 58: 'ఘ', 59: 'ఛ', 60: 'ః', 61: 'ఝ', 62: 'ఋ', 63: 'ఱ'}\n{0: '{', 1: 'v', 2: 'a', 3: 'r', 4: 'g', 5: 'l', 6: 'i', 7: 'n', 8: 'e', 9: '}', 10: 's', 11: 't', 12: 'd', 13: 'f', 14: 'c', 15: 'm', 16: 'o', 17: 'u', 18: 'w', 19: 'p', 20: 'h', 21: 'k', 22: 'y', 23: 'b', 24: 'j', 25: 'z', 26: 'x', 27: 'q'}\nvargaalavaarine\n28\n64\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train_input[1])\nprint(train_output[1])","metadata":{"execution":{"iopub.status.busy":"2024-05-15T07:28:33.078370Z","iopub.execute_input":"2024-05-15T07:28:33.078719Z","iopub.status.idle":"2024-05-15T07:28:33.085684Z","shell.execute_reply.started":"2024-05-15T07:28:33.078686Z","shell.execute_reply":"2024-05-15T07:28:33.084571Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"vastadira\nవస్తాదిరా\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndef pre_processing_validation(val_input,val_output):\n    data2 = {\n    \"all_characters\" : [],\n    \"char_num_map\" : {},\n    \"num_char_map\" : {},\n    \"source_charToNum\": torch.zeros(len(val_input),30, dtype=torch.int, device=device),\n    \"source_data\" : val_input,\n    \"all_characters_2\" : [],\n    \"char_num_map_2\" : {},\n    \"num_char_map_2\" : {},\n    \"val_charToNum\": torch.zeros(len(val_output),23, dtype=torch.int, device=device),\n    \"target_data\" : val_output,\n    \"source_len\" : 0,\n    \"target_len\" : 0\n }\n    k = 0 \n    l = 0\n    \n    m1 = data[\"char_num_map\"]\n    m2 = data[\"char_num_map_2\"]\n    \n    for i in range(0,len(val_input)):\n        val_input[i] = \"{\" + val_input[i] + \"}\"*(29-len(val_input[i]))\n        charToNum = []\n        for char in (val_input[i]):\n            index = 0\n            if(char not in data2[\"all_characters\"]):\n                data2[\"all_characters\"].append(char)\n                index = m1[char]\n                data2[\"char_num_map\"][char] = index\n                data2[\"num_char_map\"][index] = char\n            else:\n                index = m1[char]\n            \n            charToNum.append(index)\n            \n        my_tensor = torch.tensor(charToNum,device = device)\n        data2[\"source_charToNum\"][k] = my_tensor\n        \n        charToNum1 = []\n        val_output[i] = \"{\" + val_output[i] + \"}\"*(22-len(val_output[i]))\n        for char in (val_output[i]):\n            index = 0\n            if(char not in data2[\"all_characters_2\"]):\n                data2[\"all_characters_2\"].append(char)\n                index = m2[char]\n                data2[\"char_num_map_2\"][char] = index\n                data2[\"num_char_map_2\"][index] = char\n            else:\n                index = m2[char]\n                \n            charToNum1.append(index)\n            \n        my_tensor1 = torch.tensor(charToNum1,device = device)\n        data2[\"val_charToNum\"][k] = my_tensor1\n        \n        k+=1\n    \n    data2[\"source_len\"] = len(data2[\"all_characters\"])\n    data2[\"target_len\"] = len(data2[\"all_characters_2\"])\n        \n    return data2\n    \n    \ndata2 = pre_processing_validation(copy.copy(val_input),copy.copy(val_output))\n# print(data[\"all_characters\"])\n# print(data[\"char_num_map\"])\n# print(data[\"num_char_map\"])\n# print(data[\"all_characters_2\"])\n# print(data[\"char_num_map_2\"])\n# print(data[\"num_char_map_2\"])\nprint(data2[\"num_char_map\"])\nprint(data2[\"source_charToNum\"].shape)\n\nprint(data2[\"num_char_map_2\"])\nprint(data2['val_charToNum'][0])\n\n\nprint(val_input[0])\nprint(data2['source_len'])\nprint(data2['target_len'])\n","metadata":{"execution":{"iopub.status.busy":"2024-05-15T07:28:33.087401Z","iopub.execute_input":"2024-05-15T07:28:33.088114Z","iopub.status.idle":"2024-05-15T07:28:33.623077Z","shell.execute_reply.started":"2024-05-15T07:28:33.088081Z","shell.execute_reply":"2024-05-15T07:28:33.621982Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"{0: '{', 23: 'b', 20: 'h', 8: 'e', 10: 's', 15: 'm', 17: 'u', 12: 'd', 6: 'i', 7: 'n', 9: '}', 1: 'v', 22: 'y', 2: 'a', 21: 'k', 14: 'c', 11: 't', 3: 'r', 19: 'p', 5: 'l', 16: 'o', 4: 'g', 24: 'j', 18: 'w', 26: 'x', 13: 'f', 25: 'z', 27: 'q'}\ntorch.Size([4096, 30])\n{0: '{', 37: 'భ', 42: 'ీ', 32: 'ష', 3: '్', 18: 'మ', 24: 'ు', 29: 'డ', 7: 'ి', 8: 'న', 10: '}', 1: 'వ', 15: 'య', 5: 'ా', 11: 'స', 16: 'క', 27: 'చ', 12: 'త', 2: 'ర', 26: 'ం', 22: 'ప', 6: 'ల', 20: 'ూ', 49: 'థ', 33: 'ఆ', 35: 'శ', 40: 'హ', 19: 'ో', 4: 'గ', 41: 'జ', 13: 'ద', 34: 'ొ', 28: 'ై', 9: 'ే', 46: 'ఒ', 25: 'ె', 17: 'ట', 39: 'ణ', 43: 'ఇ', 38: 'ృ', 54: 'ఓ', 23: 'ధ', 45: 'ఐ', 47: 'ఎ', 36: 'అ', 44: 'బ', 52: 'ఏ', 14: 'ఫ', 31: 'ఉ', 30: 'ఖ', 21: 'ళ', 51: 'ఊ', 48: 'ౌ', 55: 'ఔ', 57: 'ఠ', 58: 'ఘ', 56: 'ఞ', 50: 'ఈ', 59: 'ఛ', 62: 'ఋ', 60: 'ః', 53: 'ఢ'}\ntensor([ 0, 37, 42, 32,  3, 18, 24, 29,  7,  8,  7, 10, 10, 10, 10, 10, 10, 10,\n        10, 10, 10, 10, 10], device='cuda:0', dtype=torch.int32)\nbheeshmudini\n28\n62\n","output_type":"stream"}]},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, x,y):\n        self.source = x\n        self.target = y\n    \n    def __len__(self):\n        return len(self.source)\n    \n    def __getitem__(self, idx):\n        source_data = self.source[idx]\n        target_data = self.target[idx]\n        return source_data, target_data","metadata":{"execution":{"iopub.status.busy":"2024-05-15T07:28:33.627782Z","iopub.execute_input":"2024-05-15T07:28:33.628517Z","iopub.status.idle":"2024-05-15T07:28:33.636105Z","shell.execute_reply.started":"2024-05-15T07:28:33.628459Z","shell.execute_reply":"2024-05-15T07:28:33.635112Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class MyDataset2(Dataset):\n    def __init__(self, x,y):\n        self.source = x\n        self.target = y\n    \n    def __len__(self):\n        return len(self.source)\n    \n    def __getitem__(self, idx):\n        source_data = self.source[idx]\n        target_data = self.target[idx]\n        return source_data, target_data","metadata":{"execution":{"iopub.status.busy":"2024-05-15T07:28:33.637225Z","iopub.execute_input":"2024-05-15T07:28:33.637560Z","iopub.status.idle":"2024-05-15T07:28:33.647881Z","shell.execute_reply.started":"2024-05-15T07:28:33.637533Z","shell.execute_reply":"2024-05-15T07:28:33.646926Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def validationAccuracy(encoder,decoder,batchsize,tf_ratio,cellType,bidirection):\n    \n    dataLoader = dataLoaderFun(\"validation\",batchsize) # dataLoader depending on train or validation\n    \n    encoder.eval()\n    decoder.eval()\n    \n    validation_accuracy = 0\n    validation_loss = 0\n    \n    lossFunction = nn.NLLLoss()\n    \n    for batch_num, (source_batch, target_batch) in enumerate(dataLoader):\n        \n        encoder_initial_state = encoder.getInitialState() #hiddenlayers * BatchSize * Neurons\n        if(cellType=='LSTM'):\n            encoder_initial_state = (encoder_initial_state,encoder.getInitialState())\n            \n        if(bidirection == \"Yes\"):\n            reversed_batch = torch.flip(source_batch, dims=[1]) # reverse the batch across rows.\n            source_batch = (source_batch + reversed_batch)//2 \n            \n        encoder_output, encoder_current_state = encoder(source_batch,encoder_initial_state)\n        #print(encoder_output)\n        #success till here\n\n        loss = 0 # decoder starts form here\n        correct = 0\n\n        output_seq_len = target_batch.shape[1] # here you will get as name justified. 40\n\n        decoder_actual_output = []\n        #print(target_batch)\n\n        randNumber = random.random()\n\n        decoder_curr_state = encoder_current_state\n\n        for i in range(0,output_seq_len):\n\n            if(i == 0):\n                decoder_input_tensor = target_batch[:, i].reshape(batchsize,1) #32*1\n                #print(dec_input_tensor.shape)\n            else:\n                if randNumber < tf_ratio:\n                    decoder_input_tensor = target_batch[:, i].reshape(batchsize, 1) # current batch is passed\n                else:\n                    decoder_input_tensor = decoder_input_tensor.reshape(batchsize, 1) # prev result is passed\n\n            #print(curr_target_chars.shape) #32\n            decoder_output, decoder_curr_state = decoder(decoder_input_tensor,decoder_curr_state)\n            #print(decoder_output.shape) #(32*1*67) but your output is (32*1*65) becz ur output size is 65\n            topv, topi = decoder_output.topk(1)  # you will get top vales and their indices.\n            #print(\"topv\", topv)\n            decoder_input_tensor = topi.squeeze().detach()  # here whatever top softmax indeces are present but converted to 1 dimension\n            #print(decoder_input_tensor.shape)\n            decoder_actual_output.append(decoder_input_tensor) # softmax values are attached                    \n\n            decoder_output = decoder_output[:, -1, :] #it is just reduce the size from (32*1*67) to (32*67)\n            #print(decoder_output.shape,curr_target_chars.shape)\n            #print(decoder_output.shape,curr_target_chars.shape)\n\n            curr_target_chars = target_batch[:, i] #(32)\n            curr_target_chars = curr_target_chars.type(dtype=torch.long)\n            #print(curr_target_chars)\n\n            loss+=(lossFunction(decoder_output, curr_target_chars)) # you are passing 32*67 softmax values to curr_target_chars which has the 32*1\n\n        tensor_2d = torch.stack(decoder_actual_output)\n        decoder_actual_output = tensor_2d.t() #it is outside the for loop\n\n        validation_accuracy += (decoder_actual_output == target_batch).all(dim=1).sum().item() # it is simple just summing up the equal values\n        validation_loss += (loss.item()/output_seq_len)\n\n        if(batch_num%20 == 0):\n            print(\"bt:\", batch_num, \" loss:\", loss.item()/output_seq_len)\n        #'k'/24\n        # here you get the actual word letters seqeunces softamx indeces\n        #[[0,1,2],[0,1,2]] = [shr,ram] 32*40\n        #correct = (decoder_actual_output == target_batch).all(dim=1).sum().item()\n        #accuracy = accuracy + correct\n    \n    encoder.train()\n    decoder.train()\n    print(\"validation_accuracy\",validation_accuracy/40.96)\n    print(\"validation_loss\",validation_loss)\n    wandb.log({'validation_accuracy':validation_accuracy/40.96})\n    wandb.log({'validation_loss':validation_loss})","metadata":{"execution":{"iopub.status.busy":"2024-05-15T07:28:33.650512Z","iopub.execute_input":"2024-05-15T07:28:33.650918Z","iopub.status.idle":"2024-05-15T07:28:33.668003Z","shell.execute_reply.started":"2024-05-15T07:28:33.650886Z","shell.execute_reply":"2024-05-15T07:28:33.667069Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class Attention(nn.Module):\n    def __init__(self, hidden_size):\n        super(Attention, self).__init__()\n        self.Wa = nn.Linear(hidden_size, hidden_size)\n        self.Ua = nn.Linear(hidden_size, hidden_size)\n        self.Va = nn.Linear(hidden_size, 1)\n\n    def forward(self, query, keys):\n        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n        scores = scores.squeeze().unsqueeze(1)\n        weights = F.softmax(scores, dim=0)\n        weights = weights.permute(2,1,0)\n        keys = keys.permute(1,0,2)\n        context = torch.bmm(weights, keys)\n        return context, weights","metadata":{"execution":{"iopub.status.busy":"2024-05-15T09:43:28.979284Z","iopub.execute_input":"2024-05-15T09:43:28.979807Z","iopub.status.idle":"2024-05-15T09:43:29.448243Z","shell.execute_reply.started":"2024-05-15T09:43:28.979770Z","shell.execute_reply":"2024-05-15T09:43:29.446332Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAttention\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_size):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28msuper\u001b[39m(Attention, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n","\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"],"ename":"NameError","evalue":"name 'nn' is not defined","output_type":"error"}]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    \n    def __init__(self,inputDim,embSize,encoderLayers,hiddenLayerNuerons,cellType,batch_size):\n        super(Encoder, self).__init__()\n        self.embedding = nn.Embedding(inputDim, embSize)\n        self.encoderLayers = encoderLayers\n        self.hiddenLayerNuerons = hiddenLayerNuerons\n        self.batch_size = batch_size\n        \n        if(cellType=='GRU'):\n            self.rnn = nn.GRU(embSize,hiddenLayerNuerons,num_layers=encoderLayers, batch_first=True)\n        elif(cellType=='RNN'):\n            self.rnn = nn.RNN(embSize,hiddenLayerNuerons,num_layers=encoderLayers, batch_first=True)\n        else:\n            self.rnn = nn.LSTM(embSize,hiddenLayerNuerons,num_layers=encoderLayers, batch_first=True)\n\n    def forward(self,sourceBatch,encoderCurrState):\n        sequenceLength = len(sourceBatch[0])\n        encoderStates = torch.zeros(sequenceLength,self.encoderLayers,self.batch_size,self.hiddenLayerNuerons,device=device)\n        for i in range(0,sequenceLength):\n            currInput = sourceBatch[:,i].reshape(self.batch_size,1)\n            dummy , encoderCurrState = self.statesCalculation(currInput,encoderCurrState)\n            encoderStates[i] = encoderCurrState\n\n        return encoderStates\n\n\n    def statesCalculation(self, currentInput, prevState):\n        embdInput = self.embedding(currentInput)\n        output, prev_state = self.rnn(embdInput, prevState)\n        return output, prev_state\n    \n    def getInitialState(self):\n        return torch.zeros(self.encoderLayers,self.batch_size,self.hiddenLayerNuerons, device=device)\n    \nclass Decoder(nn.Module):\n    def __init__(self,outputDim,embSize,hiddenLayerNuerons,decoderLayers,cellType,dropout_p):\n        super(Decoder, self).__init__()\n        self.embedding = nn.Embedding(outputDim, embSize)\n                \n        if(cellType == 'GRU'): # changed here\n            self.rnn = nn.GRU(embSize+hiddenLayerNuerons,hiddenLayerNuerons,num_layers=decoderLayers, batch_first=True)\n        elif(cellType == 'RNN'):\n            self.rnn = nn.RNN(embSize+hiddenLayerNuerons,hiddenLayerNuerons,num_layers=decoderLayers, batch_first=True)\n        else:\n            self.rnn = nn.LSTM(embSize+hiddenLayerNuerons,hiddenLayerNuerons,num_layers=decoderLayers, batch_first=True)\n            \n        self.fc = nn.Linear(hiddenLayerNuerons, outputDim) # it is useful for mapping the calculation to vocabularu\n        self.softmax = nn.LogSoftmax(dim=2) #output is in 3rd column \n        self.dropout = nn.Dropout(dropout_p)\n        self.attention = Attention(hiddenLayerNuerons).to(device)\n\n    def forward(self, current_input, prev_state,encoder_final_layers):\n        context , attn_weights = self.attention(prev_state[-1,:,:], encoder_final_layers)\n        embd_input = self.embedding(current_input)\n        curr_embd = F.relu(embd_input)\n        input_gru = torch.cat((curr_embd, context), dim=2)\n        output, prev_state = self.rnn(input_gru, prev_state)\n        #output = self.dropout(output)\n        output = self.softmax(self.fc(output)) \n        return output, prev_state, attn_weights","metadata":{"execution":{"iopub.status.busy":"2024-05-15T07:28:33.669150Z","iopub.execute_input":"2024-05-15T07:28:33.669415Z","iopub.status.idle":"2024-05-15T07:28:33.685495Z","shell.execute_reply.started":"2024-05-15T07:28:33.669392Z","shell.execute_reply":"2024-05-15T07:28:33.684569Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# input_dim = data[\"source_len\"]\n# output_dim = data[\"target_len\"]\n# char_embd_dim=64\n# hidden_layer_neurons = 512\n# learning_rate  =0.0001\n# batch_size = 64\n# number_of_layers = 10\n# tf_ratio = 0.2\n# epochs = 50\n#train(64,5,5,216,'LSTM','Yes',0.4,20,32,1e-4,\"Adam\",0.2)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T07:28:33.686974Z","iopub.execute_input":"2024-05-15T07:28:33.687328Z","iopub.status.idle":"2024-05-15T07:28:33.706331Z","shell.execute_reply.started":"2024-05-15T07:28:33.687299Z","shell.execute_reply":"2024-05-15T07:28:33.705340Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"data = pre_processing(copy.copy(train_input),copy.copy(train_output))","metadata":{"execution":{"iopub.status.busy":"2024-05-15T07:28:33.707382Z","iopub.execute_input":"2024-05-15T07:28:33.707645Z","iopub.status.idle":"2024-05-15T07:28:41.148105Z","shell.execute_reply.started":"2024-05-15T07:28:33.707623Z","shell.execute_reply":"2024-05-15T07:28:41.146664Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def dataLoaderFun(dataName,batch_size):\n    if(dataName == 'train'):\n        dataset = MyDataset(data[\"source_charToNum\"],data['val_charToNum'])\n        return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n    else:\n        dataset = MyDataset(data2[\"source_charToNum\"],data2['val_charToNum'])\n        return  DataLoader(dataset, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T07:28:41.149488Z","iopub.execute_input":"2024-05-15T07:28:41.149812Z","iopub.status.idle":"2024-05-15T07:28:41.158957Z","shell.execute_reply.started":"2024-05-15T07:28:41.149767Z","shell.execute_reply":"2024-05-15T07:28:41.157884Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def train(embSize,encoderLayers,decoderLayers,hiddenLayerNuerons,cellType,bidirection,dropout,epochs,batchsize,learningRate,optimizer,tf_ratio):\n    #add optimizer,tf_ratio to wandb parameters\n    \n    dataLoader = dataLoaderFun(\"train\",batchsize) # dataLoader depending on train or validation\n    \n    \n    encoder = Encoder(data[\"source_len\"],embSize,encoderLayers,hiddenLayerNuerons,cellType,batchsize).to(device)\n    decoder = Decoder(data[\"target_len\"],embSize,hiddenLayerNuerons,encoderLayers,cellType,dropout).to(device)\n    \n    # done till here\n    if(optimizer == 'Adam'):\n        encoderOptimizer = optim.Adam(encoder.parameters(), lr=learningRate)\n        decoderOptimizer = optim.Adam(decoder.parameters(), lr=learningRate)\n    else:\n        encoderOptimizer = optim.NAdam(encoder.parameters(), lr=learningRate)\n        decoderOptimizer = optim.NAdam(decoder.parameters(), lr=learningRate)\n    \n    lossFunction = nn.NLLLoss()\n\n    for epoch in range (0,epochs):\n    \n        train_accuracy = 0 \n        train_loss = 0 \n\n        for batch_num, (source_batch, target_batch) in enumerate(dataLoader):\n                        \n            encoder_initial_state = encoder.getInitialState() #hiddenlayers * BatchSize * Neurons\n            \n            if(bidirection == \"Yes\"):\n                reversed_batch = torch.flip(source_batch, dims=[1]) # reverse the batch across rows.\n                source_batch = (source_batch + reversed_batch)//2 # adding reversed data to source data by averaging\n            \n            if(cellType == 'LSTM'):\n                encoder_initial_state = (encoder_initial_state, encoder.getInitialState())\n                \n            encoder_states = encoder(source_batch,encoder_initial_state)\n\n            decoder_current_state = encoder_states[-1, :, :, :] # this selects the last state from encoder states\n\n            encoder_final_layer_states = encoder_states[:, -1, :, :] # this selects the hidden top layers from each sequence\n\n            # decoder_current_input = torch.full((batchsize,1),0, device=device)#it fills torch with 0s becaus '{' is mappped to zeroes\n\n            #embd_input = decoder.embedding(decoder_current_input)\n\n            #curr_embd = F.relu(embd_input)            \n\n            #Here I need to get the encoder states\n\n            #here you should change\n            \n            #print(encoder_output)\n            #success till here3\n            \n            \n            loss = 0 # decoder starts form \n            \n            output_seq_len = target_batch.shape[1] # here you will get as name justified. 40\n            attentions = []\n            decoder_actual_output = []\n            #print(target_batch)\n            \n            randNumber = random.random()\n\n            \n\n            for i in range(0,output_seq_len):\n\n                if(i == 0):\n                    decoder_current_input = torch.full((batchsize,1),0, device=device)\n                    #decoder_input_tensor = target_batch[:, i].reshape(batchsize,1) #32*1\n                    #print(dec_input_tensor.shape)\n                else:\n                    if randNumber < tf_ratio:\n                        decoder_current_input = target_batch[:, i].reshape(batchsize, 1)\n                        #decoder_input_tensor = target_batch[:, i].reshape(batchsize, 1) # current batch is passed\n                    else:\n                        decoder_current_input = decoder_current_input.reshape(batchsize, 1)\n                        #decoder_input_tensor = decoder_input_tensor.reshape(batchsize, 1) # prev result is passed\n\n                decoder_output, decoder_current_state, attn_weights = decoder(decoder_current_input, decoder_current_state, encoder_final_layer_states)\n                \n                attentions.append(attn_weights)\n                topv, topi = decoder_output.topk(1)\n                decoder_current_input = topi.squeeze().detach()\n                decoder_actual_output.append(decoder_current_input)\n                decoder_output = decoder_output[:, -1, :]\n                curr_target_chars = target_batch[:, i] #(32)\n                curr_target_chars = curr_target_chars.type(dtype=torch.long)\n                loss+=(lossFunction(decoder_output, curr_target_chars))\n\n                # #print(curr_target_chars.shape) #32\n                # decoder_output, decoder_curr_state = decoder(decoder_input_tensor,decoder_curr_state)\n                # #print(decoder_output.shape) #(32*1*67) but your output is (32*1*65) becz ur output size is 65\n                # topv, topi = decoder_output.topk(1)  # you will get top vales and their indices.\n                # #print(\"topv\", topv)\n                # decoder_input_tensor = topi.squeeze().detach()  # here whatever top softmax indeces are present but converted to 1 dimension\n                # #print(decoder_input_tensor.shape)\n                # decoder_actual_output.append(decoder_input_tensor) # softmax values are attached                    \n                        \n                # decoder_output = decoder_output[:, -1, :] #it is just reduce the size from (32*1*67) to (32*67)\n                # #print(decoder_output.shape,curr_target_chars.shape)\n                # #print(decoder_output.shape,curr_target_chars.shape)\n\n                # curr_target_chars = target_batch[:, i] #(32)\n                # curr_target_chars = curr_target_chars.type(dtype=torch.long)\n                # #print(curr_target_chars)\n                \n                # loss+=(lossFunction(decoder_output, curr_target_chars)) # you are passing 32*67 softmax values to curr_target_chars which has the 32*1\n            \n            decoder_actual_output = torch.cat(decoder_actual_output,dim=0).reshape(output_seq_len,batchsize).transpose(0,1)\n            train_accuracy += (decoder_actual_output == target_batch).all(dim=1).sum().item()\n            # tensor_2d = torch.stack(decoder_actual_output)\n            # decoder_actual_output = tensor_2d.t() #it is outside the for loop\n            # #print(decoder_actual_output) #32*40\n            # if(batch_num == 0 and epoch == epochs-1):\n            #     numToCharConverter(target_batch,decoder_actual_output,data) \n                \n            # train_accuracy += (decoder_actual_output == target_batch).all(dim=1).sum().item() # it is simple just summing up the equal values\n\n            train_loss += (loss.item()/output_seq_len)\n            \n            if(batch_num%200 == 0):\n                print(\"bt:\", batch_num, \" loss:\", loss.item()/output_seq_len)\n            #'k'/24\n            # here you get the actual word letters seqeunces softamx indeces\n            #[[0,1,2],[0,1,2]] = [shr,ram] 32*40\n            #correct = (decoder_actual_output == target_batch).all(dim=1).sum().item()\n            #accuracy = accuracy + correct\n            encoderOptimizer.zero_grad()\n            decoderOptimizer.zero_grad()\n            loss.backward()\n            encoderOptimizer.step()\n            decoderOptimizer.step()\n            \n        print(\"train_accuracy\",train_accuracy/512)\n        print(\"train_loss\",train_loss)\n        #wandb.log({'train_accuracy':train_accuracy/512})\n        #wandb.log({'train_loss':train_loss})\n        #validationAccuracy(encoder,decoder,batchsize,tf_ratio,cellType,bidirection)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T09:50:02.105531Z","iopub.execute_input":"2024-05-15T09:50:02.106080Z","iopub.status.idle":"2024-05-15T09:50:02.144889Z","shell.execute_reply.started":"2024-05-15T09:50:02.106030Z","shell.execute_reply":"2024-05-15T09:50:02.143606Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"\n\n\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n    \n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def numToCharConverter(inputArray,outputArray,data):\n    mp = data['num_char_map_2']\n    t1 = ''\n    t2 = ''\n    for row1, row2 in zip(inputArray,outputArray):\n        t1=''\n        t2=''\n        for e1, e2 in zip(row1,row2):\n            t1+=mp[e1.item()]\n            t2+=mp[e2.item()]\n        print(t1,\" \",t2)\n            \n        \n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-15T07:28:41.182961Z","iopub.execute_input":"2024-05-15T07:28:41.183382Z","iopub.status.idle":"2024-05-15T07:28:41.196374Z","shell.execute_reply.started":"2024-05-15T07:28:41.183348Z","shell.execute_reply":"2024-05-15T07:28:41.195296Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def main_fun():\n    wandb.init(project ='vanillaRNN')\n    params = wandb.config\n    with wandb.init(project = 'vanillaRNN', name='embedding'+str(params.embSize)+'cellType'+params.cellType+'batchSize'+str(params.batchsize)) as run:\n        train(params.embSize,params.encoderLayers,params.decoderLayers,params.hiddenLayerNuerons,params.cellType,params.bidirection,params.dropout,params.epochs,params.batchsize,params.learningRate,params.optimizer,params.tf_ratio)\n    \nsweep_params = {\n    'method' : 'bayes',\n    'name'   : 'DeepLearningAssignment3',\n    'metric' : {\n        'goal' : 'maximize',\n        'name' : 'validation_accuracy',\n    },\n    'parameters' : {\n        'embSize':{'values':[16,32,64]},\n        'encoderLayers':{'values':[1,5,10]},\n        'decoderLayers' : {'values' : [1,5,10]},\n        'hiddenLayerNuerons'   : {'values' : [64,256,512]},\n        'cellType' : {'values' : ['GRU','RNN','LSTM'] } ,\n        'bidirection' : {'values' : ['no','Yes']},\n        'dropout' : {'values' : [0,0.2,0.3]},\n        'epochs'  : {'values': [10,15]},\n        'batchsize' : {'values' : [32,64]},\n        'learningRate' : {'values' : [1e-2,1e-3,1e-4]},\n        'optimizer':{'values' : ['Adam','Nadam']},\n        'tf_ratio' :{'values' : [0.2,0.4,0.5]}\n    }\n}\nsweepId = wandb.sweep(sweep_params,project = 'vanillaRNN')\nwandb.agent(sweepId,function =main_fun,count = 5)\nwandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-05-15T07:28:41.199017Z","iopub.execute_input":"2024-05-15T07:28:41.199627Z","iopub.status.idle":"2024-05-15T08:38:29.506654Z","shell.execute_reply.started":"2024-05-15T07:28:41.199595Z","shell.execute_reply":"2024-05-15T08:38:29.505720Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n","output_type":"stream"},{"name":"stdout","text":"Create sweep with ID: wfr3ae6t\nSweep URL: https://wandb.ai/dlassignment/vanillaRNN/sweeps/wfr3ae6t\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xr6pmaml with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchsize: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirection: Yes\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcellType: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoderLayers: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembSize: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoderLayers: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n\u001b[34m\u001b[1mwandb\u001b[0m: \thiddenLayerNuerons: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearningRate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: Nadam\n\u001b[34m\u001b[1mwandb\u001b[0m: \ttf_ratio: 0.5\n","output_type":"stream"},{"name":"stdout","text":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))\n<IPython.core.display.HTML object>\n<IPython.core.display.HTML object>\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\nException in thread ChkStopThr:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\nException in thread NetStatThr:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 286, in check_stop_status\n    self._loop_check_status(\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 224, in _loop_check_status\n    local_handle = request()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface.py\", line 840, in deliver_stop_status\nException in thread IntMsgThr:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n    return self._deliver_stop_status(status)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 494, in _deliver_stop_status\n    self.run()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 268, in check_network_status\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 300, in check_internal_messages\n    self._loop_check_status(\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 224, in _loop_check_status\n    self._loop_check_status(\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 224, in _loop_check_status\n    local_handle = request()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface.py\", line 848, in deliver_network_status\n    local_handle = request()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface.py\", line 856, in deliver_internal_messages\n    return self._deliver_network_status(status)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 510, in _deliver_network_status\n    return self._deliver_internal_messages(internal_message)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 516, in _deliver_internal_messages\n    return self._deliver_record(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 459, in _deliver_record\n    return self._deliver_record(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 459, in _deliver_record\n    return self._deliver_record(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 459, in _deliver_record\n    handle = mailbox._deliver_record(record, interface=self)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py\", line 455, in _deliver_record\n    handle = mailbox._deliver_record(record, interface=self)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py\", line 455, in _deliver_record\n    interface._publish(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n    handle = mailbox._deliver_record(record, interface=self)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py\", line 455, in _deliver_record\n    self._sock_client.send_record_publish(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n    interface._publish(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n    self.send_server_request(server_req)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n    self._sock_client.send_record_publish(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n    self._send_message(msg)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n    self.send_server_request(server_req)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n    self._sendall_with_error_handle(header + data)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n    self._send_message(msg)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n    sent = self._sock.send(data)\nBrokenPipeError: [Errno 32] Broken pipe\n    interface._publish(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n    self._sock_client.send_record_publish(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n    self.send_server_request(server_req)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n    self._send_message(msg)\n      File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n    self._sendall_with_error_handle(header + data)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n    sent = self._sock.send(data)\nBrokenPipeError: [Errno 32] Broken pipe\nself._sendall_with_error_handle(header + data)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n    sent = self._sock.send(data)\nBrokenPipeError: [Errno 32] Broken pipe\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240515_072847-xr6pmaml</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/dlassignment/vanillaRNN/runs/xr6pmaml' target=\"_blank\">lyric-sweep-1</a></strong> to <a href='https://wandb.ai/dlassignment/vanillaRNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dlassignment/vanillaRNN/sweeps/wfr3ae6t' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN/sweeps/wfr3ae6t</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/dlassignment/vanillaRNN' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/dlassignment/vanillaRNN/sweeps/wfr3ae6t' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN/sweeps/wfr3ae6t</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/dlassignment/vanillaRNN/runs/xr6pmaml' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN/runs/xr6pmaml</a>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:xr6pmaml) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">lyric-sweep-1</strong> at: <a href='https://wandb.ai/dlassignment/vanillaRNN/runs/xr6pmaml' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN/runs/xr6pmaml</a><br/> View project at: <a href='https://wandb.ai/dlassignment/vanillaRNN' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240515_072847-xr6pmaml/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:xr6pmaml). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240515_072904-xr6pmaml</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/dlassignment/vanillaRNN/runs/xr6pmaml' target=\"_blank\">embedding32cellTypeGRUbatchSize32</a></strong> to <a href='https://wandb.ai/dlassignment/vanillaRNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dlassignment/vanillaRNN/sweeps/wfr3ae6t' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN/sweeps/wfr3ae6t</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/dlassignment/vanillaRNN' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/dlassignment/vanillaRNN/sweeps/wfr3ae6t' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN/sweeps/wfr3ae6t</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/dlassignment/vanillaRNN/runs/xr6pmaml' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN/runs/xr6pmaml</a>"},"metadata":{}},{"name":"stdout","text":"bt: 0  loss: 4.17201100225034\nbt: 200  loss: 1.801003995149032\nbt: 400  loss: 1.6598310055940046\nbt: 600  loss: 1.5628060050632642\nbt: 800  loss: 1.6551956508470618\nbt: 1000  loss: 1.417924632196841\nbt: 1200  loss: 1.602037346881369\nbt: 1400  loss: 1.4742587545643682\ntrain_accuracy 0.0\ntrain_loss 2562.4446843188744\nbt: 0  loss: 1.2942536395529043\nbt: 20  loss: 1.2127191294794497\nbt: 40  loss: 1.2638737222422725\nbt: 60  loss: 1.3427477297575579\nbt: 80  loss: 1.2160535066024116\nbt: 100  loss: 1.3008383046025815\nbt: 120  loss: 1.2913244496221128\nvalidation_accuracy 0.0\nvalidation_loss 161.00431160304856\nbt: 0  loss: 1.6632176274838655\nbt: 200  loss: 1.6422976618227751\nbt: 400  loss: 1.610021508258322\nbt: 600  loss: 1.3719864720883577\nbt: 800  loss: 1.4327327894127888\nbt: 1000  loss: 1.5642363506814707\nbt: 1200  loss: 1.731187737506369\nbt: 1400  loss: 1.618018274721892\ntrain_accuracy 0.0\ntrain_loss 2493.6533070439914\nbt: 0  loss: 1.127367931863536\nbt: 20  loss: 1.192779126374618\nbt: 40  loss: 1.1083349974259087\nbt: 60  loss: 1.2157350623089334\nbt: 80  loss: 1.3522965804390286\nbt: 100  loss: 1.3722913990850034\nbt: 120  loss: 1.283120694367782\nvalidation_accuracy 0.0\nvalidation_loss 155.51398949001143\nbt: 0  loss: 1.5945179151452107\nbt: 200  loss: 1.466363989788553\nbt: 400  loss: 1.5215503858483357\nbt: 600  loss: 1.5384315822435461\nbt: 800  loss: 1.4109108966329824\nbt: 1000  loss: 1.5607253364894702\nbt: 1200  loss: 1.5534243376358696\nbt: 1400  loss: 1.5132278774095618\ntrain_accuracy 0.0\ntrain_loss 2463.220983671106\nbt: 0  loss: 1.1619373819102412\nbt: 20  loss: 1.3694657035495923\nbt: 40  loss: 1.2701158108918562\nbt: 60  loss: 1.1097956947658374\nbt: 80  loss: 1.2477295087731404\nbt: 100  loss: 1.2268520852793818\nbt: 120  loss: 1.162607358849567\nvalidation_accuracy 0.0\nvalidation_loss 154.4431654888651\nbt: 0  loss: 1.2962635703708814\nbt: 200  loss: 1.4804690817128057\nbt: 400  loss: 1.489487191905146\nbt: 600  loss: 1.576432932978091\nbt: 800  loss: 1.3708224089249321\nbt: 1000  loss: 1.4708382979683254\nbt: 1200  loss: 1.4882105951723845\nbt: 1400  loss: 1.4762518509574558\ntrain_accuracy 0.0\ntrain_loss 2407.2811804232397\nbt: 0  loss: 1.239918335624363\nbt: 20  loss: 1.1326218480649202\nbt: 40  loss: 1.1457719388215437\nbt: 60  loss: 1.1810256294582202\nbt: 80  loss: 1.1978375808052395\nbt: 100  loss: 1.1330067178477412\nbt: 120  loss: 1.0263155232305112\nvalidation_accuracy 0.0\nvalidation_loss 152.07362573043162\nbt: 0  loss: 1.6527860890264097\nbt: 200  loss: 1.4351192971934443\nbt: 400  loss: 1.6167813176694124\nbt: 600  loss: 1.4620535477347996\nbt: 800  loss: 1.5873305279275645\nbt: 1000  loss: 1.578295832094939\nbt: 1200  loss: 1.606908715289572\nbt: 1400  loss: 1.4082512233568274\ntrain_accuracy 0.0\ntrain_loss 2312.631080129867\nbt: 0  loss: 1.0764740653659985\nbt: 20  loss: 1.11608190121858\nbt: 40  loss: 1.0490908415421196\nbt: 60  loss: 1.0084590911865234\nbt: 80  loss: 1.1077026698900305\nbt: 100  loss: 1.0514012212338655\nbt: 120  loss: 1.1121031719705332\nvalidation_accuracy 0.0\nvalidation_loss 140.17323709570837\nbt: 0  loss: 1.2507320901621943\nbt: 200  loss: 1.4270613297172214\nbt: 400  loss: 1.417860279912534\nbt: 600  loss: 1.498589391293733\nbt: 800  loss: 1.3170408165973166\nbt: 1000  loss: 1.3782172825025476\nbt: 1200  loss: 1.2179436061693274\nbt: 1400  loss: 1.3038188270900561\ntrain_accuracy 0.001953125\ntrain_loss 2191.188135312951\nbt: 0  loss: 1.0268304244331692\nbt: 20  loss: 1.1409374734629756\nbt: 40  loss: 0.8747590106466542\nbt: 60  loss: 1.0596457771632983\nbt: 80  loss: 1.1879957447881284\nbt: 100  loss: 0.9769607212232507\nbt: 120  loss: 1.0213944808296536\nvalidation_accuracy 0.0\nvalidation_loss 131.91290954921558\nbt: 0  loss: 1.4803221329398777\nbt: 200  loss: 1.2566948766293733\nbt: 400  loss: 1.3495916283648948\nbt: 600  loss: 1.2349681024966033\nbt: 800  loss: 1.2616518269414487\nbt: 1000  loss: 1.2018013829770295\nbt: 1200  loss: 1.175251172936481\nbt: 1400  loss: 1.3376466502314028\ntrain_accuracy 0.0078125\ntrain_loss 2041.4100107939328\nbt: 0  loss: 1.099114874134893\nbt: 20  loss: 0.9962559575619905\nbt: 40  loss: 1.060817635577658\nbt: 60  loss: 1.0474556632663892\nbt: 80  loss: 1.1007216909657354\nbt: 100  loss: 1.005471768586532\nbt: 120  loss: 0.8777157327403193\nvalidation_accuracy 0.048828125\nvalidation_loss 121.61635730577552\nbt: 0  loss: 1.098411808843198\nbt: 200  loss: 1.0165125805398691\nbt: 400  loss: 0.6733937885450281\nbt: 600  loss: 1.3338045866593071\nbt: 800  loss: 1.1294484345809273\nbt: 1000  loss: 1.1946795090385105\nbt: 1200  loss: 1.0841325676959495\nbt: 1400  loss: 0.4567936607029127\ntrain_accuracy 0.375\ntrain_loss 1588.5536144505372\nbt: 0  loss: 0.35709405981976056\nbt: 20  loss: 0.4027056486710258\nbt: 40  loss: 0.30496302894924\nbt: 60  loss: 0.9457612244979196\nbt: 80  loss: 0.36971195884372876\nbt: 100  loss: 0.3571441069893215\nbt: 120  loss: 0.383502255315366\nvalidation_accuracy 3.7841796875\nvalidation_loss 82.80656086880228\nbt: 0  loss: 1.1583203025486157\nbt: 200  loss: 0.43639013041620667\nbt: 400  loss: 0.3767220870308254\nbt: 600  loss: 0.38729821080746857\nbt: 800  loss: 0.27113450091818103\nbt: 1000  loss: 0.3555540001910666\nbt: 1200  loss: 1.216559368631114\nbt: 1400  loss: 1.2195742233939793\ntrain_accuracy 3.771484375\ntrain_loss 1246.880551794301\nbt: 0  loss: 0.9127767811650815\nbt: 20  loss: 0.24991634617681088\nbt: 40  loss: 0.9904701398766559\nbt: 60  loss: 0.2873615596605384\nbt: 80  loss: 1.0343545001486074\nbt: 100  loss: 0.25416434329489\nbt: 120  loss: 0.7632821124532948\nvalidation_accuracy 9.4970703125\nvalidation_loss 70.312280136606\nbt: 0  loss: 1.3771219668181047\nbt: 200  loss: 1.2324018893034563\nbt: 400  loss: 0.5763143456500509\nbt: 600  loss: 0.2601624364438264\nbt: 800  loss: 1.1596255095108696\nbt: 1000  loss: 0.16779136657714844\nbt: 1200  loss: 1.2500517471976902\nbt: 1400  loss: 1.2315954125445823\ntrain_accuracy 12.501953125\ntrain_loss 1118.7398616438331\nbt: 0  loss: 0.9683599057404891\nbt: 20  loss: 0.8705941075864045\nbt: 40  loss: 0.9607748777970023\nbt: 60  loss: 0.9514130302097487\nbt: 80  loss: 0.8975241287894871\nbt: 100  loss: 0.89630068903384\nbt: 120  loss: 0.07925508851590364\nvalidation_accuracy 26.953125\nvalidation_loss 67.945529460907\nbt: 0  loss: 0.09763641979383386\nbt: 200  loss: 1.1606561411981997\nbt: 400  loss: 0.08593928813934326\nbt: 600  loss: 1.2315398506496265\nbt: 800  loss: 1.1047890704611074\nbt: 1000  loss: 1.1114016823146655\nbt: 1200  loss: 0.12303367904994798\nbt: 1400  loss: 1.0384613534678584\ntrain_accuracy 26.76953125\ntrain_loss 1026.7877992028766\nbt: 0  loss: 0.7620949952498727\nbt: 20  loss: 0.9232696035633916\nbt: 40  loss: 0.05240509821021039\nbt: 60  loss: 0.054421735846478005\nbt: 80  loss: 0.07045989969502324\nbt: 100  loss: 0.05609070218127707\nbt: 120  loss: 0.10199131136355193\nvalidation_accuracy 27.1240234375\nvalidation_loss 69.92584650412849\nbt: 0  loss: 0.08913871516352115\nbt: 200  loss: 0.06015707098919412\nbt: 400  loss: 0.06418903495954431\nbt: 600  loss: 0.96874883900518\nbt: 800  loss: 1.2071610326352327\nbt: 1000  loss: 0.03982542908709982\nbt: 1200  loss: 0.05529747838559358\nbt: 1400  loss: 1.2091790904169497\ntrain_accuracy 33.548828125\ntrain_loss 979.875760446424\nbt: 0  loss: 0.04419491602026898\nbt: 20  loss: 0.9240569239077361\nbt: 40  loss: 0.03268176576365595\nbt: 60  loss: 0.07126292456751285\nbt: 80  loss: 0.03838282046110734\nbt: 100  loss: 1.0779859294062075\nbt: 120  loss: 0.043984293937683105\nvalidation_accuracy 34.7412109375\nvalidation_loss 62.51101380327475\nbt: 0  loss: 0.046880856804225754\nbt: 200  loss: 1.1276124042013418\nbt: 400  loss: 0.03917135881341022\nbt: 600  loss: 0.03444610989612082\nbt: 800  loss: 1.0815132804538892\nbt: 1000  loss: 1.1163733938465947\nbt: 1200  loss: 0.030562304932138195\nbt: 1400  loss: 1.0632602857506794\ntrain_accuracy 36.73828125\ntrain_loss 945.4217620142128\nbt: 0  loss: 0.0647640902063121\nbt: 20  loss: 0.04593665185181991\nbt: 40  loss: 0.7967333586319633\nbt: 60  loss: 0.04122146575347237\nbt: 80  loss: 0.05394647950711458\nbt: 100  loss: 0.9294370568316915\nbt: 120  loss: 0.049408425455508026\nvalidation_accuracy 39.8193359375\nvalidation_loss 56.5036341742329\nbt: 0  loss: 0.031476821588433304\nbt: 200  loss: 1.2392621247664741\nbt: 400  loss: 0.03975859413976255\nbt: 600  loss: 1.158101869666058\nbt: 800  loss: 1.1464007004447605\nbt: 1000  loss: 1.1619312452233357\nbt: 1200  loss: 1.071391478828762\nbt: 1400  loss: 0.03853850261024807\ntrain_accuracy 37.94140625\ntrain_loss 920.9393116909524\nbt: 0  loss: 0.02792244631311168\nbt: 20  loss: 0.8273070791493291\nbt: 40  loss: 0.9575016187584918\nbt: 60  loss: 0.02764989759611047\nbt: 80  loss: 0.08353551574375319\nbt: 100  loss: 0.055806004482766854\nbt: 120  loss: 0.873930143273395\nvalidation_accuracy 44.140625\nvalidation_loss 51.67545383779898\n{ఎదుర్కోగలరని}}}}}}}}}}   {ఎదురుస్్్్ా}}}}}}}}}}}\n{విడదియ్యటానికి}}}}}}}}   {వియ్రస్ు్ాు}}}}}}}}}}}\n{కూర్చోబెట్టాల}}}}}}}}}   {యూర్చుపోవ్నాన}}}}}}}}}\n{మిల్లా}}}}}}}}}}}}}}}}   {మిల్లా}}}}}}}}}}}}}}}}\n{తలకోనకు}}}}}}}}}}}}}}}   {తలుుుుు}}}}}}}}}}}}}}}\n{మాటకెంత}}}}}}}}}}}}}}}   {మాటలలన}}}}}}}}}}}}}}}}\n{భరించిందే}}}}}}}}}}}}}   {భరిచచంాన}}}}}}}}}}}}}}\n{అతడికైనా}}}}}}}}}}}}}}   {ఆడిల్్ి}}}}}}}}}}}}}}}\n{స్వాజీకి}}}}}}}}}}}}}}   {స్వా్్}}}}}}}}}}}}}}}}\n{మురిగిపోయేలా}}}}}}}}}}   {ముర్ధిప్స్ంి}}}}}}}}}}\n{రాజాన్స్}}}}}}}}}}}}}}   {రాజా}}}}}}}}}}}}}}}}}}\n{చిరికోటిబిబ్}}}}}}}}}}   {చిర్రులిరాల}}}}}}}}}}}\n{చిమ్మకాయ}}}}}}}}}}}}}}   {చింగర్ల}}}}}}}}}}}}}}}\n{బెస్ను}}}}}}}}}}}}}}}}   {జీస్స్}}}}}}}}}}}}}}}}\n{వర్షించనుంది}}}}}}}}}}   {ఆర్పించాంి}}}}}}}}}}}}\n{తెచ్చినోళ్లే}}}}}}}}}}   {తెప్చిచోచ్ంి}}}}}}}}}}\n{పరిశోధనలనుంచి}}}}}}}}}   {పరిపితింుుుు్న}}}}}}}}\n{ప్రశ్నే}}}}}}}}}}}}}}}   {ప్రశ్త}}}}}}}}}}}}}}}}\n{ఫర్కన్}}}}}}}}}}}}}}}}   {కార్ట్}}}}}}}}}}}}}}}}\n{తిరునక్షత్రం}}}}}}}}}}   {తిగుగసి్్్్ల}}}}}}}}}}\n{నిందాపూరితంగా}}}}}}}}}   {నింగుుుుుునన}}}}}}}}}}\n{వైష్టం}}}}}}}}}}}}}}}}   {వవశ్స్త}}}}}}}}}}}}}}}\n{స్ట్రోమ్డాహ్ల్}}}}}}}}   {స్టుర్లాల}}}}}}}}}}}}}\n{మాట్లాడిస్తున్నట్లు}}}   {మాట్లిటోుుుటనన}}}}}}}}\n{సహస్రధారలతో}}}}}}}}}}}   {సహ్రరరరుాుల}}}}}}}}}}}\n{కోరుకుంటన్నారు}}}}}}}}   {కొరుకుంటంంటన}}}}}}}}}}\n{ఏరుకునేవాళ్లు}}}}}}}}}   {ఎరురుతునునా}}}}}}}}}}}\n{కిష్కిందా}}}}}}}}}}}}}   {క్ష్పింాి}}}}}}}}}}}}}\n{పెద్దవయ్యే}}}}}}}}}}}}   {పెట్టాా్టి}}}}}}}}}}}}\n{అభ్యంతరకరమైన}}}}}}}}}}   {అభ్థారరంాాాన}}}}}}}}}}\n{గువిలి}}}}}}}}}}}}}}}}   {గుల్లి}}}}}}}}}}}}}}}}\n{ఈసంవత్సరాంతానికి}}}}}}   {ఎమసారరరరుుాన}}}}}}}}}}\nbt: 0  loss: 1.0534902655560037\nbt: 200  loss: 0.024304483247839886\nbt: 400  loss: 0.03786525259847227\nbt: 600  loss: 1.0850666709568189\nbt: 800  loss: 1.0216722903044329\nbt: 1000  loss: 1.0428135913351309\nbt: 1200  loss: 1.0782121575396995\nbt: 1400  loss: 0.038854534211366074\ntrain_accuracy 39.564453125\ntrain_loss 897.1239530858804\nbt: 0  loss: 0.8835569464642069\nbt: 20  loss: 0.7052044246507727\nbt: 40  loss: 0.9188914920972742\nbt: 60  loss: 0.03031436775041663\nbt: 80  loss: 0.8152998219365659\nbt: 100  loss: 0.8085630665654722\nbt: 120  loss: 0.03961873831956283\nvalidation_accuracy 35.7421875\nvalidation_loss 62.28702826992322\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▁▁▁▁▁▁▁▂▃▆▇▇██</td></tr><tr><td>train_loss</td><td>███▇▇▆▆▄▂▂▂▁▁▁▁</td></tr><tr><td>validation_accuracy</td><td>▁▁▁▁▁▁▁▂▃▅▅▇▇█▇</td></tr><tr><td>validation_loss</td><td>███▇▇▆▅▃▂▂▂▂▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>39.56445</td></tr><tr><td>train_loss</td><td>897.12395</td></tr><tr><td>validation_accuracy</td><td>35.74219</td></tr><tr><td>validation_loss</td><td>62.28703</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">embedding32cellTypeGRUbatchSize32</strong> at: <a href='https://wandb.ai/dlassignment/vanillaRNN/runs/xr6pmaml' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN/runs/xr6pmaml</a><br/> View project at: <a href='https://wandb.ai/dlassignment/vanillaRNN' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240515_072904-xr6pmaml/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: a0hhtfsf with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchsize: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirection: no\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcellType: RNN\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoderLayers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembSize: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoderLayers: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n\u001b[34m\u001b[1mwandb\u001b[0m: \thiddenLayerNuerons: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearningRate: 0.01\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: Nadam\n\u001b[34m\u001b[1mwandb\u001b[0m: \ttf_ratio: 0.4\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240515_075521-a0hhtfsf</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/dlassignment/vanillaRNN/runs/a0hhtfsf' target=\"_blank\">peach-sweep-2</a></strong> to <a href='https://wandb.ai/dlassignment/vanillaRNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dlassignment/vanillaRNN/sweeps/wfr3ae6t' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN/sweeps/wfr3ae6t</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/dlassignment/vanillaRNN' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/dlassignment/vanillaRNN/sweeps/wfr3ae6t' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN/sweeps/wfr3ae6t</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/dlassignment/vanillaRNN/runs/a0hhtfsf' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN/runs/a0hhtfsf</a>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:a0hhtfsf) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">peach-sweep-2</strong> at: <a href='https://wandb.ai/dlassignment/vanillaRNN/runs/a0hhtfsf' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN/runs/a0hhtfsf</a><br/> View project at: <a href='https://wandb.ai/dlassignment/vanillaRNN' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240515_075521-a0hhtfsf/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:a0hhtfsf). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240515_075538-a0hhtfsf</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/dlassignment/vanillaRNN/runs/a0hhtfsf' target=\"_blank\">embedding64cellTypeRNNbatchSize64</a></strong> to <a href='https://wandb.ai/dlassignment/vanillaRNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dlassignment/vanillaRNN/sweeps/wfr3ae6t' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN/sweeps/wfr3ae6t</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/dlassignment/vanillaRNN' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/dlassignment/vanillaRNN/sweeps/wfr3ae6t' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN/sweeps/wfr3ae6t</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/dlassignment/vanillaRNN/runs/a0hhtfsf' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN/runs/a0hhtfsf</a>"},"metadata":{}},{"name":"stdout","text":"bt: 0  loss: 4.291961006496264\nbt: 200  loss: 1.7214018780252207\nbt: 400  loss: 1.7379226684570312\nbt: 600  loss: 1.921964396601138\ntrain_accuracy 0.0\ntrain_loss 1527.3696050229264\nbt: 0  loss: 1.546673816183339\nbt: 20  loss: 1.4377152816109036\nbt: 40  loss: 1.4004037276558254\nbt: 60  loss: 1.4360341611115828\nvalidation_accuracy 0.0\nvalidation_loss 92.4030394346818\nbt: 0  loss: 1.6823529782502546\nbt: 200  loss: 1.7320747375488281\nbt: 400  loss: 1.7785107156504756\nbt: 600  loss: 1.7556895380434783\ntrain_accuracy 0.0\ntrain_loss 1391.083103014076\nbt: 0  loss: 1.487120255180027\nbt: 20  loss: 1.4626086691151494\nbt: 40  loss: 1.5826260110606318\nbt: 60  loss: 1.4829048488451086\nvalidation_accuracy 0.0\nvalidation_loss 99.01114306242567\nbt: 0  loss: 2.0641608860181724\nbt: 200  loss: 1.7648526067319124\nbt: 400  loss: 1.8312766033670176\nbt: 600  loss: 1.896785072658373\ntrain_accuracy 0.0\ntrain_loss 1438.1221059716265\nbt: 0  loss: 1.5113374461298403\nbt: 20  loss: 1.4867905326511548\nbt: 40  loss: 1.4564303522524626\nbt: 60  loss: 1.379009080969769\nvalidation_accuracy 0.0\nvalidation_loss 91.34464313672937\nbt: 0  loss: 1.8614002725352412\nbt: 200  loss: 1.8201572584069294\nbt: 400  loss: 1.7190443951150645\nbt: 600  loss: 1.783195329749066\ntrain_accuracy 0.0\ntrain_loss 1393.6188855378516\nbt: 0  loss: 1.4471603061841882\nbt: 20  loss: 1.4787717072860054\nbt: 40  loss: 1.469523056693699\nbt: 60  loss: 1.4479250700577446\nvalidation_accuracy 0.0\nvalidation_loss 93.66752765489659\nbt: 0  loss: 1.790840314782184\nbt: 200  loss: 1.7859309652577275\nbt: 400  loss: 1.8269681515900984\nbt: 600  loss: 2.079483695652174\ntrain_accuracy 0.0\ntrain_loss 1502.482427182404\nbt: 0  loss: 1.683825617251189\nbt: 20  loss: 1.6929211823836616\nbt: 40  loss: 1.63079717884893\nbt: 60  loss: 1.737904921821926\nvalidation_accuracy 0.0\nvalidation_loss 106.03530353048572\nbt: 0  loss: 2.0820684018342392\nbt: 200  loss: 1.920938077180282\nbt: 400  loss: 2.051772573719854\nbt: 600  loss: 2.07146984597911\ntrain_accuracy 0.0\ntrain_loss 1656.8473008197293\nbt: 0  loss: 1.600878674051036\nbt: 20  loss: 1.6805763244628906\nbt: 40  loss: 1.7948769279148267\nbt: 60  loss: 1.665556700333305\nvalidation_accuracy 0.0\nvalidation_loss 107.87246239703634\nbt: 0  loss: 2.026605357294497\nbt: 200  loss: 2.074179276176121\nbt: 400  loss: 2.0271959719450576\nbt: 600  loss: 2.093682164731233\ntrain_accuracy 0.0\ntrain_loss 1657.5960787897516\nbt: 0  loss: 1.54504510630732\nbt: 20  loss: 1.6251890762992527\nbt: 40  loss: 1.6890565623407778\nbt: 60  loss: 1.8001090339992358\nvalidation_accuracy 0.0\nvalidation_loss 107.57110064962636\nbt: 0  loss: 2.0994738703188687\nbt: 200  loss: 2.054904606031335\nbt: 400  loss: 2.280276754628057\nbt: 600  loss: 2.0484602554984717\ntrain_accuracy 0.0\ntrain_loss 1656.2539429042647\nbt: 0  loss: 1.7310434424358865\nbt: 20  loss: 1.5980949401855469\nbt: 40  loss: 1.6014590056046196\nbt: 60  loss: 1.682493790336277\nvalidation_accuracy 0.0\nvalidation_loss 108.21848297119146\nbt: 0  loss: 2.152898705523947\nbt: 200  loss: 2.167802230171535\nbt: 400  loss: 1.967217486837636\nbt: 600  loss: 2.1385083405867866\ntrain_accuracy 0.0\ntrain_loss 1651.9205411828102\nbt: 0  loss: 1.658902707307235\nbt: 20  loss: 1.6799805682638418\nbt: 40  loss: 1.7222890439240828\nbt: 60  loss: 1.671360679294752\nvalidation_accuracy 0.0\nvalidation_loss 109.5568365014118\nbt: 0  loss: 2.0279094861901323\nbt: 200  loss: 2.107432987378991\nbt: 400  loss: 2.07972584600034\nbt: 600  loss: 2.017144078793733\ntrain_accuracy 0.0\ntrain_loss 1631.97968491264\nbt: 0  loss: 1.6382663560950237\nbt: 20  loss: 1.6879992277725884\nbt: 40  loss: 1.6942949709684954\nbt: 60  loss: 1.6899258157481318\nvalidation_accuracy 0.0\nvalidation_loss 105.31602494612982\nbt: 0  loss: 2.023535852846892\nbt: 200  loss: 2.030293671981148\nbt: 400  loss: 2.1074303336765454\nbt: 600  loss: 2.0176542530889097\ntrain_accuracy 0.0\ntrain_loss 1647.6860361513886\nbt: 0  loss: 1.6026639523713484\nbt: 20  loss: 1.6751491712487263\nbt: 40  loss: 1.697379900061566\nbt: 60  loss: 1.6638599893321162\nvalidation_accuracy 0.0\nvalidation_loss 107.0778908107592\nbt: 0  loss: 2.060012319813604\nbt: 200  loss: 1.960739633311396\nbt: 400  loss: 2.0361804132876187\nbt: 600  loss: 2.018839794656505\ntrain_accuracy 0.0\ntrain_loss 1643.3068316915753\nbt: 0  loss: 1.6876799541970957\nbt: 20  loss: 1.553901838219684\nbt: 40  loss: 1.6753591454547385\nbt: 60  loss: 1.5400694142217222\nvalidation_accuracy 0.0\nvalidation_loss 104.58129634027895\nbt: 0  loss: 2.0075101437775986\nbt: 200  loss: 2.0730143008024795\nbt: 400  loss: 2.0184739154318105\nbt: 600  loss: 2.1158293019170347\ntrain_accuracy 0.0\ntrain_loss 1636.355870122493\nbt: 0  loss: 1.6735567839249321\nbt: 20  loss: 1.5892149883767832\nbt: 40  loss: 1.584981337837551\nbt: 60  loss: 1.6733789858610735\nvalidation_accuracy 0.0\nvalidation_loss 105.37589562457542\nbt: 0  loss: 2.0930965257727583\nbt: 200  loss: 2.05468633900518\nbt: 400  loss: 2.024747433869735\nbt: 600  loss: 2.047683218251104\ntrain_accuracy 0.0\ntrain_loss 1638.18312951793\nbt: 0  loss: 1.7217103709345278\nbt: 20  loss: 1.7567549995754077\nbt: 40  loss: 1.7087218243142832\nbt: 60  loss: 1.5920882846998132\nvalidation_accuracy 0.0\nvalidation_loss 105.55723687876826\n{వాటికి}}}}}}}}}}}}}}}}   {సి}}}}}}}}}}}}}}}}}}}}\n{అవకాశాల్లేకపోలేదని}}}}   {పా}}}}}}}}}}}}}}}}}}}}\n{వాగ్యుద్ధమే}}}}}}}}}}}   {ప}}}}}}}}}}}}}}}}}}}}}\n{నిపోతున్నాయి}}}}}}}}}}   {పా}}}}}}}}}}}}}}}}}}}}\n{విశాస్త్రితో}}}}}}}}}}   {సా్}}}}}}}}}}}}}}}}}}}\n{పెంచమంటారా}}}}}}}}}}}}   {సా}}}}}}}}}}}}}}}}}}}}\n{ఎస్సెల్వీ}}}}}}}}}}}}}   {సా}}}}}}}}}}}}}}}}}}}}\n{గొంతునిచ్చాడు}}}}}}}}}   {ప}్}}}}}}}}}}}}}}}}}}}\n{కొడుకుదే}}}}}}}}}}}}}}   {సా}}}}}}}}}}}}}}}}}}}}\n{దేవాలయాల్లోనూ}}}}}}}}}   {ప}ర}}}}}}}}}}}}}}}}}}}\n{ఉసికొల్పి}}}}}}}}}}}}}   {పా}}}}}}}}}}}}}}}}}}}}\n{ఇంటెనకాలి}}}}}}}}}}}}}   {అా}}}}}}}}}}}}}}}}}}}}\n{ఒడిగట్టకండి}}}}}}}}}}}   {మార}}}}}}}}}}}}}}}}}}}\n{వేదాంత్కళ}}}}}}}}}}}}}   {పా}}}}}}}}}}}}}}}}}}}}\n{వ్యాసాన్నే}}}}}}}}}}}}   {పా్}}}}}}}}}}}}}}}}}}}\n{కమెడియన్కి}}}}}}}}}}}}   {స}}}}}}}}}}}}}}}}}}}}}\n{వెయ్యకు}}}}}}}}}}}}}}}   {అా}}}}}}}}}}}}}}}}}}}}\n{ఆధికారికంగానే}}}}}}}}}   {మా}}}}}}}}}}}}}}}}}}}}\n{వూచకోతలో}}}}}}}}}}}}}}   {ప}}}}}}}}}}}}}}}}}}}}}\n{అంతరాష్ట్రం}}}}}}}}}}}   {పా}}}}}}}}}}}}}}}}}}}}\n{కవును}}}}}}}}}}}}}}}}}   {సా్}}}}}}}}}}}}}}}}}}}\n{ప్రతిఫలించదు}}}}}}}}}}   {సి}}}}}}}}}}}}}}}}}}}}\n{తడుపుకుంటూ}}}}}}}}}}}}   {ప}}}}}}}}}}}}}}}}}}}}}\n{వూడ్చుకు}}}}}}}}}}}}}}   {పా}}}}}}}}}}}}}}}}}}}}\n{రాప్కార్}}}}}}}}}}}}}}   {పా}}}}}}}}}}}}}}}}}}}}\n{దృక్పథపు}}}}}}}}}}}}}}   {వ}}}}}}}}}}}}}}}}}}}}}\n{ఆత్మాశ్రయుడై}}}}}}}}}}   {అా}}}}}}}}}}}}}}}}}}}}\n{అభిమానుల్లోంచి}}}}}}}}   {పా్}}}}}}}}}}}}}}}}}}}\n{పాట్లుంటాయి}}}}}}}}}}}   {ప}}}}}}}}}}}}}}}}}}}}}\n{వైభవంగా}}}}}}}}}}}}}}}   {సా}}}}}}}}}}}}}}}}}}}}\n{మార్చినెలల}}}}}}}}}}}}   {పా}}}}}}}}}}}}}}}}}}}}\n{దుప్పటితో}}}}}}}}}}}}}   {పి}}}}}}}}}}}}}}}}}}}}\n{ప్రస్థావం}}}}}}}}}}}}}   {ప}}}}}}}}}}}}}}}}}}}}}\n{ఆసామికి}}}}}}}}}}}}}}}   {స}}}}}}}}}}}}}}}}}}}}}\n{ఆచరించేవారే}}}}}}}}}}}   {స}}}}}}}}}}}}}}}}}}}}}\n{వచ్చితివో}}}}}}}}}}}}}   {పా}}}}}}}}}}}}}}}}}}}}\n{మహిరాఖాన్}}}}}}}}}}}}}   {పె}}}}}}}}}}}}}}}}}}}}\n{మార్కేట్లో}}}}}}}}}}}}   {అ}}}}}}}}}}}}}}}}}}}}}\n{రాజాత్తి}}}}}}}}}}}}}}   {స}}}}}}}}}}}}}}}}}}}}}\n{పూణాలోని}}}}}}}}}}}}}}   {సె}}}}}}}}}}}}}}}}}}}}\n{మృదులాస్థుడు}}}}}}}}}}   {పా}}}}}}}}}}}}}}}}}}}}\n{మెనెలాస్కు}}}}}}}}}}}}   {పార}}}}}}}}}}}}}}}}}}}\n{అప్పెలెట్}}}}}}}}}}}}}   {ప}}}}}}}}}}}}}}}}}}}}}\n{పట్టణమంతటా}}}}}}}}}}}}   {సా}}}}}}}}}}}}}}}}}}}}\n{క్రూరాత్ములు}}}}}}}}}}   {సా}}}}}}}}}}}}}}}}}}}}\n{సమర్ధించాము}}}}}}}}}}}   {పి}}}}}}}}}}}}}}}}}}}}\n{సాస్లలోని}}}}}}}}}}}}}   {ప}ర}}}}}}}}}}}}}}}}}}}\n{మార్గదర్శనమూ}}}}}}}}}}   {పా}}}}}}}}}}}}}}}}}}}}\n{ఒప్పకుంటానని}}}}}}}}}}   {సా}}}}}}}}}}}}}}}}}}}}\n{గురింతి}}}}}}}}}}}}}}}   {సా}}}}}}}}}}}}}}}}}}}}\n{డబ్బులతోనో}}}}}}}}}}}}   {పా్}}}}}}}}}}}}}}}}}}}\n{కడిగించే}}}}}}}}}}}}}}   {స్}}}}}}}}}}}}}}}}}}}}\n{నగరబాటలో}}}}}}}}}}}}}}   {సా}}}}}}}}}}}}}}}}}}}}\n{ప్రదేశమేగాక}}}}}}}}}}}   {ప}}}}}}}}}}}}}}}}}}}}}\n{బహుమతికే}}}}}}}}}}}}}}   {ప}}}}}}}}}}}}}}}}}}}}}\n{కల్లచన్}}}}}}}}}}}}}}}   {సా}}}}}}}}}}}}}}}}}}}}\n{పగలుపూట}}}}}}}}}}}}}}}   {అ}}}}}}}}}}}}}}}}}}}}}\n{ఖిన్నులై}}}}}}}}}}}}}}   {అార}}}}}}}}}}}}}}}}}}}\n{ఏర్పడినాయట}}}}}}}}}}}}   {సా}}}}}}}}}}}}}}}}}}}}\n{శ్రీవామ}}}}}}}}}}}}}}}   {స}}}}}}}}}}}}}}}}}}}}}\n{ఆమెకుండదు}}}}}}}}}}}}}   {}ా}}}}}}}}}}}}}}}}}}}}\n{పడలేనన్న}}}}}}}}}}}}}}   {పా}}}}}}}}}}}}}}}}}}}}\n{మూడులక్షలపైగా}}}}}}}}}   {పా}}}}}}}}}}}}}}}}}}}}\n{ఆవుపాద}}}}}}}}}}}}}}}}   {ప}}}}}}}}}}}}}}}}}}}}}\nbt: 0  loss: 1.9154586791992188\nbt: 200  loss: 2.0343631246815557\nbt: 400  loss: 1.9644286114236582\nbt: 600  loss: 2.0388213447902515\ntrain_accuracy 0.0\ntrain_loss 1637.7922595480181\nbt: 0  loss: 1.6031832487686821\nbt: 20  loss: 1.5338735165803328\nbt: 40  loss: 1.6080940910007642\nbt: 60  loss: 1.6303692693295686\nvalidation_accuracy 0.0\nvalidation_loss 105.22263336181638\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.027 MB of 0.027 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>▅▁▂▁▄████▇██▇▇▇</td></tr><tr><td>validation_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_loss</td><td>▁▄▁▂▇▇▇▇█▆▇▆▆▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>0.0</td></tr><tr><td>train_loss</td><td>1637.79226</td></tr><tr><td>validation_accuracy</td><td>0.0</td></tr><tr><td>validation_loss</td><td>105.22263</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">embedding64cellTypeRNNbatchSize64</strong> at: <a href='https://wandb.ai/dlassignment/vanillaRNN/runs/a0hhtfsf' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN/runs/a0hhtfsf</a><br/> View project at: <a href='https://wandb.ai/dlassignment/vanillaRNN' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240515_075538-a0hhtfsf/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 044prx1b with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchsize: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirection: no\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcellType: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoderLayers: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembSize: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoderLayers: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thiddenLayerNuerons: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearningRate: 0.0001\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: Adam\n\u001b[34m\u001b[1mwandb\u001b[0m: \ttf_ratio: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240515_080611-044prx1b</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/dlassignment/vanillaRNN/runs/044prx1b' target=\"_blank\">ancient-sweep-3</a></strong> to <a href='https://wandb.ai/dlassignment/vanillaRNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dlassignment/vanillaRNN/sweeps/wfr3ae6t' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN/sweeps/wfr3ae6t</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/dlassignment/vanillaRNN' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/dlassignment/vanillaRNN/sweeps/wfr3ae6t' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN/sweeps/wfr3ae6t</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/dlassignment/vanillaRNN/runs/044prx1b' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN/runs/044prx1b</a>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:044prx1b) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">ancient-sweep-3</strong> at: <a href='https://wandb.ai/dlassignment/vanillaRNN/runs/044prx1b' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN/runs/044prx1b</a><br/> View project at: <a href='https://wandb.ai/dlassignment/vanillaRNN' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240515_080611-044prx1b/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:044prx1b). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240515_080628-044prx1b</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/dlassignment/vanillaRNN/runs/044prx1b' target=\"_blank\">embedding32cellTypeLSTMbatchSize32</a></strong> to <a href='https://wandb.ai/dlassignment/vanillaRNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dlassignment/vanillaRNN/sweeps/wfr3ae6t' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN/sweeps/wfr3ae6t</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/dlassignment/vanillaRNN' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/dlassignment/vanillaRNN/sweeps/wfr3ae6t' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN/sweeps/wfr3ae6t</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/dlassignment/vanillaRNN/runs/044prx1b' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN/runs/044prx1b</a>"},"metadata":{}},{"name":"stdout","text":"bt: 0  loss: 4.160850193189538\nbt: 200  loss: 1.5415752245032268\nbt: 400  loss: 1.4989519533903704\nbt: 600  loss: 1.5197906494140625\nbt: 800  loss: 1.4059358679729959\nbt: 1000  loss: 1.537321671195652\nbt: 1200  loss: 1.58685070535411\nbt: 1400  loss: 1.465985505477242\ntrain_accuracy 0.0\ntrain_loss 2564.729053994882\nbt: 0  loss: 1.1325773985489556\nbt: 20  loss: 1.1426699265189793\nbt: 40  loss: 1.110105265741763\nbt: 60  loss: 1.209818052208942\nbt: 80  loss: 1.1471962306810461\nbt: 100  loss: 1.2203822757886804\nbt: 120  loss: 1.3005457339079485\nvalidation_accuracy 0.0\nvalidation_loss 154.21738516766086\nbt: 0  loss: 1.5103313611901326\nbt: 200  loss: 1.5464857350225034\nbt: 400  loss: 1.5244215260381284\nbt: 600  loss: 1.4848176707392153\nbt: 800  loss: 1.5982420548148777\nbt: 1000  loss: 1.4503666421641475\nbt: 1200  loss: 1.4919946090034817\nbt: 1400  loss: 1.3714148479959238\ntrain_accuracy 0.0\ntrain_loss 2400.3036344777015\nbt: 0  loss: 1.199162192966627\nbt: 20  loss: 1.218340666397758\nbt: 40  loss: 1.169425632642663\nbt: 60  loss: 1.1612417801566746\nbt: 80  loss: 1.1328639154848845\nbt: 100  loss: 1.1245775637419329\nbt: 120  loss: 1.0936860623567\nvalidation_accuracy 0.0\nvalidation_loss 147.20606571695077\nbt: 0  loss: 1.4164951158606487\nbt: 200  loss: 1.3993528614873472\nbt: 400  loss: 1.362871501756751\nbt: 600  loss: 1.5448309856912363\nbt: 800  loss: 1.375689630923064\nbt: 1000  loss: 1.4220060265582541\nbt: 1200  loss: 1.3579201905623726\nbt: 1400  loss: 1.2610840175462805\ntrain_accuracy 0.0\ntrain_loss 2243.930893276048\nbt: 0  loss: 1.0432432423467222\nbt: 20  loss: 1.0663633761198625\nbt: 40  loss: 0.9943796240765116\nbt: 60  loss: 1.0582935499108357\nbt: 80  loss: 0.9246114647906759\nbt: 100  loss: 0.9314892810323964\nbt: 120  loss: 0.916751944500467\nvalidation_accuracy 0.0\nvalidation_loss 132.67727337712824\nbt: 0  loss: 1.3948243182638418\nbt: 200  loss: 1.2116686779519785\nbt: 400  loss: 1.2731619295866594\nbt: 600  loss: 1.292760185573412\nbt: 800  loss: 1.1758919591489045\nbt: 1000  loss: 1.2658642478611157\nbt: 1200  loss: 1.314869092858356\nbt: 1400  loss: 1.0682589489480723\ntrain_accuracy 0.00390625\ntrain_loss 1971.3272388292373\nbt: 0  loss: 0.8930886310079823\nbt: 20  loss: 0.8150455640709918\nbt: 40  loss: 1.0059972845989724\nbt: 60  loss: 0.829021868498429\nbt: 80  loss: 0.8363809170930282\nbt: 100  loss: 0.7589584018873132\nbt: 120  loss: 0.9668065775995669\nvalidation_accuracy 0.0244140625\nvalidation_loss 111.66033031629482\nbt: 0  loss: 1.2890661488408628\nbt: 200  loss: 1.1161709661069124\nbt: 400  loss: 1.0791964323624321\nbt: 600  loss: 1.1379211259924846\nbt: 800  loss: 1.0937248727549678\nbt: 1000  loss: 1.0494927945344343\nbt: 1200  loss: 1.0240031532619311\nbt: 1400  loss: 1.060432185297427\ntrain_accuracy 0.04296875\ntrain_loss 1650.597515272057\nbt: 0  loss: 0.7147750025210173\nbt: 20  loss: 0.6902449649313221\nbt: 40  loss: 0.6846699921981149\nbt: 60  loss: 0.6174734779026197\nbt: 80  loss: 0.7176132202148438\nbt: 100  loss: 0.6548000418621561\nbt: 120  loss: 0.6364328964896824\nvalidation_accuracy 0.9521484375\nvalidation_loss 90.2742038395094\nbt: 0  loss: 0.9357091654901919\nbt: 200  loss: 0.9385318756103516\nbt: 400  loss: 0.9320149629012399\nbt: 600  loss: 0.7830032680345618\nbt: 800  loss: 0.9621918719747792\nbt: 1000  loss: 0.8198279505190642\nbt: 1200  loss: 0.8426989679751189\nbt: 1400  loss: 0.639062093651813\ntrain_accuracy 0.484375\ntrain_loss 1356.5620085260164\nbt: 0  loss: 0.6251727809076724\nbt: 20  loss: 0.49482494851817255\nbt: 40  loss: 0.6160384468410326\nbt: 60  loss: 0.6269261318704357\nbt: 80  loss: 0.539171550584876\nbt: 100  loss: 0.47749461298403534\nbt: 120  loss: 0.5350127012833304\nvalidation_accuracy 2.587890625\nvalidation_loss 77.14128166696302\nbt: 0  loss: 0.7506546352220618\nbt: 200  loss: 0.7589057424794072\nbt: 400  loss: 0.6637666536414105\nbt: 600  loss: 0.6611448370892069\nbt: 800  loss: 0.667396586874257\nbt: 1000  loss: 0.6758628098861031\nbt: 1200  loss: 0.7772608217985734\nbt: 1400  loss: 0.6038232471631921\ntrain_accuracy 2.03125\ntrain_loss 1125.0972333161733\nbt: 0  loss: 0.5052923534227454\nbt: 20  loss: 0.5382708673891814\nbt: 40  loss: 0.5289710915606954\nbt: 60  loss: 0.5505399289338485\nbt: 80  loss: 0.49706454899000085\nbt: 100  loss: 0.5867692698603091\nbt: 120  loss: 0.49137924028479535\nvalidation_accuracy 6.591796875\nvalidation_loss 64.00992882770043\nbt: 0  loss: 0.5010470514712126\nbt: 200  loss: 0.6709703777147376\nbt: 400  loss: 0.6974309009054432\nbt: 600  loss: 0.5592412948608398\nbt: 800  loss: 0.42829658674157184\nbt: 1000  loss: 0.6090940392535665\nbt: 1200  loss: 0.5506185863329016\nbt: 1400  loss: 0.6013525257939878\ntrain_accuracy 5.10546875\ntrain_loss 945.2180298929635\nbt: 0  loss: 0.37919019616168476\nbt: 20  loss: 0.42124205050261126\nbt: 40  loss: 0.3959275950556216\nbt: 60  loss: 0.39486839460289996\nbt: 80  loss: 0.5014197722725247\nbt: 100  loss: 0.5064323674077573\nbt: 120  loss: 0.4529260552447775\nvalidation_accuracy 11.7431640625\nvalidation_loss 56.50316706947659\nbt: 0  loss: 0.5384176503057065\nbt: 200  loss: 0.5276060519011124\nbt: 400  loss: 0.4783735689909562\nbt: 600  loss: 0.4913041487984035\nbt: 800  loss: 0.4741288475368334\nbt: 1000  loss: 0.4583980726159137\nbt: 1200  loss: 0.5995893063752548\nbt: 1400  loss: 0.5832435773766559\ntrain_accuracy 10.09375\ntrain_loss 795.8817406529971\nbt: 0  loss: 0.3073170910710874\nbt: 20  loss: 0.3792700145555579\nbt: 40  loss: 0.3381067773570185\nbt: 60  loss: 0.4638702973075535\nbt: 80  loss: 0.44662367779275647\nbt: 100  loss: 0.4100791267726732\nbt: 120  loss: 0.44314430070960004\nvalidation_accuracy 18.5791015625\nvalidation_loss 50.869084192358926\n{ఆస్తినంతటినీ}}}}}}}}}}   {ఆస్తినంటటిని}}}}}}}}}}\n{అవోలెరా}}}}}}}}}}}}}}}   {అవోల్రా}}}}}}}}}}}}}}}\n{గడపడానికి}}}}}}}}}}}}}   {గడపడడిిక}}}}}}}}}}}}}}\n{యుటిఆర్}}}}}}}}}}}}}}}   {ఉట్ఎ్}}}}}}}}}}}}}}}}}\n{స్పష్టమవుతోది}}}}}}}}}   {స్షష్థమవుతుడి}}}}}}}}}\n{పిడుగుపడ్డట్టైంది}}}}}   {పిదుదుడడడప్టటుంటి}}}}}\n{సమయమిద్దాం}}}}}}}}}}}}   {సమయమిద్దంం}}}}}}}}}}}}\n{మాస్టర్బెషన్}}}}}}}}}}   {మాస్టరర్కన్}}}}}}}}}}}\n{చేయించుకోలేకపోయారని}}}   {చేయించుకోలోకోవోయని}}}}\n{రాష్ట్రకూటుల}}}}}}}}}}   {రాస్త్రకుతుల}}}}}}}}}}\n{చుక్కమూతి}}}}}}}}}}}}}   {చూక్కమోతి}}}}}}}}}}}}}\n{ఎవోఖ్}}}}}}}}}}}}}}}}}   {ఎవోక్}}}}}}}}}}}}}}}}}\n{నిమిరే}}}}}}}}}}}}}}}}   {నినిరే}్}}}}}}}}}}}}}}\n{దుమ్కాను}}}}}}}}}}}}}}   {దుంకను}}}}}}}}}}}}}}}}\n{ఒకళ్ళింటికి}}}}}}}}}}}   {ఒకల్లింటికి}}}}}}}}}}}\n{దురైస్వామి}}}}}}}}}}}}   {దురాస్రయయ్}}}}}}}}}}}}\n{చేసుకోలేకపోయాడా}}}}}}}   {చేసుకోలేపోపోడడ}}}}}}}}\n{అనిపించిందంతే}}}}}}}}}   {అనిపించిందంట}}}}}}}}}}\n{నారదమునిని}}}}}}}}}}}}   {నారడుునిని}}}}}}}}}}}}\n{పట్టుకెళ్లిపోయారు}}}}}   {పట్టుకెళ్లికోవారు}}}}}\n{కళ్లజూసి}}}}}}}}}}}}}}   {కల్లాేసిి}}}}}}}}}}}}}\n{బీమాగా}}}}}}}}}}}}}}}}   {బీమగగా}}}}}}}}}}}}}}}}\n{ప్రజలపక్షం}}}}}}}}}}}}   {ప్రజలలక్షంం}}}}}}}}}}}\n{ముఖకవళికలకి}}}}}}}}}}}   {ముకకవేవకలకి}}}}}}}}}}}\n{వస్తుధ్వనితో}}}}}}}}}}   {వస్తుదియనితో}}}}}}}}}}\n{నవ్వగలరు}}}}}}}}}}}}}}   {నవ్వగగాుు}}}}}}}}}}}}}\n{ఉద్ధవుడిని}}}}}}}}}}}}   {ఉద్ధవుడిని}}}}}}}}}}}}\n{ఊడిపడినవ్}}}}}}}}}}}}}   {ఊడిదడినా్}}}}}}}}}}}}}\n{విద్యాసంబంధ}}}}}}}}}}}   {విద్యారంంంం}}}}}}}}}}}\n{స్వర్ణకారులందరికీ}}}}}   {స్వర్ణాారుుంవరికి}}}}}\n{దాఖైలన}}}}}}}}}}}}}}}}   {దాకమలన}}}}}}}}}}}}}}}}\n{శైవుడు}}}}}}}}}}}}}}}}   {సావుడు}}}}}}}}}}}}}}}}\nbt: 0  loss: 0.5102785773899244\nbt: 200  loss: 0.4153262843256411\nbt: 400  loss: 0.6156148081240447\nbt: 600  loss: 0.375902797864831\nbt: 800  loss: 0.46572987929634424\nbt: 1000  loss: 0.36627085312553076\nbt: 1200  loss: 0.3792861026266347\nbt: 1400  loss: 0.30222129821777344\ntrain_accuracy 15.83203125\ntrain_loss 680.7480548568393\nbt: 0  loss: 0.4534004874851393\nbt: 20  loss: 0.3329901073289954\nbt: 40  loss: 0.44632542651632556\nbt: 60  loss: 0.24814394245976987\nbt: 80  loss: 0.31174483506575873\nbt: 100  loss: 0.550629242606785\nbt: 120  loss: 0.33487577023713483\nvalidation_accuracy 22.0458984375\nvalidation_loss 43.47931130036064\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.026 MB uploaded\\r'), FloatProgress(value=0.0524951393389501, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▁▁▁▁▁▂▃▅█</td></tr><tr><td>train_loss</td><td>█▇▇▆▅▄▃▂▁▁</td></tr><tr><td>validation_accuracy</td><td>▁▁▁▁▁▂▃▅▇█</td></tr><tr><td>validation_loss</td><td>██▇▅▄▃▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>15.83203</td></tr><tr><td>train_loss</td><td>680.74805</td></tr><tr><td>validation_accuracy</td><td>22.0459</td></tr><tr><td>validation_loss</td><td>43.47931</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">embedding32cellTypeLSTMbatchSize32</strong> at: <a href='https://wandb.ai/dlassignment/vanillaRNN/runs/044prx1b' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN/runs/044prx1b</a><br/> View project at: <a href='https://wandb.ai/dlassignment/vanillaRNN' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240515_080628-044prx1b/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4rpznt5d with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchsize: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirection: no\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcellType: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoderLayers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembSize: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoderLayers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thiddenLayerNuerons: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearningRate: 0.0001\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: Nadam\n\u001b[34m\u001b[1mwandb\u001b[0m: \ttf_ratio: 0.4\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240515_082602-4rpznt5d</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/dlassignment/vanillaRNN/runs/4rpznt5d' target=\"_blank\">snowy-sweep-4</a></strong> to <a href='https://wandb.ai/dlassignment/vanillaRNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dlassignment/vanillaRNN/sweeps/wfr3ae6t' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN/sweeps/wfr3ae6t</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/dlassignment/vanillaRNN' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/dlassignment/vanillaRNN/sweeps/wfr3ae6t' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN/sweeps/wfr3ae6t</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/dlassignment/vanillaRNN/runs/4rpznt5d' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN/runs/4rpznt5d</a>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:4rpznt5d) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">snowy-sweep-4</strong> at: <a href='https://wandb.ai/dlassignment/vanillaRNN/runs/4rpznt5d' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN/runs/4rpznt5d</a><br/> View project at: <a href='https://wandb.ai/dlassignment/vanillaRNN' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240515_082602-4rpznt5d/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:4rpznt5d). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240515_082619-4rpznt5d</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/dlassignment/vanillaRNN/runs/4rpznt5d' target=\"_blank\">embedding16cellTypeLSTMbatchSize64</a></strong> to <a href='https://wandb.ai/dlassignment/vanillaRNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dlassignment/vanillaRNN/sweeps/wfr3ae6t' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN/sweeps/wfr3ae6t</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/dlassignment/vanillaRNN' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/dlassignment/vanillaRNN/sweeps/wfr3ae6t' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN/sweeps/wfr3ae6t</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/dlassignment/vanillaRNN/runs/4rpznt5d' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN/runs/4rpznt5d</a>"},"metadata":{}},{"name":"stdout","text":"bt: 0  loss: 4.170070814049763\nbt: 200  loss: 1.5839113981827446\nbt: 400  loss: 1.6531413534413213\nbt: 600  loss: 1.6648066976796025\ntrain_accuracy 0.0\ntrain_loss 1355.6090854976487\nbt: 0  loss: 1.159553859544837\nbt: 20  loss: 1.1315325861391814\nbt: 40  loss: 1.2465030006740405\nbt: 60  loss: 1.3091647935950237\nvalidation_accuracy 0.0\nvalidation_loss 76.80896195121433\nbt: 0  loss: 1.4673650990361753\nbt: 200  loss: 1.3585336933965269\nbt: 400  loss: 1.558106795601223\nbt: 600  loss: 1.592110011888587\ntrain_accuracy 0.044921875\ntrain_loss 1119.250143299931\nbt: 0  loss: 1.204714070195737\nbt: 20  loss: 0.7435647715692935\nbt: 40  loss: 1.205215537029764\nbt: 60  loss: 0.7824585956075917\nvalidation_accuracy 0.48828125\nvalidation_loss 67.55105756676714\nbt: 0  loss: 1.5526137973951257\nbt: 200  loss: 0.8169065558392069\nbt: 400  loss: 0.7116193356721298\nbt: 600  loss: 0.6157037486200747\ntrain_accuracy 2.013671875\ntrain_loss 986.5183951336401\nbt: 0  loss: 0.5290522782698922\nbt: 20  loss: 1.3377064414646314\nbt: 40  loss: 0.5244542826776919\nbt: 60  loss: 0.5555494557256284\nvalidation_accuracy 5.3466796875\nvalidation_loss 65.70448751034944\nbt: 0  loss: 1.7128196384595789\nbt: 200  loss: 1.6500590780506963\nbt: 400  loss: 1.5771089636761209\nbt: 600  loss: 1.6120547419009001\ntrain_accuracy 8.705078125\ntrain_loss 891.6518234170007\nbt: 0  loss: 0.3260542413462763\nbt: 20  loss: 1.201287891553796\nbt: 40  loss: 1.1468119413956352\nbt: 60  loss: 1.222307951554008\nvalidation_accuracy 9.27734375\nvalidation_loss 62.377944697504454\nbt: 0  loss: 1.5278814564580503\nbt: 200  loss: 1.520372141962466\nbt: 400  loss: 1.4844207763671875\nbt: 600  loss: 1.5924395685610564\ntrain_accuracy 16.1171875\ntrain_loss 846.479045515474\nbt: 0  loss: 1.1413564267365828\nbt: 20  loss: 1.236674681953762\nbt: 40  loss: 1.2021500131358271\nbt: 60  loss: 0.2622721506201703\nvalidation_accuracy 14.9658203125\nvalidation_loss 57.67440941022789\nbt: 0  loss: 0.3378838456195334\nbt: 200  loss: 0.22703809323518173\nbt: 400  loss: 1.5737276491911516\nbt: 600  loss: 0.1572460298952849\ntrain_accuracy 25.189453125\ntrain_loss 769.5833160980884\nbt: 0  loss: 1.1426743217136548\nbt: 20  loss: 0.1516358645065971\nbt: 40  loss: 1.1778864653214165\nbt: 60  loss: 0.13638402068096658\nvalidation_accuracy 30.6396484375\nvalidation_loss 45.63624300127442\nbt: 0  loss: 1.4422625666079314\nbt: 200  loss: 1.549263166344684\nbt: 400  loss: 1.4684667172639265\nbt: 600  loss: 0.10664794756018597\ntrain_accuracy 30.224609375\ntrain_loss 739.7982533081713\nbt: 0  loss: 0.10314940369647482\nbt: 20  loss: 1.1002355658489724\nbt: 40  loss: 0.10161495208740234\nbt: 60  loss: 1.0615732773490574\nvalidation_accuracy 26.9287109375\nvalidation_loss 50.34406081489895\nbt: 0  loss: 0.10016138657279637\nbt: 200  loss: 1.4205653978430706\nbt: 400  loss: 1.4423418459684954\nbt: 600  loss: 1.4387892018193784\ntrain_accuracy 33.552734375\ntrain_loss 713.8087481467618\nbt: 0  loss: 1.200245484061863\nbt: 20  loss: 0.0634149053822393\nbt: 40  loss: 1.1377589184304941\nbt: 60  loss: 0.06831232879472815\nvalidation_accuracy 38.37890625\nvalidation_loss 43.82923144879549\nbt: 0  loss: 1.4659201580545176\nbt: 200  loss: 1.4876717277195142\nbt: 400  loss: 0.05712969406791355\nbt: 600  loss: 1.4123480423637058\ntrain_accuracy 37.0234375\ntrain_loss 680.8997768396918\nbt: 0  loss: 0.061244902403458305\nbt: 20  loss: 1.0824098172395125\nbt: 40  loss: 0.05769320156263268\nbt: 60  loss: 1.0159152487049932\nvalidation_accuracy 30.0537109375\nvalidation_loss 48.14885036323382\n{శబ్దంకు}}}}}}}}}}}}}}}   {కా్్లలు}}}}}}}}}}}}}}}\n{దర్శించుకుంటామన్నది}}}   {పా్్ిిిిుుుుననననన}}}}}\n{తిలబందేశ్వర్}}}}}}}}}}   {పిర్కుు్్్ని}}}}}}}}}}\n{పండుకొనునప్పుడు}}}}}}}   {పా్కిిుుు్్్నన}}}}}}}}\n{రోటీలన్నా}}}}}}}}}}}}}   {కిర్లుని}}}}}}}}}}}}}}\n{ఉండనీయవు}}}}}}}}}}}}}}   {అన్రరలలి}}}}}}}}}}}}}}\n{రూయా}}}}}}}}}}}}}}}}}}   {మాయా}}}}}}}}}}}}}}}}}}\n{గోల్మాన్}}}}}}}}}}}}}}   {మెర్కు}}}}}}}}}}}}}}}}\n{నిర్మాణరంగం}}}}}}}}}}}   {పిర్రాాాాన}}}}}}}}}}}}\n{ఖర్చైనా}}}}}}}}}}}}}}}   {కా్ాాన}}}}}}}}}}}}}}}}\n{చర్మంపైనున్న}}}}}}}}}}   {మా్ిిిుు్ననన}}}}}}}}}}\n{దెంగాన}}}}}}}}}}}}}}}}   {వురాని}}}}}}}}}}}}}}}}\n{పక్కవాటాలోనే}}}}}}}}}}   {కా్్ిి్లన}}}}}}}}}}}}}\n{అంతర్జాతీంగా}}}}}}}}}}   {అదదమాాాననన}}}}}}}}}}}}\n{తుల్యార్థం}}}}}}}}}}}}   {వుర్కులన}}}}}}}}}}}}}}\n{ధనుస్తి}}}}}}}}}}}}}}}   {కా్్లల}}}}}}}}}}}}}}}}\n{గ్రహించకుండానే}}}}}}}}   {ప్ర్ిిిాాాానన}}}}}}}}}\n{న్యూమరీగా}}}}}}}}}}}}}   {స్ర్లల}}}}}}}}}}}}}}}}\n{బోనేసి}}}}}}}}}}}}}}}}   {కిర్క}}}}}}}}}}}}}}}}}\n{చదువుకోరాదని}}}}}}}}}}   {మా్ిిిుుననన}}}}}}}}}}}\n{కాటిడైడ్లు}}}}}}}}}}}}   {కా్్ుులల}}}}}}}}}}}}}}\n{ఖడ్సేపై}}}}}}}}}}}}}}}   {పారాలల}}}}}}}}}}}}}}}}\n{జయదేవునికి}}}}}}}}}}}}   {మా్్ుు్లన}}}}}}}}}}}}}\n{తెలంగాణానాయకులకు}}}}}}   {చీర్చచచచచచచాాాన}}}}}}}\n{ఇవ్వబడినప్పుడు}}}}}}}}   {మా్్ుుు్్్నన}}}}}}}}}}\n{అభప్రాయపడ్డారు}}}}}}}}   {అర్రాాాాాాన}}}}}}}}}}}\n{తొక్కిపడేసింది}}}}}}}}   {వెర్కుుున్ననన}}}}}}}}}\n{వొచ్చని}}}}}}}}}}}}}}}   {మురాా}}}}}}}}}}}}}}}}}\n{రొట్టెముక్కకు}}}}}}}}}   {తెర్కుతు్్న}}}}}}}}}}}\n{దత్తత్రేయను}}}}}}}}}}}   {కా్్ుు్్్న}}}}}}}}}}}}\n{పుల్లలే}}}}}}}}}}}}}}}   {స్ర్ల్}}}}}}}}}}}}}}}}\n{వ్యాసాలున్నాయి}}}}}}}}   {పిర్క్్్నన}}}}}}}}}}}}\n{సాధనన}}}}}}}}}}}}}}}}}   {కాాాా}}}}}}}}}}}}}}}}}\n{విలవిల్లాడుతున్నాయి}}}   {పిర్కిిిుుుుునననని}}}}\n{పెదయాగనమిల్లి}}}}}}}}}   {పిర్రింంంాన}}}}}}}}}}}\n{సుంకిడ్డి}}}}}}}}}}}}}   {ప్ర్ర్్్్్}}}}}}}}}}}}\n{తొలగించడమన్నది}}}}}}}}   {విర్రిిచచచాాాన}}}}}}}}\n{అభీష్టపై}}}}}}}}}}}}}}   {అదదమాాన}}}}}}}}}}}}}}}\n{దుఃఖపడుతున్నాయి}}}}}}}   {పిర్కిిిుుునననన}}}}}}}\n{నాలపించి}}}}}}}}}}}}}}   {పారాాాన}}}}}}}}}}}}}}}\n{అనువదిస్తారు}}}}}}}}}}   {అదదదిి్్నన}}}}}}}}}}}}\n{డకోటాలోని}}}}}}}}}}}}}   {మా్్లలల}}}}}}}}}}}}}}}\n{మఖుమల్}}}}}}}}}}}}}}}}   {మా్లలి}}}}}}}}}}}}}}}}\n{క్రిమినాలిటీ}}}}}}}}}}   {మెర్కుత్్్}}}}}}}}}}}}\n{ముట్టడిలో}}}}}}}}}}}}}   {మెర్లులి}}}}}}}}}}}}}}\n{డిప్రిషన్స్}}}}}}}}}}}   {క్ర్ర్ర్్్్్}}}}}}}}}}\n{పరుపల్లి}}}}}}}}}}}}}}   {కా్్్్్ు}}}}}}}}}}}}}}\n{ఉపయోగిచుకొంటున్నారు}}}   {అర్కిిిుుుుుననననన}}}}}\n{ఉడకబెట్టకూడదు}}}}}}}}}   {అదదదిి్్్ననన}}}}}}}}}}\n{వారించిన}}}}}}}}}}}}}}   {కా్ాాలల}}}}}}}}}}}}}}}\n{తెస్తామా}}}}}}}}}}}}}}   {కిర్లి}}}}}}}}}}}}}}}}\n{పాలుకూరు}}}}}}}}}}}}}}   {కా్్లల}}}}}}}}}}}}}}}}\n{అచ్యునందన్}}}}}}}}}}}}   {అదదదిిిి}}}}}}}}}}}}}}\n{పెగిల్చేలా}}}}}}}}}}}}   {వుర్కులన}}}}}}}}}}}}}}\n{కళ్లుంటేనే}}}}}}}}}}}}   {కా్్్్్్్}}}}}}}}}}}}}\n{స్నానవిధిని}}}}}}}}}}}   {పిరాాాాాన}}}}}}}}}}}}}\n{ఏకాగ్రతలు}}}}}}}}}}}}}   {ప్రాాాలల}}}}}}}}}}}}}}\n{వీక్షకునికి}}}}}}}}}}}   {విర్కింంంన}}}}}}}}}}}}\n{స్కినీ}}}}}}}}}}}}}}}}   {పెర్ల్్్}}}}}}}}}}}}}}\n{భాతం}}}}}}}}}}}}}}}}}}   {కాాా}}}}}}}}}}}}}}}}}}\n{చిందేవరకు}}}}}}}}}}}}}   {చేదేపానని}}}}}}}}}}}}}\n{పైకెగసిన}}}}}}}}}}}}}}   {పా్్ాాన}}}}}}}}}}}}}}}\n{జీవాత్మని}}}}}}}}}}}}}   {చీరాాా}}}}}}}}}}}}}}}}\n{శస్తచ్రికిత్సపైనే}}}}}   {పా్్ిిిుుుుననననన}}}}}}\nbt: 0  loss: 1.3844980156939963\nbt: 200  loss: 0.04118794461955195\nbt: 400  loss: 0.04791898312775985\nbt: 600  loss: 0.03994472130485203\ntrain_accuracy 36.490234375\ntrain_loss 689.4765948653221\nbt: 0  loss: 0.03281387557154116\nbt: 20  loss: 0.03152521796848463\nbt: 40  loss: 1.1312061807383662\nbt: 60  loss: 1.129369652789572\nvalidation_accuracy 34.9609375\nvalidation_loss 44.661467305991955\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▁▁▃▄▆▇▇██</td></tr><tr><td>train_loss</td><td>█▆▄▃▃▂▂▁▁▁</td></tr><tr><td>validation_accuracy</td><td>▁▁▂▃▄▇▆█▆▇</td></tr><tr><td>validation_loss</td><td>█▆▆▅▄▁▂▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>36.49023</td></tr><tr><td>train_loss</td><td>689.47659</td></tr><tr><td>validation_accuracy</td><td>34.96094</td></tr><tr><td>validation_loss</td><td>44.66147</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">embedding16cellTypeLSTMbatchSize64</strong> at: <a href='https://wandb.ai/dlassignment/vanillaRNN/runs/4rpznt5d' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN/runs/4rpznt5d</a><br/> View project at: <a href='https://wandb.ai/dlassignment/vanillaRNN' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240515_082619-4rpznt5d/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: a0n1kyj2 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchsize: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirection: no\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcellType: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoderLayers: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembSize: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoderLayers: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thiddenLayerNuerons: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearningRate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: Nadam\n\u001b[34m\u001b[1mwandb\u001b[0m: \ttf_ratio: 0.4\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240515_083056-a0n1kyj2</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/dlassignment/vanillaRNN/runs/a0n1kyj2' target=\"_blank\">lemon-sweep-5</a></strong> to <a href='https://wandb.ai/dlassignment/vanillaRNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dlassignment/vanillaRNN/sweeps/wfr3ae6t' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN/sweeps/wfr3ae6t</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/dlassignment/vanillaRNN' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/dlassignment/vanillaRNN/sweeps/wfr3ae6t' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN/sweeps/wfr3ae6t</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/dlassignment/vanillaRNN/runs/a0n1kyj2' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN/runs/a0n1kyj2</a>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:a0n1kyj2) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">lemon-sweep-5</strong> at: <a href='https://wandb.ai/dlassignment/vanillaRNN/runs/a0n1kyj2' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN/runs/a0n1kyj2</a><br/> View project at: <a href='https://wandb.ai/dlassignment/vanillaRNN' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240515_083056-a0n1kyj2/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:a0n1kyj2). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240515_083113-a0n1kyj2</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/dlassignment/vanillaRNN/runs/a0n1kyj2' target=\"_blank\">embedding64cellTypeGRUbatchSize64</a></strong> to <a href='https://wandb.ai/dlassignment/vanillaRNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dlassignment/vanillaRNN/sweeps/wfr3ae6t' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN/sweeps/wfr3ae6t</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/dlassignment/vanillaRNN' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/dlassignment/vanillaRNN/sweeps/wfr3ae6t' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN/sweeps/wfr3ae6t</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/dlassignment/vanillaRNN/runs/a0n1kyj2' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN/runs/a0n1kyj2</a>"},"metadata":{}},{"name":"stdout","text":"bt: 0  loss: 4.116538006326427\nbt: 200  loss: 1.612474192743716\nbt: 400  loss: 1.5424806346064028\nbt: 600  loss: 1.4928320179814878\ntrain_accuracy 0.0\ntrain_loss 1295.0366446453584\nbt: 0  loss: 1.27704554018767\nbt: 20  loss: 1.3107788251793904\nbt: 40  loss: 1.137357877648395\nbt: 60  loss: 1.2657728609831438\nvalidation_accuracy 0.0\nvalidation_loss 76.50097830399226\nbt: 0  loss: 1.5021534795346467\nbt: 200  loss: 1.4726254007090693\nbt: 400  loss: 1.5722145412279211\nbt: 600  loss: 1.5139719092327615\ntrain_accuracy 0.0\ntrain_loss 1183.9058399200424\nbt: 0  loss: 1.1798882691756538\nbt: 20  loss: 1.2019999130912449\nbt: 40  loss: 1.1611982428509255\nbt: 60  loss: 1.1276185408882473\nvalidation_accuracy 0.0\nvalidation_loss 72.71501325524372\nbt: 0  loss: 1.429164223048998\nbt: 200  loss: 1.42992815764054\nbt: 400  loss: 1.3617979132610818\nbt: 600  loss: 1.4401964933975884\ntrain_accuracy 0.0\ntrain_loss 1106.6481761932375\nbt: 0  loss: 0.9205502219822096\nbt: 20  loss: 1.015453172766644\nbt: 40  loss: 1.0095050645911174\nbt: 60  loss: 1.1501818117888079\nvalidation_accuracy 0.0\nvalidation_loss 64.96135637034541\nbt: 0  loss: 1.3545151586117952\nbt: 200  loss: 1.1626556230627971\nbt: 400  loss: 1.2794614874798318\nbt: 600  loss: 1.210500717163086\ntrain_accuracy 0.01171875\ntrain_loss 908.6239892296176\nbt: 0  loss: 0.8950915129288383\nbt: 20  loss: 0.9293478260869565\nbt: 40  loss: 0.6178172982257345\nbt: 60  loss: 0.9340397378672725\nvalidation_accuracy 0.1220703125\nvalidation_loss 50.292286624079175\nbt: 0  loss: 1.232200290845788\nbt: 200  loss: 0.5722871034041696\nbt: 400  loss: 0.6362490032030188\nbt: 600  loss: 1.0447939167851987\ntrain_accuracy 0.32421875\ntrain_loss 709.1885346537049\nbt: 0  loss: 0.7229609282120414\nbt: 20  loss: 0.8114860368811566\nbt: 40  loss: 0.7476415219514266\nbt: 60  loss: 0.7420201508895211\nvalidation_accuracy 1.708984375\nvalidation_loss 38.77317619323733\nbt: 0  loss: 1.0540368453316067\nbt: 200  loss: 0.45575996067212976\nbt: 400  loss: 0.8679200877314028\nbt: 600  loss: 0.3126875006634256\ntrain_accuracy 1.927734375\ntrain_loss 586.662330192068\nbt: 0  loss: 0.8273915000583815\nbt: 20  loss: 0.2580188253651495\nbt: 40  loss: 0.24842593980872113\nbt: 60  loss: 0.2438497957975968\nvalidation_accuracy 5.2978515625\nvalidation_loss 34.22287824879522\nbt: 0  loss: 0.3097163490627123\nbt: 200  loss: 0.8994563558827275\nbt: 400  loss: 0.2557810700458029\nbt: 600  loss: 0.7752688864003057\ntrain_accuracy 7.822265625\ntrain_loss 478.7307012288459\nbt: 0  loss: 0.6779027192488961\nbt: 20  loss: 0.6186884589817213\nbt: 40  loss: 0.591083402219026\nbt: 60  loss: 0.13925551331561545\nvalidation_accuracy 11.7919921875\nvalidation_loss 31.719379611637283\nbt: 0  loss: 0.875680342964504\nbt: 200  loss: 0.7201450182043988\nbt: 400  loss: 0.1328496207361636\nbt: 600  loss: 1.7316967508067256\ntrain_accuracy 19.478515625\ntrain_loss 414.7408085128537\nbt: 0  loss: 0.1079862117767334\nbt: 20  loss: 0.5118027977321459\nbt: 40  loss: 0.4633034001226011\nbt: 60  loss: 0.1133429071177607\nvalidation_accuracy 29.58984375\nvalidation_loss 21.995115446007773\nbt: 0  loss: 0.07940603339153787\nbt: 200  loss: 0.7067513673201852\nbt: 400  loss: 0.8414426057235055\nbt: 600  loss: 0.6938457074372665\ntrain_accuracy 28.42578125\ntrain_loss 369.26464910610855\nbt: 0  loss: 0.44223619543987774\nbt: 20  loss: 0.5903875102167544\nbt: 40  loss: 0.36005372586457624\nbt: 60  loss: 0.6164340558259384\nvalidation_accuracy 28.1005859375\nvalidation_loss 23.982240163761645\n{ఇక్కడికొచ్చేది}}}}}}}}   {ఎక్కపిచచచచచచచి}}}}}}}}\n{వైఫలయలను}}}}}}}}}}}}}}   {వైతాాాలను}}}}}}}}}}}}}\n{బుల్లిపెట్టెలో}}}}}}}}   {బుల్లిపోస్టోలో}}}}}}}}\n{ఆపదవి}}}}}}}}}}}}}}}}}   {ఆతువి}}}}}}}}}}}}}}}}}\n{పాట్రిసియో}}}}}}}}}}}}   {పటర్నిక్్}}}}}}}}}}}}}\n{కాల్టెక్స్}}}}}}}}}}}}   {కాస్టిక్స్}}}}}}}}}}}}\n{వత్తేవాడు}}}}}}}}}}}}}   {పట్టివాడుు}}}}}}}}}}}}\n{కాటరాక్ట్స్}}}}}}}}}}}   {కాట్ర్్్స్్}}}}}}}}}}}\n{జయభేరులు}}}}}}}}}}}}}}   {జాాాషలులు}}}}}}}}}}}}}\n{తహతహలాడారు}}}}}}}}}}}}   {జబరరాముారు}}}}}}}}}}}}\n{చందనాడ}}}}}}}}}}}}}}}}   {చందడనడ}}}}}}}}}}}}}}}}\n{సొంతమనుషులే}}}}}}}}}}}   {సోంతాననరరలల}}}}}}}}}}}\n{సమకూర్చుతుండగా}}}}}}}}   {సంకక్కకకుుంంగా}}}}}}}}\n{స్టేడియంను}}}}}}}}}}}}   {స్టెమియననుు}}}}}}}}}}}\n{మాట్లాడినవాళ్ల}}}}}}}}   {మాట్పించిా్్ల}}}}}}}}}\n{భద్రతలకు}}}}}}}}}}}}}}   {జద్రరలలు}}}}}}}}}}}}}}\n{శ్రద్ధాశ్రీనాధ్}}}}}}}   {శ్రనకరరయ్యినం}}}}}}}}}\n{దయామయులైన}}}}}}}}}}}}}   {దహాాాాలలనన}}}}}}}}}}}}\n{తోకలేపి}}}}}}}}}}}}}}}   {తోకలోపి}}}}}}}}}}}}}}}\n{సినిమాకాపీ}}}}}}}}}}}}   {కినినిిి్}}}}}}}}}}}}}\n{సామన్యవ్యక్తిగా}}}}}}}   {సామన్్యి్్్్లగా}}}}}}}\n{చట్టపరమైనవిగా}}}}}}}}}   {చట్టపరరిిిిిా}}}}}}}}}\n{మాటలకై}}}}}}}}}}}}}}}}   {మాటలకి}}}}}}}}}}}}}}}}\n{అడుగులేసాడు}}}}}}}}}}}   {అడుపుపేసాుు}}}}}}}}}}}\n{దించనున్నామని}}}}}}}}}   {దించనననననాని}}}}}}}}}}\n{రాయడంవల్లనే}}}}}}}}}}}   {రామంమాల్లనే}}}}}}}}}}}\n{దామావారిపాలెంలో}}}}}}}   {దామరిపోేేగో}}}}}}}}}}}\n{హంప్యాక్}}}}}}}}}}}}}}   {యింటట్్్}}}}}}}}}}}}}}\n{వెళ్లదీస్తున్నాడని}}}}   {వెల్లిిస్తున్నాని}}}}}\n{చెబుతూవస్తోన్న}}}}}}}}   {చెతుతుప్్్తన్న}}}}}}}}\n{చింతనాపరుడుగా}}}}}}}}}   {చిం్డారుుుంగా}}}}}}}}}\n{ఊళ్ళోవాళ్ళిచ్చిన}}}}}}   {ఎప్లోగాలిిిచిని}}}}}}}\n{హర్కీస్}}}}}}}}}}}}}}}   {హా్్కకస్}}}}}}}}}}}}}}\n{కొట్టుడుపై}}}}}}}}}}}}   {కొట్టుుుటట}}}}}}}}}}}}\n{డోనేషియా}}}}}}}}}}}}}}   {దొనిసియ}}}}}}}}}}}}}}}\n{నర్సర్లు}}}}}}}}}}}}}}   {నర్ర్్లుు}}}}}}}}}}}}}\n{లోపించిందనేది}}}}}}}}}   {లోపించిందదదది}}}}}}}}}\n{చెప్పనున్నారో}}}}}}}}}   {చెప్పునన్నారో}}}}}}}}}\n{ఆంద్రప్రదేశ్లో}}}}}}}}   {అండ్రురరిిి్లో}}}}}}}}\n{ప్లాగ్స్}}}}}}}}}}}}}}   {ప్లోట్స్}}}}}}}}}}}}}}\n{ముగియండగా}}}}}}}}}}}}}   {ముగియంంగా}}}}}}}}}}}}}\n{ఉద్యోగాలివ్వమని}}}}}}}   {ఎద్గిగిలాయవయనని}}}}}}}\n{రెడ్డయ్య}}}}}}}}}}}}}}   {రెద్డాయయ}}}}}}}}}}}}}}\n{ఒప్పడు}}}}}}}}}}}}}}}}   {ఎల్పడడు}}}}}}}}}}}}}}}\n{ఉమ్మితో}}}}}}}}}}}}}}}   {ఎమ్మితో}}}}}}}}}}}}}}}\n{బద్దలవుతాయన్న}}}}}}}}}   {బద్దగలలలాాన్న}}}}}}}}}\n{రాసేపనిలో}}}}}}}}}}}}}   {రాసోపినోో}}}}}}}}}}}}}\n{ప్రాపర్టీల్లో}}}}}}}}}   {ప్రోప్ట్్ిల్లో}}}}}}}}\n{మండపేటకి}}}}}}}}}}}}}}   {మండపోకకక}}}}}}}}}}}}}}\n{వేయబోతున్నారన్న}}}}}}}   {వేయబలతున్నార్్}}}}}}}}\n{సదాభిప్రాయంతో}}}}}}}}}   {సదమరిప్తామంతో}}}}}}}}}\n{దీర్ఘాంత}}}}}}}}}}}}}}   {దీర్యాంంట}}}}}}}}}}}}}\n{ప్రబోధాలను}}}}}}}}}}}}   {ప్రతంవాలను}}}}}}}}}}}}\n{కుటుంబాధిపత్యం}}}}}}}}   {కుతుండడిి్్్ం}}}}}}}}}\n{ప్రతిబింబించేలా}}}}}}}   {ప్రతివిిిచచేేగా}}}}}}}\n{విచ్చుకుంటాయి}}}}}}}}}   {విచ్చుకుంటాయి}}}}}}}}}\n{నిదర్శమంటున్నారు}}}}}}   {నిదరరామంతున్నారు}}}}}}\n{బాలింతలకి}}}}}}}}}}}}}   {బాలింపలలి}}}}}}}}}}}}}\n{ఈశ్వరాంశవని}}}}}}}}}}}   {ఎస్వరమవయయనని}}}}}}}}}}\n{విజ్ఞానానికీ}}}}}}}}}}   {విబ్రనాానికి}}}}}}}}}}\n{ఒదిలేసిన}}}}}}}}}}}}}}   {ఎడిలిసిన}}}}}}}}}}}}}}\n{జరుగుతున్నదాడుల}}}}}}}   {జరుపుతున్నాాంుల}}}}}}}\n{అదరగొట్టాడట}}}}}}}}}}}   {అడరాుత్తుటట}}}}}}}}}}}\n{హోమో}}}}}}}}}}}}}}}}}}   {జీమవో}}}}}}}}}}}}}}}}}\nbt: 0  loss: 0.7111252494480299\nbt: 200  loss: 0.6895334409630817\nbt: 400  loss: 0.6121874270231827\nbt: 600  loss: 0.05513474733933159\ntrain_accuracy 33.6171875\ntrain_loss 335.28178879489064\nbt: 0  loss: 0.4589610721753991\nbt: 20  loss: 0.04183489861695663\nbt: 40  loss: 0.43320125082264777\nbt: 60  loss: 0.49738062982973846\nvalidation_accuracy 39.599609375\nvalidation_loss 18.797042696372326\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.018 MB uploaded\\r'), FloatProgress(value=0.0783155180748778, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▁▁▁▁▁▃▅▇█</td></tr><tr><td>train_loss</td><td>█▇▇▅▄▃▂▂▁▁</td></tr><tr><td>validation_accuracy</td><td>▁▁▁▁▁▂▃▆▆█</td></tr><tr><td>validation_loss</td><td>██▇▅▃▃▃▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>33.61719</td></tr><tr><td>train_loss</td><td>335.28179</td></tr><tr><td>validation_accuracy</td><td>39.59961</td></tr><tr><td>validation_loss</td><td>18.79704</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">embedding64cellTypeGRUbatchSize64</strong> at: <a href='https://wandb.ai/dlassignment/vanillaRNN/runs/a0n1kyj2' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN/runs/a0n1kyj2</a><br/> View project at: <a href='https://wandb.ai/dlassignment/vanillaRNN' target=\"_blank\">https://wandb.ai/dlassignment/vanillaRNN</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240515_083113-a0n1kyj2/logs</code>"},"metadata":{}},{"name":"stdout","text":"Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7d1d09c517e0>> (for post_run_cell), with arguments args (<ExecutionResult object at 7d1d09c52c80, execution_count=19 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7d1d09c51ea0, raw_cell=\"def main_fun():\n    wandb.init(project ='vanillaRN..\" store_history=True silent=False shell_futures=True cell_id=26d38ce5-8d5b-4a8e-b80f-ec8d7206f6a0> result=None>,),kwargs {}:\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:433\u001b[0m, in \u001b[0;36m_WandbInit._pause_backend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    432\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpausing backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 433\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface.py:682\u001b[0m, in \u001b[0;36mInterfaceBase.publish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    681\u001b[0m     pause \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mPauseRequest()\n\u001b[0;32m--> 682\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpause\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:357\u001b[0m, in \u001b[0;36mInterfaceShared._publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m, pause: pb\u001b[38;5;241m.\u001b[39mPauseRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    356\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(pause\u001b[38;5;241m=\u001b[39mpause)\n\u001b[0;32m--> 357\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py:51\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:221\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    219\u001b[0m server_req \u001b[38;5;241m=\u001b[39m spb\u001b[38;5;241m.\u001b[39mServerRequest()\n\u001b[1;32m    220\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[0;32m--> 221\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:155\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:152\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    150\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 152\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n","\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"],"ename":"BrokenPipeError","evalue":"[Errno 32] Broken pipe","output_type":"error"}]},{"cell_type":"code","source":"\ntrain(data)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T08:38:29.507789Z","iopub.execute_input":"2024-05-15T08:38:29.508075Z","iopub.status.idle":"2024-05-15T08:38:29.879964Z","shell.execute_reply.started":"2024-05-15T08:38:29.508037Z","shell.execute_reply":"2024-05-15T08:38:29.878617Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7d1d09c517e0>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7d1bd0375c00, raw_cell=\"\ntrain(data)\" store_history=True silent=False shell_futures=True cell_id=3550fc13-b4ba-4f61-b9a9-19d94db086c6>,),kwargs {}:\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:438\u001b[0m, in \u001b[0;36m_WandbInit._resume_backend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    437\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresuming backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 438\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface.py:690\u001b[0m, in \u001b[0;36mInterfaceBase.publish_resume\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     resume \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mResumeRequest()\n\u001b[0;32m--> 690\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:361\u001b[0m, in \u001b[0;36mInterfaceShared._publish_resume\u001b[0;34m(self, resume)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m, resume: pb\u001b[38;5;241m.\u001b[39mResumeRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    360\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(resume\u001b[38;5;241m=\u001b[39mresume)\n\u001b[0;32m--> 361\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py:51\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:221\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    219\u001b[0m server_req \u001b[38;5;241m=\u001b[39m spb\u001b[38;5;241m.\u001b[39mServerRequest()\n\u001b[1;32m    220\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[0;32m--> 221\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:155\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:152\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    150\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 152\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n","\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"],"ename":"BrokenPipeError","evalue":"[Errno 32] Broken pipe","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mTypeError\u001b[0m: train() missing 11 required positional arguments: 'encoderLayers', 'decoderLayers', 'hiddenLayerNuerons', 'cellType', 'bidirection', 'dropout', 'epochs', 'batchsize', 'learningRate', 'optimizer', and 'tf_ratio'"],"ename":"TypeError","evalue":"train() missing 11 required positional arguments: 'encoderLayers', 'decoderLayers', 'hiddenLayerNuerons', 'cellType', 'bidirection', 'dropout', 'epochs', 'batchsize', 'learningRate', 'optimizer', and 'tf_ratio'","output_type":"error"},{"name":"stdout","text":"Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7d1d09c517e0>> (for post_run_cell), with arguments args (<ExecutionResult object at 7d1bd0376500, execution_count=20 error_before_exec=None error_in_exec=train() missing 11 required positional arguments: 'encoderLayers', 'decoderLayers', 'hiddenLayerNuerons', 'cellType', 'bidirection', 'dropout', 'epochs', 'batchsize', 'learningRate', 'optimizer', and 'tf_ratio' info=<ExecutionInfo object at 7d1bd0375c00, raw_cell=\"\ntrain(data)\" store_history=True silent=False shell_futures=True cell_id=3550fc13-b4ba-4f61-b9a9-19d94db086c6> result=None>,),kwargs {}:\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:433\u001b[0m, in \u001b[0;36m_WandbInit._pause_backend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    432\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpausing backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 433\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface.py:682\u001b[0m, in \u001b[0;36mInterfaceBase.publish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    681\u001b[0m     pause \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mPauseRequest()\n\u001b[0;32m--> 682\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpause\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:357\u001b[0m, in \u001b[0;36mInterfaceShared._publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m, pause: pb\u001b[38;5;241m.\u001b[39mPauseRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    356\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(pause\u001b[38;5;241m=\u001b[39mpause)\n\u001b[0;32m--> 357\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py:51\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:221\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    219\u001b[0m server_req \u001b[38;5;241m=\u001b[39m spb\u001b[38;5;241m.\u001b[39mServerRequest()\n\u001b[1;32m    220\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[0;32m--> 221\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:155\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:152\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    150\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 152\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n","\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"],"ename":"BrokenPipeError","evalue":"[Errno 32] Broken pipe","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}