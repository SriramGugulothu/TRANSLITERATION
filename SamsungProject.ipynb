{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8813062,"sourceType":"datasetVersion","datasetId":5301302},{"sourceId":8898935,"sourceType":"datasetVersion","datasetId":5350032}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom transformers import MobileBertTokenizer, MobileBertModel\nimport string\nfrom datasets import Dataset as Hug_Face_Dataset,load_from_disk\nfrom torch.utils.data import DataLoader,Dataset\nimport torch.nn.functional as F\nimport torch.nn as nn      \nfrom sklearn.metrics import precision_recall_fscore_support\nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-08T03:08:59.916642Z","iopub.execute_input":"2024-07-08T03:08:59.916939Z","iopub.status.idle":"2024-07-08T03:09:07.334736Z","shell.execute_reply.started":"2024-07-08T03:08:59.916916Z","shell.execute_reply":"2024-07-08T03:09:07.333811Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df = pd.read_parquet(r\"/kaggle/input/parquet\")","metadata":{"execution":{"iopub.status.busy":"2024-07-08T03:09:07.336231Z","iopub.execute_input":"2024-07-08T03:09:07.336681Z","iopub.status.idle":"2024-07-08T03:09:07.860314Z","shell.execute_reply.started":"2024-07-08T03:09:07.336640Z","shell.execute_reply":"2024-07-08T03:09:07.859537Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_parquet(r\"/kaggle/input/testdata\")","metadata":{"execution":{"iopub.status.busy":"2024-07-08T03:09:15.288937Z","iopub.execute_input":"2024-07-08T03:09:15.289916Z","iopub.status.idle":"2024-07-08T03:09:15.367018Z","shell.execute_reply.started":"2024-07-08T03:09:15.289873Z","shell.execute_reply":"2024-07-08T03:09:15.366077Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"test_df","metadata":{"execution":{"iopub.status.busy":"2024-07-08T03:09:17.197373Z","iopub.execute_input":"2024-07-08T03:09:17.197750Z","iopub.status.idle":"2024-07-08T03:09:17.231358Z","shell.execute_reply.started":"2024-07-08T03:09:17.197722Z","shell.execute_reply":"2024-07-08T03:09:17.230413Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                                  tokens  \\\n0      [On, this, occasion, he, failed, to, gain, the...   \n1      [On, both, these, occasions, he, was, backed, ...   \n2      [He, also, appeared, as, himself, in, the, 199...   \n3      [The, Colorado, Rockies, were, created, as, an...   \n4      [He, kept, busy, recording, demo, tapes, at, h...   \n...                                                  ...   \n11592                                [com, ,, Amazon, .]   \n11593  [In, January, 2013, ,, the, European, Food, Sa...   \n11594  [All, of, the, games, had, art, true, to, the,...   \n11595  [There, was, also, a, game, made, for, the, Ga...   \n11596  [This, system, was, widely, copied, in, variou...   \n\n                                                ner_tags lang  \n0      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 4, ...   en  \n1      [0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 4, 4, 0, ...   en  \n2                [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0]   en  \n3      [0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0, ...   en  \n4      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   en  \n...                                                  ...  ...  \n11592                                       [0, 0, 3, 0]   en  \n11593  [0, 0, 0, 0, 0, 3, 4, 4, 4, 0, 0, 0, 0, 0, 3, ...   en  \n11594  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, ...   en  \n11595  [0, 0, 0, 0, 0, 0, 0, 0, 7, 8, 0, 0, 0, 0, 0, ...   en  \n11596                     [0, 0, 0, 0, 0, 0, 0, 3, 0, 0]   en  \n\n[11597 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tokens</th>\n      <th>ner_tags</th>\n      <th>lang</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[On, this, occasion, he, failed, to, gain, the...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 4, ...</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[On, both, these, occasions, he, was, backed, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 4, 4, 0, ...</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[He, also, appeared, as, himself, in, the, 199...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0]</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[The, Colorado, Rockies, were, created, as, an...</td>\n      <td>[0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0, ...</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[He, kept, busy, recording, demo, tapes, at, h...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11592</th>\n      <td>[com, ,, Amazon, .]</td>\n      <td>[0, 0, 3, 0]</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>11593</th>\n      <td>[In, January, 2013, ,, the, European, Food, Sa...</td>\n      <td>[0, 0, 0, 0, 0, 3, 4, 4, 4, 0, 0, 0, 0, 0, 3, ...</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>11594</th>\n      <td>[All, of, the, games, had, art, true, to, the,...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, ...</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>11595</th>\n      <td>[There, was, also, a, game, made, for, the, Ga...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 7, 8, 0, 0, 0, 0, 0, ...</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>11596</th>\n      <td>[This, system, was, widely, copied, in, variou...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 3, 0, 0]</td>\n      <td>en</td>\n    </tr>\n  </tbody>\n</table>\n<p>11597 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-08T08:02:51.867191Z","iopub.execute_input":"2024-07-08T08:02:51.868027Z","iopub.status.idle":"2024-07-08T08:02:51.884801Z","shell.execute_reply.started":"2024-07-08T08:02:51.867993Z","shell.execute_reply":"2024-07-08T08:02:51.883834Z"},"trusted":true},"execution_count":112,"outputs":[{"execution_count":112,"output_type":"execute_result","data":{"text/plain":"                                              tokens  \\\n0  [This, division, also, contains, the, Ventana,...   \n1  [\", So, here, is, the, balance, NBC, has, to, ...   \n2  [It, is, a, protest, song, that, \", creates, a...   \n3  [This, differs, from, approaches, such, as, IP...   \n4  [Since, then, ,, only, Terry, Bradshaw, in, 14...   \n\n                                            ner_tags lang  \n0         [0, 0, 0, 0, 0, 5, 6, 0, 0, 0, 0, 5, 0, 0]   en  \n1  [0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 7, 8, 0, 0, ...   en  \n2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   en  \n3  [0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, ...   en  \n4  [0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 1, 2, 0, 0, 0, ...   en  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tokens</th>\n      <th>ner_tags</th>\n      <th>lang</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[This, division, also, contains, the, Ventana,...</td>\n      <td>[0, 0, 0, 0, 0, 5, 6, 0, 0, 0, 0, 5, 0, 0]</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[\", So, here, is, the, balance, NBC, has, to, ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 7, 8, 0, 0, ...</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[It, is, a, protest, song, that, \", creates, a...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[This, differs, from, approaches, such, as, IP...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>en</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[Since, then, ,, only, Terry, Bradshaw, in, 14...</td>\n      <td>[0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 1, 2, 0, 0, 0, ...</td>\n      <td>en</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mp2 = {'B-PER':1,'I-PER':2,'B-ORG':3,'I-ORG':4,'B-LOC':5,'I-LOC':6,'B-MISC':7,'I-MISC':8,'B-NRM':9,'B-REG':10,'B-RS':11,'I-LIT':12,'I-NRM':13,'I-REG':14,'I-RS':15,'B-ANIM':16,'I-ANIM':17,'B-BIO':18,'I-BIO':19,'B-CEL':20,'I-CEL':21,'B-DIS':22,'I-DIS':23,'B-EVE':24,\n      'I-EVE':25,'B-FOOD':26,'I-FOOD':27,'B-INST':28,'I-INST':29,'B-MEDIA':30,'I-MEDIA':31,'B-MYTH':32,'I-MYTH':33,'B-PLANT':34,'I-PLANT':35,'B-TIME':36,'I-TIME':37,'B-VEHI':38,'I-VEHI':39,'B-LIT':40} ","metadata":{"execution":{"iopub.status.busy":"2024-07-07T17:34:02.641883Z","iopub.execute_input":"2024-07-07T17:34:02.642690Z","iopub.status.idle":"2024-07-07T17:34:02.648999Z","shell.execute_reply.started":"2024-07-07T17:34:02.642662Z","shell.execute_reply":"2024-07-07T17:34:02.647984Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def fun(tokens,tags):\n    count = 0\n    words = []\n    entities = []\n    index = 0\n    for token in tokens:\n        if(token[0] not in string.punctuation):\n            temp = token.split()\n            for t in temp:\n                words.append(t)\n            if(tags[index]!=0):\n                entities.append((str(count+1),str(count+len(temp)),mp[tags[index]]))\n            count+=len(temp)\n        index+=1\n    return words,entities","metadata":{"execution":{"iopub.status.busy":"2024-07-08T03:09:24.019675Z","iopub.execute_input":"2024-07-08T03:09:24.020020Z","iopub.status.idle":"2024-07-08T03:09:24.026754Z","shell.execute_reply.started":"2024-07-08T03:09:24.019994Z","shell.execute_reply":"2024-07-08T03:09:24.025635Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df2 = pd.DataFrame(columns=['input','output'])","metadata":{"execution":{"iopub.status.busy":"2024-07-08T03:09:28.055763Z","iopub.execute_input":"2024-07-08T03:09:28.056584Z","iopub.status.idle":"2024-07-08T03:09:28.061845Z","shell.execute_reply.started":"2024-07-08T03:09:28.056554Z","shell.execute_reply":"2024-07-08T03:09:28.060793Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"test_df2 = pd.DataFrame(columns=['input','output'])","metadata":{"execution":{"iopub.status.busy":"2024-07-08T03:09:30.436224Z","iopub.execute_input":"2024-07-08T03:09:30.436601Z","iopub.status.idle":"2024-07-08T03:09:30.441870Z","shell.execute_reply.started":"2024-07-08T03:09:30.436572Z","shell.execute_reply":"2024-07-08T03:09:30.440882Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"test_df2","metadata":{"execution":{"iopub.status.busy":"2024-07-08T03:09:32.488283Z","iopub.execute_input":"2024-07-08T03:09:32.488895Z","iopub.status.idle":"2024-07-08T03:09:32.496462Z","shell.execute_reply.started":"2024-07-08T03:09:32.488864Z","shell.execute_reply":"2024-07-08T03:09:32.495480Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"Empty DataFrame\nColumns: [input, output]\nIndex: []","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input</th>\n      <th>output</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df2","metadata":{"execution":{"iopub.status.busy":"2024-07-08T03:09:35.169422Z","iopub.execute_input":"2024-07-08T03:09:35.170341Z","iopub.status.idle":"2024-07-08T03:09:35.178152Z","shell.execute_reply.started":"2024-07-08T03:09:35.170308Z","shell.execute_reply":"2024-07-08T03:09:35.177341Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Empty DataFrame\nColumns: [input, output]\nIndex: []","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input</th>\n      <th>output</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"mp = {1:'B-PER',2:'I-PER',3:'B-ORG',4:'I-ORG',5:'B-LOC',6:'I-LOC',7:'B-MISC',8:'I-MISC'}","metadata":{"execution":{"iopub.status.busy":"2024-07-08T03:09:37.215433Z","iopub.execute_input":"2024-07-08T03:09:37.215847Z","iopub.status.idle":"2024-07-08T03:09:37.220516Z","shell.execute_reply.started":"2024-07-08T03:09:37.215817Z","shell.execute_reply":"2024-07-08T03:09:37.219696Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(0,len(df)):\n    k,l = fun(df['tokens'][i],df['ner_tags'][i])\n    df2.loc[i]=[k,l]","metadata":{"execution":{"iopub.status.busy":"2024-07-08T03:09:40.778831Z","iopub.execute_input":"2024-07-08T03:09:40.779187Z","iopub.status.idle":"2024-07-08T03:13:39.595970Z","shell.execute_reply.started":"2024-07-08T03:09:40.779158Z","shell.execute_reply":"2024-07-08T03:13:39.594948Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"for i in range(0,len(test_df)):\n    k,l = fun(test_df['tokens'][i],test_df['ner_tags'][i])\n    test_df2.loc[i]=[k,l]","metadata":{"execution":{"iopub.status.busy":"2024-07-08T03:21:51.916510Z","iopub.execute_input":"2024-07-08T03:21:51.917221Z","iopub.status.idle":"2024-07-08T03:22:04.119808Z","shell.execute_reply.started":"2024-07-08T03:21:51.917188Z","shell.execute_reply":"2024-07-08T03:22:04.118950Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"test_df2","metadata":{"execution":{"iopub.status.busy":"2024-07-08T03:22:09.613157Z","iopub.execute_input":"2024-07-08T03:22:09.614164Z","iopub.status.idle":"2024-07-08T03:22:09.642277Z","shell.execute_reply.started":"2024-07-08T03:22:09.614121Z","shell.execute_reply":"2024-07-08T03:22:09.641246Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"                                                   input  \\\n0      [On, this, occasion, he, failed, to, gain, the...   \n1      [On, both, these, occasions, he, was, backed, ...   \n2      [He, also, appeared, as, himself, in, the, 199...   \n3      [The, Colorado, Rockies, were, created, as, an...   \n4      [He, kept, busy, recording, demo, tapes, at, h...   \n...                                                  ...   \n11592                                      [com, Amazon]   \n11593  [In, January, 2013, the, European, Food, Safet...   \n11594  [All, of, the, games, had, art, true, to, the,...   \n11595  [There, was, also, a, game, made, for, the, Ga...   \n11596  [This, system, was, widely, copied, in, variou...   \n\n                                                  output  \n0      [(12, 12, B-ORG), (13, 13, I-ORG), (14, 14, I-...  \n1      [(10, 10, B-ORG), (11, 11, I-ORG), (12, 12, I-...  \n2                                     [(10, 10, B-MISC)]  \n3      [(2, 2, B-ORG), (3, 3, I-ORG), (13, 13, B-LOC)...  \n4      [(24, 24, B-LOC), (25, 25, I-LOC), (26, 26, I-...  \n...                                                  ...  \n11592                                    [(2, 2, B-ORG)]  \n11593  [(5, 5, B-ORG), (6, 6, I-ORG), (7, 7, I-ORG), ...  \n11594                                  [(12, 12, B-ORG)]  \n11595                 [(9, 9, B-MISC), (10, 10, I-MISC)]  \n11596                                    [(8, 8, B-ORG)]  \n\n[11597 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input</th>\n      <th>output</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[On, this, occasion, he, failed, to, gain, the...</td>\n      <td>[(12, 12, B-ORG), (13, 13, I-ORG), (14, 14, I-...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[On, both, these, occasions, he, was, backed, ...</td>\n      <td>[(10, 10, B-ORG), (11, 11, I-ORG), (12, 12, I-...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[He, also, appeared, as, himself, in, the, 199...</td>\n      <td>[(10, 10, B-MISC)]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[The, Colorado, Rockies, were, created, as, an...</td>\n      <td>[(2, 2, B-ORG), (3, 3, I-ORG), (13, 13, B-LOC)...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[He, kept, busy, recording, demo, tapes, at, h...</td>\n      <td>[(24, 24, B-LOC), (25, 25, I-LOC), (26, 26, I-...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11592</th>\n      <td>[com, Amazon]</td>\n      <td>[(2, 2, B-ORG)]</td>\n    </tr>\n    <tr>\n      <th>11593</th>\n      <td>[In, January, 2013, the, European, Food, Safet...</td>\n      <td>[(5, 5, B-ORG), (6, 6, I-ORG), (7, 7, I-ORG), ...</td>\n    </tr>\n    <tr>\n      <th>11594</th>\n      <td>[All, of, the, games, had, art, true, to, the,...</td>\n      <td>[(12, 12, B-ORG)]</td>\n    </tr>\n    <tr>\n      <th>11595</th>\n      <td>[There, was, also, a, game, made, for, the, Ga...</td>\n      <td>[(9, 9, B-MISC), (10, 10, I-MISC)]</td>\n    </tr>\n    <tr>\n      <th>11596</th>\n      <td>[This, system, was, widely, copied, in, variou...</td>\n      <td>[(8, 8, B-ORG)]</td>\n    </tr>\n  </tbody>\n</table>\n<p>11597 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df2","metadata":{"execution":{"iopub.status.busy":"2024-07-08T03:22:12.899091Z","iopub.execute_input":"2024-07-08T03:22:12.899758Z","iopub.status.idle":"2024-07-08T03:22:12.931420Z","shell.execute_reply.started":"2024-07-08T03:22:12.899726Z","shell.execute_reply":"2024-07-08T03:22:12.930419Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"                                                   input  \\\n0      [This, division, also, contains, the, Ventana,...   \n1      [So, here, is, the, balance, NBC, has, to, con...   \n2      [It, is, a, protest, song, that, creates, a, c...   \n3      [This, differs, from, approaches, such, as, IP...   \n4      [Since, then, only, Terry, Bradshaw, in, 147, ...   \n...                                                  ...   \n92715  [The, couple, had, a, son, David, and, a, daug...   \n92716  [The, Home, Secretary, J., R., Clynes, was, pr...   \n92717  [At, the, time, of, her, birth, she, was, four...   \n92718  [The, film, was, based, on, the, Broadway, pla...   \n92719  [The, couple, had, two, children, both, born, ...   \n\n                                                  output  \n0        [(6, 6, B-LOC), (7, 7, I-LOC), (11, 11, B-LOC)]  \n1      [(6, 6, B-ORG), (10, 10, B-MISC), (11, 11, I-M...  \n2                                      [(22, 22, B-LOC)]  \n3                                       [(9, 9, B-MISC)]  \n4      [(4, 4, B-PER), (5, 5, I-PER), (9, 9, B-PER), ...  \n...                                                  ...  \n92715                   [(6, 6, B-PER), (10, 10, B-PER)]  \n92716      [(4, 4, B-PER), (5, 5, I-PER), (6, 6, I-PER)]  \n92717                 [(17, 17, B-PER), (18, 18, I-PER)]  \n92718                                   [(7, 7, B-MISC)]  \n92719  [(9, 9, B-MISC), (12, 12, B-PER), (14, 14, B-P...  \n\n[92720 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input</th>\n      <th>output</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[This, division, also, contains, the, Ventana,...</td>\n      <td>[(6, 6, B-LOC), (7, 7, I-LOC), (11, 11, B-LOC)]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[So, here, is, the, balance, NBC, has, to, con...</td>\n      <td>[(6, 6, B-ORG), (10, 10, B-MISC), (11, 11, I-M...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[It, is, a, protest, song, that, creates, a, c...</td>\n      <td>[(22, 22, B-LOC)]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[This, differs, from, approaches, such, as, IP...</td>\n      <td>[(9, 9, B-MISC)]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[Since, then, only, Terry, Bradshaw, in, 147, ...</td>\n      <td>[(4, 4, B-PER), (5, 5, I-PER), (9, 9, B-PER), ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>92715</th>\n      <td>[The, couple, had, a, son, David, and, a, daug...</td>\n      <td>[(6, 6, B-PER), (10, 10, B-PER)]</td>\n    </tr>\n    <tr>\n      <th>92716</th>\n      <td>[The, Home, Secretary, J., R., Clynes, was, pr...</td>\n      <td>[(4, 4, B-PER), (5, 5, I-PER), (6, 6, I-PER)]</td>\n    </tr>\n    <tr>\n      <th>92717</th>\n      <td>[At, the, time, of, her, birth, she, was, four...</td>\n      <td>[(17, 17, B-PER), (18, 18, I-PER)]</td>\n    </tr>\n    <tr>\n      <th>92718</th>\n      <td>[The, film, was, based, on, the, Broadway, pla...</td>\n      <td>[(7, 7, B-MISC)]</td>\n    </tr>\n    <tr>\n      <th>92719</th>\n      <td>[The, couple, had, two, children, both, born, ...</td>\n      <td>[(9, 9, B-MISC), (12, 12, B-PER), (14, 14, B-P...</td>\n    </tr>\n  </tbody>\n</table>\n<p>92720 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset3 = Hug_Face_Dataset.from_pandas(df2)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T03:22:18.129361Z","iopub.execute_input":"2024-07-08T03:22:18.130179Z","iopub.status.idle":"2024-07-08T03:22:18.646767Z","shell.execute_reply.started":"2024-07-08T03:22:18.130149Z","shell.execute_reply":"2024-07-08T03:22:18.645781Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"test_dataset3 = Hug_Face_Dataset.from_pandas(test_df2)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T03:22:20.488577Z","iopub.execute_input":"2024-07-08T03:22:20.489336Z","iopub.status.idle":"2024-07-08T03:22:20.559042Z","shell.execute_reply.started":"2024-07-08T03:22:20.489300Z","shell.execute_reply":"2024-07-08T03:22:20.558088Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"dataset3.save_to_disk(r\"C:\\Users\\srira\\OneDrive\\Desktop\\kaggle\")","metadata":{"execution":{"iopub.status.busy":"2024-07-08T03:22:24.061339Z","iopub.execute_input":"2024-07-08T03:22:24.062027Z","iopub.status.idle":"2024-07-08T03:22:24.174919Z","shell.execute_reply.started":"2024-07-08T03:22:24.061993Z","shell.execute_reply":"2024-07-08T03:22:24.174165Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"Saving the dataset (0/1 shards):   0%|          | 0/92720 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da00851411f946cf9c4c3a8fa5709b31"}},"metadata":{}}]},{"cell_type":"code","source":"test_dataset3.save_to_disk(r\"C:\\Users\\srira\\OneDrive\\Desktop\\test_kaggle\")","metadata":{"execution":{"iopub.status.busy":"2024-07-08T03:22:27.422216Z","iopub.execute_input":"2024-07-08T03:22:27.422814Z","iopub.status.idle":"2024-07-08T03:22:27.464606Z","shell.execute_reply.started":"2024-07-08T03:22:27.422780Z","shell.execute_reply":"2024-07-08T03:22:27.463734Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"Saving the dataset (0/1 shards):   0%|          | 0/11597 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"252fd1b66fe544fcb3babefd43a01310"}},"metadata":{}}]},{"cell_type":"code","source":"dataset = load_from_disk(r\"C:\\Users\\srira\\OneDrive\\Desktop\\kaggle\")","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:43:39.655073Z","iopub.execute_input":"2024-07-08T05:43:39.655708Z","iopub.status.idle":"2024-07-08T05:43:39.665974Z","shell.execute_reply.started":"2024-07-08T05:43:39.655677Z","shell.execute_reply":"2024-07-08T05:43:39.665114Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"dataset2 = load_from_disk(r\"C:\\Users\\srira\\OneDrive\\Desktop\\test_kaggle\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_temp = pd.DataFrame(dataset)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:43:42.421604Z","iopub.execute_input":"2024-07-08T05:43:42.422448Z","iopub.status.idle":"2024-07-08T05:43:54.017879Z","shell.execute_reply.started":"2024-07-08T05:43:42.422417Z","shell.execute_reply":"2024-07-08T05:43:54.017065Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_temp_2 = pd.DataFrame(dataset2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_temp_2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_temp","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:43:56.817817Z","iopub.execute_input":"2024-07-08T05:43:56.818429Z","iopub.status.idle":"2024-07-08T05:43:56.847443Z","shell.execute_reply.started":"2024-07-08T05:43:56.818397Z","shell.execute_reply":"2024-07-08T05:43:56.846489Z"},"trusted":true},"execution_count":94,"outputs":[{"execution_count":94,"output_type":"execute_result","data":{"text/plain":"                                                   input  \\\n0      [This, division, also, contains, the, Ventana,...   \n1      [So, here, is, the, balance, NBC, has, to, con...   \n2      [It, is, a, protest, song, that, creates, a, c...   \n3      [This, differs, from, approaches, such, as, IP...   \n4      [Since, then, only, Terry, Bradshaw, in, 147, ...   \n...                                                  ...   \n92715  [The, couple, had, a, son, David, and, a, daug...   \n92716  [The, Home, Secretary, J., R., Clynes, was, pr...   \n92717  [At, the, time, of, her, birth, she, was, four...   \n92718  [The, film, was, based, on, the, Broadway, pla...   \n92719  [The, couple, had, two, children, both, born, ...   \n\n                                                  output  __index_level_0__  \n0        [[6, 6, B-LOC], [7, 7, I-LOC], [11, 11, B-LOC]]                  0  \n1      [[6, 6, B-ORG], [10, 10, B-MISC], [11, 11, I-M...                  1  \n2                                      [[22, 22, B-LOC]]                  2  \n3                                       [[9, 9, B-MISC]]                  3  \n4      [[4, 4, B-PER], [5, 5, I-PER], [9, 9, B-PER], ...                  4  \n...                                                  ...                ...  \n92715                   [[6, 6, B-PER], [10, 10, B-PER]]              92715  \n92716      [[4, 4, B-PER], [5, 5, I-PER], [6, 6, I-PER]]              92716  \n92717                 [[17, 17, B-PER], [18, 18, I-PER]]              92717  \n92718                                   [[7, 7, B-MISC]]              92718  \n92719  [[9, 9, B-MISC], [12, 12, B-PER], [14, 14, B-P...              92719  \n\n[92720 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input</th>\n      <th>output</th>\n      <th>__index_level_0__</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[This, division, also, contains, the, Ventana,...</td>\n      <td>[[6, 6, B-LOC], [7, 7, I-LOC], [11, 11, B-LOC]]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[So, here, is, the, balance, NBC, has, to, con...</td>\n      <td>[[6, 6, B-ORG], [10, 10, B-MISC], [11, 11, I-M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[It, is, a, protest, song, that, creates, a, c...</td>\n      <td>[[22, 22, B-LOC]]</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[This, differs, from, approaches, such, as, IP...</td>\n      <td>[[9, 9, B-MISC]]</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[Since, then, only, Terry, Bradshaw, in, 147, ...</td>\n      <td>[[4, 4, B-PER], [5, 5, I-PER], [9, 9, B-PER], ...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>92715</th>\n      <td>[The, couple, had, a, son, David, and, a, daug...</td>\n      <td>[[6, 6, B-PER], [10, 10, B-PER]]</td>\n      <td>92715</td>\n    </tr>\n    <tr>\n      <th>92716</th>\n      <td>[The, Home, Secretary, J., R., Clynes, was, pr...</td>\n      <td>[[4, 4, B-PER], [5, 5, I-PER], [6, 6, I-PER]]</td>\n      <td>92716</td>\n    </tr>\n    <tr>\n      <th>92717</th>\n      <td>[At, the, time, of, her, birth, she, was, four...</td>\n      <td>[[17, 17, B-PER], [18, 18, I-PER]]</td>\n      <td>92717</td>\n    </tr>\n    <tr>\n      <th>92718</th>\n      <td>[The, film, was, based, on, the, Broadway, pla...</td>\n      <td>[[7, 7, B-MISC]]</td>\n      <td>92718</td>\n    </tr>\n    <tr>\n      <th>92719</th>\n      <td>[The, couple, had, two, children, both, born, ...</td>\n      <td>[[9, 9, B-MISC], [12, 12, B-PER], [14, 14, B-P...</td>\n      <td>92719</td>\n    </tr>\n  </tbody>\n</table>\n<p>92720 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, inputTokens,outputEntity,tokenizer,max_tokens=128,mapping={'B-PER':1}):\n        self.source = inputTokens\n        self.target = outputEntity\n        self.tokenizer = tokenizer\n        self.max_tokens = max_tokens\n        self.mapping = mapping\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        \n    def __len__(self):\n        return len(self.source)\n    \n    def __getitem__(self, idx):\n        \n        source_data = self.source[idx]\n        target_data = self.target[idx]\n        tokenized_input = self.tokenizer(source_data, return_tensors='pt', padding='max_length', truncation=True, max_length=self.max_tokens,is_split_into_words=True)\n        label_ids = torch.zeros(tokenized_input['input_ids'].size(1), dtype=torch.long)\n        \n        for start, end, label in target_data:\n            start = int(start)\n            end = int(end)\n            label_id = self.mapping[label]\n            label_ids[start:end+1] = label_id\n        \n        return tokenized_input['input_ids'].squeeze(0).to(self.device), tokenized_input['attention_mask'].squeeze(0).to(self.device), label_ids.to(self.device)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:44:07.411240Z","iopub.execute_input":"2024-07-08T05:44:07.411599Z","iopub.status.idle":"2024-07-08T05:44:07.421714Z","shell.execute_reply.started":"2024-07-08T05:44:07.411570Z","shell.execute_reply":"2024-07-08T05:44:07.420721Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"class NERModel2(nn.Module):\n    \n    def __init__(self, max_tokens=128, hidden_size=64, num_entities=8,mobilebert_model=None,device='cpu',dropout_p=0.5):\n        \n        super(NERModel2, self).__init__()\n        \n        self.max_tokens = max_tokens\n        self.num_entities = num_entities\n        # MobileBERT model (base model)\n        self.mobilebert = mobilebert_model.to(device=device)\n        \n        self.hidden_size = hidden_size\n        \n        self.device = device\n        \n        # First GRU Layer\n        \n        self.gru1 = nn.GRU(input_size=self.mobilebert.config.hidden_size, hidden_size=hidden_size, batch_first=True)\n        \n        # Second GRU Layer\n        \n        self.gru2 = nn.GRU(input_size=hidden_size, hidden_size=hidden_size, batch_first=True)\n        \n        # Fully connected layers\n        self.fc_layer = nn.Linear(hidden_size, num_entities)\n        \n        self.dropout = nn.Dropout(dropout_p)\n    \n            \n    def forward(self, input_ids, attention_mask):\n        \n        batch_size = input_ids.size(0)\n        \n        \n        outputs = self.mobilebert(input_ids=input_ids, attention_mask=attention_mask)\n        \n        sequence_output = outputs.last_hidden_state  \n        \n        temp = torch.zeros(1,batch_size,self.hidden_size,device = input_ids.device)\n        \n        \n        gru1_outputs = torch.zeros(batch_size, self.max_tokens, self.gru1.hidden_size, device=input_ids.device)\n        gru2_outputs = torch.zeros(batch_size, self.max_tokens, self.gru2.hidden_size, device=input_ids.device)\n        \n        for i in range(self.max_tokens):\n\n            gru1_output, temp = self.gru1(sequence_output[:, i].unsqueeze(1),temp)\n            gru1_outputs[:,i,:] = gru1_output.squeeze(1)\n            \n        temp = torch.zeros(1,batch_size,self.hidden_size,device = input_ids.device)\n        \n        for i in range(self.max_tokens-1,-1,-1):\n            temp2, temp =  self.gru1(sequence_output[:,i].unsqueeze(1),temp)\n            temp2 = temp2.squeeze(1)\n            gru1_outputs[:,i,:] = (gru1_outputs[:,i,:] + temp2) / 2\n            \n        temp = torch.zeros(1,batch_size,self.gru2.input_size,device = input_ids.device)\n        \n        for i in range(self.max_tokens):\n            gru2_output, temp = self.gru2(gru1_outputs[:, i].unsqueeze(1),temp)\n            gru2_outputs[:,i,:] = gru2_output.squeeze(1)\n            \n        temp = torch.zeros(1,batch_size,self.gru2.input_size,device = input_ids.device)\n        \n        for i in range(self.max_tokens-1,-1,-1):\n            temp2, temp =  self.gru2(gru1_outputs[:,i].unsqueeze(1),temp)\n            temp2 = temp2.squeeze(1)\n            gru2_outputs[:,i,:] = (gru2_outputs[:,i,:] + temp2) / 2                  \n            \n        overallOutput = torch.zeros(batch_size, self.max_tokens,self.num_entities, device=input_ids.device)\n        \n        for i in range(self.max_tokens):\n            output = self.dropout(gru2_outputs[:, i, :]) # dropout on gru outputs\n            overallOutput[:, i, :] = self.fc_layer(output)\n        \n        return overallOutput","metadata":{"execution":{"iopub.status.busy":"2024-07-08T09:18:50.843265Z","iopub.execute_input":"2024-07-08T09:18:50.844108Z","iopub.status.idle":"2024-07-08T09:18:50.863619Z","shell.execute_reply.started":"2024-07-08T09:18:50.844070Z","shell.execute_reply":"2024-07-08T09:18:50.862643Z"},"trusted":true},"execution_count":129,"outputs":[]},{"cell_type":"code","source":"def dataProcessing(dataset,tokenizer,max_tokens,batch_size,mapping):\n    inputData = dataset['input'] \n    outputData = dataset['output']\n    myDataset = MyDataset(inputData,outputData,tokenizer,max_tokens,mapping)\n    dataLoader = DataLoader(myDataset,batch_size,shuffle = True)\n    return dataLoader    ","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:44:32.513995Z","iopub.execute_input":"2024-07-08T05:44:32.514345Z","iopub.status.idle":"2024-07-08T05:44:32.521957Z","shell.execute_reply.started":"2024-07-08T05:44:32.514316Z","shell.execute_reply":"2024-07-08T05:44:32.520852Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:44:36.045086Z","iopub.execute_input":"2024-07-08T05:44:36.046043Z","iopub.status.idle":"2024-07-08T05:44:36.050155Z","shell.execute_reply.started":"2024-07-08T05:44:36.046010Z","shell.execute_reply":"2024-07-08T05:44:36.049160Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-07-08T05:44:38.110497Z","iopub.execute_input":"2024-07-08T05:44:38.111311Z","iopub.status.idle":"2024-07-08T05:44:38.115343Z","shell.execute_reply.started":"2024-07-08T05:44:38.111279Z","shell.execute_reply":"2024-07-08T05:44:38.114274Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"def testingAccuracyCalculator(model,tokenizer,max_tokens,batch_size,mapping):\n    \n    dataset = load_from_disk(r\"C:\\Users\\srira\\OneDrive\\Desktop\\test_kaggle\")\n    \n    dataLoader = dataProcessing(dataset,tokenizer,max_tokens,batch_size,mapping)\n    \n    criterion = nn.CrossEntropyLoss()\n    numberOfInputs = len(dataset['input'])*128\n    total_loss = 0.0\n    total_steps = 0.0\n    correct_predictions = 0.0        \n    \n    all_true_labels = []\n    all_pred_labels = []\n    \n    model.eval() #model is now in evaluation mode. \n    \n    \n    for idx,(input_ids, attention_mask, labels) in enumerate(tqdm(dataLoader)):\n\n        output = model(input_ids, attention_mask)\n\n        # Flatten the logits and labels for loss calculation\n\n        output_flat = output.view(-1, output.size(-1))\n        labels_flat = labels.view(-1)\n\n        probabilities = F.softmax(output_flat, dim=1)\n\n        predicted_labels = torch.argmax(probabilities, dim=1)\n\n        correct_predictions += (predicted_labels == labels_flat).sum().item()\n\n        all_true_labels.extend(labels_flat.cpu().numpy())\n        all_pred_labels.extend(predicted_labels.cpu().numpy())\n\n        loss = criterion(output_flat, labels_flat)\n        \n        total_loss += loss.item() \n\n        if(idx%100==0):\n            print(f'loss {loss.item()}')\n\n        total_steps += 1\n        \n    avg_loss = total_loss / total_steps\n    accuracy_percentage = (correct_predictions / numberOfInputs)*100\n    precision, recall, f1, _ = precision_recall_fscore_support(all_true_labels, all_pred_labels, average='weighted',zero_division=0) #I have used weighted average of three scores.\n    print(f'average_loss {avg_loss}, accuracyPercentage, {accuracy_percentage:.2f}')  \n    print(f'precision{precision:.2f},recall{recall:.2f},f1_score{f1:.2f}')\n    with open(r\"C:\\Users\\srira\\OneDrive\\Desktop\\kaggle\\checkpoints.log\", 'a') as log_file:\n        log_file.write(f'Testing mode ->> avg_loss {avg_loss}, accuracy_percentage {accuracy_percentage:.2f},precision {precision:.2f},recall {recall:.2f}, f1 {f1:.2f}\\n')\n    model.train()  # model now is in training mode.","metadata":{"execution":{"iopub.status.busy":"2024-07-08T08:42:05.785009Z","iopub.execute_input":"2024-07-08T08:42:05.785754Z","iopub.status.idle":"2024-07-08T08:42:05.796835Z","shell.execute_reply.started":"2024-07-08T08:42:05.785724Z","shell.execute_reply":"2024-07-08T08:42:05.795890Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"def train(max_tokens,hidden_size,num_entities,learning_rate,batch_size,mapping,epochs,dropout):\n    \n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    tokenizer = MobileBertTokenizer.from_pretrained('google/mobilebert-uncased')\n    mobilebert_model = MobileBertModel.from_pretrained('google/mobilebert-uncased')\n    mobilebert_model.config.embedding_size = 256    \n    dataset = load_from_disk(r\"C:\\Users\\srira\\OneDrive\\Desktop\\kaggle\")\n    \n    dataloader = dataProcessing(dataset,tokenizer,max_tokens,batch_size,mapping)\n    \n    model = NERModel2(max_tokens,hidden_size,num_entities,mobilebert_model,device,dropout)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n    \n    criterion = nn.CrossEntropyLoss()\n    \n    model.to(device)\n    \n    model.train()\n    \n    numberOfInputs = len(dataset['input'])*128\n    \n    with open(r\"C:\\Users\\srira\\OneDrive\\Desktop\\kaggle\\checkpoints.log\", 'w') as log_file:\n        log_file.write(\"Starting training log\\n\")\n    \n    for epoch in range(epochs): \n\n        total_loss = 0.0\n        total_steps = 0.0\n        \n        correct_predictions = 0.0\n        print(f'epoch{epoch}')\n        \n        all_true_labels = []\n        all_pred_labels = []\n        \n        for idx,(input_ids, attention_mask, labels) in enumerate(tqdm(dataloader)):\n            \n            optimizer.zero_grad()\n        \n            output = model(input_ids, attention_mask)\n\n            # Flatten the logits and labels for loss calculation\n            \n            output_flat = output.view(-1, output.size(-1))\n            labels_flat = labels.view(-1)\n\n            probabilities = F.softmax(output_flat, dim=1)\n\n            predicted_labels = torch.argmax(probabilities, dim=1)\n            \n            correct_predictions += (predicted_labels == labels_flat).sum().item()\n            \n            all_true_labels.extend(labels_flat.cpu().numpy())\n            all_pred_labels.extend(predicted_labels.cpu().numpy())\n\n            # Calculate loss\n            loss = criterion(output_flat, labels_flat)\n\n            # Backward pass\n            loss.backward()\n            \n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) # gradient clipping\n            \n            optimizer.step()\n\n            # Accumulate loss\n            total_loss += loss.item() \n            \n            if(idx%200==0):\n                print(f'loss {loss.item()}')\n            \n            total_steps += 1\n\n        # Print average loss\n        avg_loss = total_loss / total_steps\n        accuracy_percentage = (correct_predictions / numberOfInputs)*100\n        precision, recall, f1, _ = precision_recall_fscore_support(all_true_labels, all_pred_labels, average='weighted',zero_division=0) #I have used weighted average of three scores.\n        print(f'epoch {epoch}, average_loss {avg_loss}, accuracyPercentage, {accuracy_percentage:.2f}')  \n        print(f'precision{precision:.2f},recall{recall:.2f},f1_score{f1:.2f}')\n        with open(r\"C:\\Users\\srira\\OneDrive\\Desktop\\kaggle\\checkpoints.log\", 'a') as log_file:\n            log_file.write(f'Training mode ->> epoch {epoch},avg_loss {avg_loss}, accuracy_percentage {accuracy_percentage:.2f},precision {precision:.2f},recall {recall:.2f}, f1 {f1:.2f}\\n')\n        checkpoint_path = os.path.join(r\"C:\\Users\\srira\\OneDrive\\Desktop\\kaggle\", f'epoch_{epoch}_checkpoint.pth')\n        torch.save(model.state_dict(), checkpoint_path)\n        testingAccuracyCalculator(model,tokenizer,max_tokens,batch_size,mapping)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T10:26:42.454563Z","iopub.execute_input":"2024-07-08T10:26:42.454925Z","iopub.status.idle":"2024-07-08T10:26:42.471107Z","shell.execute_reply.started":"2024-07-08T10:26:42.454899Z","shell.execute_reply":"2024-07-08T10:26:42.470059Z"},"trusted":true},"execution_count":154,"outputs":[]},{"cell_type":"code","source":"import os","metadata":{"execution":{"iopub.status.busy":"2024-07-08T10:24:02.590161Z","iopub.execute_input":"2024-07-08T10:24:02.590531Z","iopub.status.idle":"2024-07-08T10:24:02.595632Z","shell.execute_reply.started":"2024-07-08T10:24:02.590483Z","shell.execute_reply":"2024-07-08T10:24:02.594424Z"},"trusted":true},"execution_count":151,"outputs":[]},{"cell_type":"code","source":"epoch = 1\n","metadata":{"execution":{"iopub.status.busy":"2024-07-08T10:24:31.766203Z","iopub.execute_input":"2024-07-08T10:24:31.766618Z","iopub.status.idle":"2024-07-08T10:24:31.772706Z","shell.execute_reply.started":"2024-07-08T10:24:31.766590Z","shell.execute_reply":"2024-07-08T10:24:31.771735Z"},"trusted":true},"execution_count":153,"outputs":[]},{"cell_type":"code","source":"mapping = {'B-PER':1,'I-PER':2,'B-ORG':3,'I-ORG':4,'B-LOC':5,'I-LOC':6,'B-MISC':7,'I-MISC':8,'B-NRM':9,'B-REG':10,'B-RS':11,'I-LIT':12,'I-NRM':13,'I-REG':14,'I-RS':15,'B-ANIM':16,'I-ANIM':17,'B-BIO':18,'I-BIO':19,'B-CEL':20,'I-CEL':21,'B-DIS':22,'I-DIS':23,'B-EVE':24,\n      'I-EVE':25,'B-FOOD':26,'I-FOOD':27,'B-INST':28,'I-INST':29,'B-MEDIA':30,'I-MEDIA':31,'B-MYTH':32,'I-MYTH':33,'B-PLANT':34,'I-PLANT':35,'B-TIME':36,'I-TIME':37,'B-VEHI':38,'I-VEHI':39,'B-LIT':40}","metadata":{"execution":{"iopub.status.busy":"2024-07-07T17:40:24.672317Z","iopub.execute_input":"2024-07-07T17:40:24.672973Z","iopub.status.idle":"2024-07-07T17:40:24.679703Z","shell.execute_reply.started":"2024-07-07T17:40:24.672918Z","shell.execute_reply":"2024-07-07T17:40:24.678723Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"print(64*)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mapping = {'B-PER':1,'I-PER':2,'B-ORG':3,'I-ORG':4,'B-LOC':5,'I-LOC':6,'B-MISC':7,'I-MISC':8,'B-NRM':9,'B-REG':10,'B-RS':11,'I-LIT':12,'I-NRM':13,'I-REG':14,'I-RS':15,'B-ANIM':16,'I-ANIM':17,'B-BIO':18,'I-BIO':19,'B-CEL':20,'I-CEL':21,'B-DIS':22,'I-DIS':23,'B-EVE':24,\n      'I-EVE':25,'B-FOOD':26,'I-FOOD':27,'B-INST':28,'I-INST':29,'B-MEDIA':30,'I-MEDIA':31,'B-MYTH':32,'I-MYTH':33,'B-PLANT':34,'I-PLANT':35,'B-TIME':36,'I-TIME':37,'B-VEHI':38,'I-VEHI':39,'B-LIT':40} \ntrain(max_tokens=128,hidden_size=64,num_entities=41,learning_rate=1e-4,batch_size=64,mapping=mapping,epochs=2,dropout=0.8)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T10:26:47.623144Z","iopub.execute_input":"2024-07-08T10:26:47.623854Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"epoch0\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 1/1449 [00:01<26:32,  1.10s/it]","output_type":"stream"},{"name":"stdout","text":"loss 3.9240734577178955\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 6/1449 [00:06<24:33,  1.02s/it]","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}